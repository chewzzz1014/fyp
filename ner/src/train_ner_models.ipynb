{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chewzzz1014/fyp/blob/master/ner/src/train_ner_models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train NER Models"
      ],
      "metadata": {
        "id": "t0P9v82yDulr"
      },
      "id": "t0P9v82yDulr"
    },
    {
      "cell_type": "code",
      "source": [
        "# mount drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "5YToyjV-40ZV",
        "outputId": "2b843367-c9ad-4c39-e3ce-f75e64c6e7d5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "5YToyjV-40ZV",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir spacy_ner_data"
      ],
      "metadata": {
        "id": "VtZ7OFQtpG4-"
      },
      "id": "VtZ7OFQtpG4-",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "import spacy\n",
        "from spacy.tokens import DocBin\n",
        "\n",
        "# Load JSON data\n",
        "with open('/content/drive/MyDrive/FYP/Implementation/Resume Dataset/200_resumes_annotated.json', \"r\") as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "def remove_overlapping_entities(entities):\n",
        "    \"\"\"Remove overlapping entities from the list.\"\"\"\n",
        "    entities = sorted(entities, key=lambda x: x[0])  # Sort by start position\n",
        "    non_overlapping = []\n",
        "    last_end = -1\n",
        "    for start, end, label in entities:\n",
        "        if start >= last_end:  # Only add if there's no overlap with the previous entity\n",
        "            non_overlapping.append((start, end, label))\n",
        "            last_end = end\n",
        "    return non_overlapping\n",
        "\n",
        "# Function to convert JSON data to Spacy's DocBin format\n",
        "def convert_to_spacy_format(data):\n",
        "    nlp = spacy.blank(\"en\")  # Load a blank Spacy model\n",
        "    doc_bin = DocBin()  # Container for our docs\n",
        "\n",
        "    for item in data:\n",
        "        text = item['data']['Text']  # Full document text\n",
        "        entities = []\n",
        "\n",
        "        for annotation in item['annotations'][0]['result']:\n",
        "            start = annotation['value']['start']\n",
        "            end = annotation['value']['end']\n",
        "            label = annotation['value']['labels'][0]  # Entity label\n",
        "            entities.append((start, end, label))\n",
        "\n",
        "        entities = remove_overlapping_entities(entities)  # Remove overlapping entities\n",
        "        # Create a Spacy doc and add entities to it\n",
        "        doc = nlp.make_doc(text)\n",
        "        spans = [doc.char_span(start, end, label=label) for start, end, label in entities]\n",
        "        # Filter out None spans if Spacy can't align the character indices with tokens\n",
        "        spans = [span for span in spans if span is not None]\n",
        "        doc.ents = spans  # Assign entities to the doc\n",
        "        doc_bin.add(doc)\n",
        "\n",
        "    return doc_bin\n",
        "\n",
        "# Split data into train and test sets\n",
        "train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)\n",
        "\n",
        "# Convert train and test sets to Spacy format\n",
        "train_doc_bin = convert_to_spacy_format(train_data)\n",
        "test_doc_bin = convert_to_spacy_format(test_data)\n",
        "\n",
        "# Save the train and test data to .spacy files\n",
        "train_doc_bin.to_disk(\"spacy_ner_data/train_data.spacy\")\n",
        "test_doc_bin.to_disk(\"spacy_ner_data/test_data.spacy\")"
      ],
      "metadata": {
        "id": "R-8QBDX3gtkp"
      },
      "id": "R-8QBDX3gtkp",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Spacy NER"
      ],
      "metadata": {
        "id": "FMM7E6hNCEUv"
      },
      "id": "FMM7E6hNCEUv"
    },
    {
      "cell_type": "code",
      "source": [
        "# create base_config.cfg and paste the config generated from spacy widget\n",
        "# update train and test file path\n",
        "!touch base_config.cfg"
      ],
      "metadata": {
        "id": "ruPln43fCDLm"
      },
      "id": "ruPln43fCDLm",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# generate config.cfg from base_config.cfg\n",
        "!python -m spacy init fill-config base_config.cfg config.cfg"
      ],
      "metadata": {
        "id": "0aRjL9jqC-5k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5489cd43-f730-47d0-ca13-c1ed658d98da"
      },
      "id": "0aRjL9jqC-5k",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[38;5;2m✔ Auto-filled config with all values\u001b[0m\n",
            "\u001b[38;5;2m✔ Saved config\u001b[0m\n",
            "config.cfg\n",
            "You can now add your data and train your pipeline:\n",
            "python -m spacy train config.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download en_core_web_lg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9wb_aBw9X2NU",
        "outputId": "561939c7-f8b1-4038-af0d-ddd3824b3509"
      },
      "id": "9wb_aBw9X2NU",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting en-core-web-lg==3.7.1\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-3.7.1/en_core_web_lg-3.7.1-py3-none-any.whl (587.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m587.7/587.7 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /usr/local/lib/python3.10/dist-packages (from en-core-web-lg==3.7.1) (3.7.5)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.12.5)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (4.66.6)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.9.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (75.1.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (24.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.4.1)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.26.4)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.23.4)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2024.8.30)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (13.9.3)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.20.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (7.0.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.18.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.16.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.1.2)\n",
            "Installing collected packages: en-core-web-lg\n",
            "Successfully installed en-core-web-lg-3.7.1\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_lg')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train model using hyperparameters set in config.cfg\n",
        "# save trained model in spacy-output/ dir\n",
        "!python -m spacy train config.cfg --output ./spacy_output\n",
        "!cp -r ./spacy_output /content/drive/MyDrive/FYP/Implementation/"
      ],
      "metadata": {
        "id": "Jav_l46BEDjF"
      },
      "id": "Jav_l46BEDjF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate trained model performance\n",
        "# store output and visualization into result/ dir\n",
        "!python -m spacy evaluate spacy_output/model-best spacy_ner_data/test_data.spacy -dp spacy_output"
      ],
      "metadata": {
        "id": "V2wzIOsWJgkG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0f701bb-ffdb-4167-f67a-0146a54859ba"
      },
      "id": "V2wzIOsWJgkG",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[38;5;4mℹ Using CPU\u001b[0m\n",
            "\u001b[1m\n",
            "================================== Results ==================================\u001b[0m\n",
            "\n",
            "TOK     100.00\n",
            "NER P   51.12 \n",
            "NER R   41.26 \n",
            "NER F   45.66 \n",
            "SPEED   2395  \n",
            "\n",
            "\u001b[1m\n",
            "=============================== NER (per type) ===============================\u001b[0m\n",
            "\n",
            "                P       R       F\n",
            "NAME        89.66   78.79   83.87\n",
            "JOB         72.00   32.43   44.72\n",
            "DEG         62.16   63.89   63.01\n",
            "UNI         38.89   34.15   36.36\n",
            "EMAIL       63.33   95.00   76.00\n",
            "LOC         39.39   31.71   35.14\n",
            "WORK PER    75.45   83.00   79.05\n",
            "COMPANY     28.42   36.49   31.95\n",
            "SKILL       40.96   28.96   33.93\n",
            "PHONE       89.66   83.87   86.67\n",
            "STUDY PER   65.62   58.33   61.76\n",
            "\n",
            "<IPython.core.display.HTML object>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/spacy/__main__.py\", line 4, in <module>\n",
            "    setup_cli()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/spacy/cli/_util.py\", line 87, in setup_cli\n",
            "    command(prog_name=COMMAND)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/click/core.py\", line 1157, in __call__\n",
            "    return self.main(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/typer/core.py\", line 728, in main\n",
            "    return _main(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/typer/core.py\", line 197, in _main\n",
            "    rv = self.invoke(ctx)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/click/core.py\", line 1688, in invoke\n",
            "    return _process_result(sub_ctx.command.invoke(sub_ctx))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/click/core.py\", line 1434, in invoke\n",
            "    return ctx.invoke(self.callback, **ctx.params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/click/core.py\", line 783, in invoke\n",
            "    return __callback(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/typer/main.py\", line 703, in wrapper\n",
            "    return callback(**use_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/spacy/cli/evaluate.py\", line 47, in evaluate_cli\n",
            "    evaluate(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/spacy/cli/evaluate.py\", line 141, in evaluate\n",
            "    render_parses(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/spacy/cli/evaluate.py\", line 208, in render_parses\n",
            "    file_.write(html)\n",
            "TypeError: write() argument must be str, not None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# make prediction\n",
        "import spacy\n",
        "resume_text = '''\n",
        "John Doe lives at 1234 Elm Street in Los Angeles, CA 90001. He can be reached at +1 (555) 123-4567 or via email at john.doe@example.com. John is a results-driven software engineer with over 5 years of experience in web development and cloud infrastructure, with strong knowledge of JavaScript, Python, and cloud technologies like AWS and Azure. Currently, he works as a Software Engineer at Google LLC in San Francisco, CA, where he has been employed since August 2019. In this role, he has developed scalable web applications using JavaScript, Node.js, and React, deployed and maintained cloud infrastructure on AWS, reducing downtime by 20%, and led a team of 4 engineers to enhance backend performance by 30%. Previously, he worked as a Junior Developer at Tech Innovators Inc. in Austin, TX, from July 2017 to July 2019, where he created RESTful APIs using Python and Flask, collaborated with front-end developers to build and deploy user-facing applications, and wrote unit and integration tests, improving code coverage by 15%.\n",
        "\n",
        "John holds a Master of Science in Computer Science from the University of California, Berkeley, with a graduation date of May 2017, and a Bachelor of Science in Information Technology from the University of Texas at Austin, graduated in May 2015. His skillset includes proficiency in programming languages like Python, JavaScript, and Java; frameworks such as React, Flask, and Django; cloud platforms including AWS, Google Cloud, and Azure; as well as other tools like Git, Docker, Kubernetes, and SQL. He is certified as an AWS Certified Solutions Architect – Associate, earned in 2020, and as a Google Professional Cloud Architect, earned in 2021'\n",
        "'''\n",
        "nlp = spacy.load(\"spacy-output/model-best\")\n",
        "doc = nlp(resume_text.lower())\n",
        "\n",
        "print(doc.ents)\n",
        "\n",
        "for ent in doc.ents:\n",
        "    print(f\"{ent.text}: {ent.label_}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UXAlZZkEeeMc",
        "outputId": "b8cb33e8-de59-4fb2-9c8e-b54180992c00"
      },
      "id": "UXAlZZkEeeMc",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(john doe, in los, (555) 123-4567, john.doe@example.com, john is, aws, restful apis, master of science, bachelor of science in information technology, python, aws, azure, git, docker)\n",
            "john doe: NAME\n",
            "in los: LOC\n",
            "(555) 123-4567: PHONE\n",
            "john.doe@example.com: EMAIL\n",
            "john is: NAME\n",
            "aws: SKILL\n",
            "restful apis: SKILL\n",
            "master of science: DEG\n",
            "bachelor of science in information technology: DEG\n",
            "python: SKILL\n",
            "aws: SKILL\n",
            "azure: SKILL\n",
            "git: SKILL\n",
            "docker: SKILL\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from spacy import displacy\n",
        "displacy.render(doc, style=\"ent\", jupyter=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 507
        },
        "id": "LtxtV7GufiOw",
        "outputId": "670daab7-d8e9-4f21-f231-84c81cb6f23d"
      },
      "id": "LtxtV7GufiOw",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\"><br>\n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    john doe\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NAME</span>\n",
              "</mark>\n",
              " lives at 1234 elm street \n",
              "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    in los\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
              "</mark>\n",
              " angeles, ca 90001. he can be reached at +1 \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    (555) 123-4567\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PHONE</span>\n",
              "</mark>\n",
              " or via email at \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    john.doe@example.com\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">EMAIL</span>\n",
              "</mark>\n",
              ". \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    john is\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NAME</span>\n",
              "</mark>\n",
              " a results-driven software engineer with over 5 years of experience in web development and cloud infrastructure, with strong knowledge of javascript, python, and cloud technologies like \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    aws\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">SKILL</span>\n",
              "</mark>\n",
              " and azure. currently, he works as a software engineer at google llc in san francisco, ca, where he has been employed since august 2019. in this role, he has developed scalable web applications using javascript, node.js, and react, deployed and maintained cloud infrastructure on aws, reducing downtime by 20%, and led a team of 4 engineers to enhance backend performance by 30%. previously, he worked as a junior developer at tech innovators inc. in austin, tx, from july 2017 to july 2019, where he created \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    restful apis\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">SKILL</span>\n",
              "</mark>\n",
              " using python and flask, collaborated with front-end developers to build and deploy user-facing applications, and wrote unit and integration tests, improving code coverage by 15%.<br><br>john holds a \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    master of science\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DEG</span>\n",
              "</mark>\n",
              " in computer science from the university of california, berkeley, with a graduation date of may 2017, and a \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    bachelor of science in information technology\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DEG</span>\n",
              "</mark>\n",
              " from the university of texas at austin, graduated in may 2015. his skillset includes proficiency in programming languages like \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    python\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">SKILL</span>\n",
              "</mark>\n",
              ", javascript, and java; frameworks such as react, flask, and django; cloud platforms including \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    aws\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">SKILL</span>\n",
              "</mark>\n",
              ", google cloud, and \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    azure\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">SKILL</span>\n",
              "</mark>\n",
              "; as well as other tools like \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    git\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">SKILL</span>\n",
              "</mark>\n",
              ", \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    docker\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">SKILL</span>\n",
              "</mark>\n",
              ", kubernetes, and sql. he is certified as an aws certified solutions architect – associate, earned in 2020, and as a google professional cloud architect, earned in 2021'<br></div></span>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Flair NER"
      ],
      "metadata": {
        "id": "1z_niSalE0uT"
      },
      "id": "1z_niSalE0uT"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install flair"
      ],
      "metadata": {
        "id": "lsEUGnPpnjuU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05be38a8-32af-40d9-97e1-7fdb7f35c491"
      },
      "id": "lsEUGnPpnjuU",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: flair in /usr/local/lib/python3.10/dist-packages (0.14.0)\n",
            "Requirement already satisfied: boto3>=1.20.27 in /usr/local/lib/python3.10/dist-packages (from flair) (1.35.54)\n",
            "Requirement already satisfied: conllu<5.0.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from flair) (4.5.3)\n",
            "Requirement already satisfied: deprecated>=1.2.13 in /usr/local/lib/python3.10/dist-packages (from flair) (1.2.14)\n",
            "Requirement already satisfied: ftfy>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from flair) (6.3.1)\n",
            "Requirement already satisfied: gdown>=4.4.0 in /usr/local/lib/python3.10/dist-packages (from flair) (5.2.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from flair) (0.24.7)\n",
            "Requirement already satisfied: langdetect>=1.0.9 in /usr/local/lib/python3.10/dist-packages (from flair) (1.0.9)\n",
            "Requirement already satisfied: lxml>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from flair) (5.3.0)\n",
            "Requirement already satisfied: matplotlib>=2.2.3 in /usr/local/lib/python3.10/dist-packages (from flair) (3.8.0)\n",
            "Requirement already satisfied: more-itertools>=8.13.0 in /usr/local/lib/python3.10/dist-packages (from flair) (10.5.0)\n",
            "Requirement already satisfied: mpld3>=0.3 in /usr/local/lib/python3.10/dist-packages (from flair) (0.5.10)\n",
            "Requirement already satisfied: pptree>=3.1 in /usr/local/lib/python3.10/dist-packages (from flair) (3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from flair) (2.8.2)\n",
            "Requirement already satisfied: pytorch-revgrad>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from flair) (0.2.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from flair) (2024.9.11)\n",
            "Requirement already satisfied: scikit-learn>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from flair) (1.5.2)\n",
            "Requirement already satisfied: segtok>=1.5.11 in /usr/local/lib/python3.10/dist-packages (from flair) (1.5.11)\n",
            "Requirement already satisfied: sqlitedict>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from flair) (2.1.0)\n",
            "Requirement already satisfied: tabulate>=0.8.10 in /usr/local/lib/python3.10/dist-packages (from flair) (0.9.0)\n",
            "Requirement already satisfied: torch!=1.8,>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from flair) (2.5.0+cu121)\n",
            "Requirement already satisfied: tqdm>=4.63.0 in /usr/local/lib/python3.10/dist-packages (from flair) (4.66.6)\n",
            "Requirement already satisfied: transformer-smaller-training-vocab>=0.2.3 in /usr/local/lib/python3.10/dist-packages (from flair) (0.4.0)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.18.0 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]<5.0.0,>=4.18.0->flair) (4.44.2)\n",
            "Requirement already satisfied: wikipedia-api>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from flair) (0.7.1)\n",
            "Requirement already satisfied: semver<4.0.0,>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from flair) (3.0.2)\n",
            "Requirement already satisfied: bioc<3.0.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from flair) (2.1)\n",
            "Requirement already satisfied: jsonlines>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from bioc<3.0.0,>=2.0.0->flair) (4.0.0)\n",
            "Requirement already satisfied: intervaltree in /usr/local/lib/python3.10/dist-packages (from bioc<3.0.0,>=2.0.0->flair) (3.1.0)\n",
            "Requirement already satisfied: docopt in /usr/local/lib/python3.10/dist-packages (from bioc<3.0.0,>=2.0.0->flair) (0.6.2)\n",
            "Requirement already satisfied: botocore<1.36.0,>=1.35.54 in /usr/local/lib/python3.10/dist-packages (from boto3>=1.20.27->flair) (1.35.54)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from boto3>=1.20.27->flair) (1.0.1)\n",
            "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from boto3>=1.20.27->flair) (0.10.3)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from deprecated>=1.2.13->flair) (1.16.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from ftfy>=6.1.0->flair) (0.2.13)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown>=4.4.0->flair) (4.12.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown>=4.4.0->flair) (3.16.1)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown>=4.4.0->flair) (2.32.3)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.10.0->flair) (2024.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.10.0->flair) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.10.0->flair) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.10.0->flair) (4.12.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from langdetect>=1.0.9->flair) (1.16.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.2.3->flair) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.2.3->flair) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.2.3->flair) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.2.3->flair) (1.4.7)\n",
            "Requirement already satisfied: numpy<2,>=1.21 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.2.3->flair) (1.26.4)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.2.3->flair) (10.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.2.3->flair) (3.2.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from mpld3>=0.3->flair) (3.1.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.2->flair) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.2->flair) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.2->flair) (3.5.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch!=1.8,>=1.5.0->flair) (3.4.2)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch!=1.8,>=1.5.0->flair) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch!=1.8,>=1.5.0->flair) (1.3.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.18.0->transformers[sentencepiece]<5.0.0,>=4.18.0->flair) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.18.0->transformers[sentencepiece]<5.0.0,>=4.18.0->flair) (0.19.1)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]<5.0.0,>=4.18.0->flair) (3.20.3)\n",
            "Requirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]<5.0.0,>=4.18.0->flair) (0.2.0)\n",
            "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /usr/local/lib/python3.10/dist-packages (from botocore<1.36.0,>=1.35.54->boto3>=1.20.27->flair) (2.2.3)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonlines>=1.2.0->bioc<3.0.0,>=2.0.0->flair) (24.2.0)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece,torch]<5.0,>=4.1->transformer-smaller-training-vocab>=0.2.3->flair) (0.34.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown>=4.4.0->flair) (2.6)\n",
            "Requirement already satisfied: sortedcontainers<3.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from intervaltree->bioc<3.0.0,>=2.0.0->flair) (2.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->mpld3>=0.3->flair) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown>=4.4.0->flair) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown>=4.4.0->flair) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown>=4.4.0->flair) (2024.8.30)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown>=4.4.0->flair) (1.7.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.21.0->transformers[sentencepiece,torch]<5.0,>=4.1->transformer-smaller-training-vocab>=0.2.3->flair) (5.9.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# convert spacy data into flair data\n",
        "import spacy\n",
        "from spacy.tokens import DocBin\n",
        "import os\n",
        "\n",
        "def convert_spacy_to_flair(input_file, output_file):\n",
        "    \"\"\"\n",
        "    Convert SpaCy binary format to Flair's CoNLL format.\n",
        "\n",
        "    Args:\n",
        "        input_file (str): Path to SpaCy binary file (.spacy)\n",
        "        output_file (str): Path to output file for Flair format\n",
        "    \"\"\"\n",
        "    # Load spaCy model\n",
        "    nlp = spacy.blank(\"en\")\n",
        "\n",
        "    # Load the DocBin\n",
        "    doc_bin = DocBin().from_disk(input_file)\n",
        "    docs = list(doc_bin.get_docs(nlp.vocab))\n",
        "\n",
        "    with open(output_file, 'w', encoding='utf-8') as f:\n",
        "        for doc in docs:\n",
        "            tokens = [(t.text, t.ent_iob_, t.ent_type_) for t in doc]\n",
        "\n",
        "            # Write tokens in CoNLL format\n",
        "            for token in tokens:\n",
        "                text, iob, ent_type = token\n",
        "\n",
        "                # Convert spaCy IOB to CoNLL format\n",
        "                if iob == 'O':\n",
        "                    tag = 'O'\n",
        "                else:\n",
        "                    tag = f'{iob}-{ent_type}' if ent_type else 'O'\n",
        "\n",
        "                # Write line: token and NER tag\n",
        "                f.write(f'{text} {tag}\\n')\n",
        "\n",
        "            # Empty line between sentences\n",
        "            f.write('\\n')\n",
        "\n",
        "def convert_spacy_json_to_flair(input_file, output_file):\n",
        "    \"\"\"\n",
        "    Convert SpaCy JSON format to Flair's CoNLL format.\n",
        "\n",
        "    Args:\n",
        "        input_file (str): Path to JSON file with SpaCy annotations\n",
        "        output_file (str): Path to output file for Flair format\n",
        "    \"\"\"\n",
        "    import json\n",
        "\n",
        "    nlp = spacy.blank(\"en\")\n",
        "\n",
        "    with open(input_file, 'r', encoding='utf-8') as f:\n",
        "        training_data = json.load(f)\n",
        "\n",
        "    with open(output_file, 'w', encoding='utf-8') as f:\n",
        "        for example in training_data:\n",
        "            text = example['text']\n",
        "            ents = example.get('entities', [])\n",
        "\n",
        "            # Create a spaCy doc\n",
        "            doc = nlp(text)\n",
        "\n",
        "            # Add entities to doc\n",
        "            spans = []\n",
        "            for start, end, label in ents:\n",
        "                span = doc.char_span(start, end, label=label)\n",
        "                if span is not None:\n",
        "                    spans.append(span)\n",
        "            doc.ents = spans\n",
        "\n",
        "            # Convert to CoNLL format\n",
        "            tokens = [(t.text, t.ent_iob_, t.ent_type_) for t in doc]\n",
        "\n",
        "            for token in tokens:\n",
        "                text, iob, ent_type = token\n",
        "                if iob == 'O':\n",
        "                    tag = 'O'\n",
        "                else:\n",
        "                    tag = f'{iob}-{ent_type}' if ent_type else 'O'\n",
        "                f.write(f'{text} {tag}\\n')\n",
        "\n",
        "            f.write('\\n')\n",
        "\n",
        "# Example usage for JSON format\n",
        "flair_train_json = \"flair_train.txt\"\n",
        "flair_test_json = \"flair_test.txt\"\n",
        "\n",
        "convert_spacy_to_flair('/content/spacy_ner_data/train_data.spacy', flair_train_json)\n",
        "convert_spacy_to_flair('/content/spacy_ner_data/test_data.spacy', flair_test_json)"
      ],
      "metadata": {
        "id": "8SgkTXeIiTtF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "outputId": "543851d7-3af2-43f5-e1a2-36030cdc0bf9"
      },
      "id": "8SgkTXeIiTtF",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/spacy_ner_data/train_data.spacy'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-fa51b6171dc5>\u001b[0m in \u001b[0;36m<cell line: 89>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0mflair_test_json\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"flair_test.txt\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m \u001b[0mconvert_spacy_to_flair\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/spacy_ner_data/train_data.spacy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflair_train_json\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0mconvert_spacy_to_flair\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/spacy_ner_data/test_data.spacy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflair_test_json\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-1-fa51b6171dc5>\u001b[0m in \u001b[0;36mconvert_spacy_to_flair\u001b[0;34m(input_file, output_file)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;31m# Load the DocBin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mdoc_bin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDocBin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_disk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0mdocs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc_bin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_docs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/spacy/tokens/_serialize.py\u001b[0m in \u001b[0;36mfrom_disk\u001b[0;34m(self, path)\u001b[0m\n\u001b[1;32m    273\u001b[0m         \"\"\"\n\u001b[1;32m    274\u001b[0m         \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    276\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/pathlib.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, mode, buffering, encoding, errors, newline)\u001b[0m\n\u001b[1;32m   1117\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1118\u001b[0m             \u001b[0mencoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext_encoding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1119\u001b[0;31m         return self._accessor.open(self, mode, buffering, encoding, errors,\n\u001b[0m\u001b[1;32m   1120\u001b[0m                                    newline)\n\u001b[1;32m   1121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/spacy_ner_data/train_data.spacy'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# convert spacy data into flair data\n",
        "import spacy\n",
        "from spacy.training import Corpus\n",
        "\n",
        "!python -m spacy download de_core_news_sm\n",
        "nlp = spacy.load(\"de_core_news_sm\")\n",
        "corpus = Corpus(\"/content/spacy_ner_data/test_data.spacy\")\n",
        "\n",
        "data = corpus(nlp)\n",
        "\n",
        "# Flair supports BIO and BIOES, see https://github.com/flairNLP/flair/issues/875\n",
        "def rename_biluo_to_bioes(old_tag):\n",
        "    new_tag = \"\"\n",
        "    try:\n",
        "        if old_tag.startswith(\"L\"):\n",
        "            new_tag = \"E\" + old_tag[1:]\n",
        "        elif old_tag.startswith(\"U\"):\n",
        "            new_tag = \"S\" + old_tag[1:]\n",
        "        else:\n",
        "            new_tag = old_tag\n",
        "    except:\n",
        "        pass\n",
        "    return new_tag\n",
        "\n",
        "\n",
        "def generate_corpus():\n",
        "    corpus = []\n",
        "    n_ex = 0\n",
        "    for example in data:\n",
        "        n_ex += 1\n",
        "        text = example.text\n",
        "        doc = nlp(text)\n",
        "        tags = example.get_aligned_ner()\n",
        "        # Check if it's an empty list of NER tags.\n",
        "        if None in tags:\n",
        "            pass\n",
        "        else:\n",
        "            new_tags = [rename_biluo_to_bioes(tag) for tag in tags]\n",
        "            for token, tag in zip(doc,new_tags):\n",
        "                row = token.text +' '+ token.pos_ +' ' +tag + '\\n'\n",
        "                corpus.append(row)\n",
        "            corpus.append('\\n')\n",
        "    return corpus\n",
        "\n",
        "def write_file(filepath):\n",
        "    with open(filepath, 'w', encoding='utf-8') as f:\n",
        "        corpus = generate_corpus()\n",
        "        f.writelines(corpus)\n",
        "\n",
        "def main():\n",
        "    write_file('flair_test.txt')\n",
        "\n",
        "main()"
      ],
      "metadata": {
        "id": "TbHBmnUyv65f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be6d42bd-f6a2-4143-b278-f010c011ae8f"
      },
      "id": "TbHBmnUyv65f",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting de-core-news-sm==3.7.0\n",
            "  Using cached https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-3.7.0/de_core_news_sm-3.7.0-py3-none-any.whl (14.6 MB)\n",
            "Requirement already satisfied: spacy<3.8.0,>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from de-core-news-sm==3.7.0) (3.7.5)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.12.5)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (4.66.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.9.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (75.1.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (24.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.4.1)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.26.4)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.23.4)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2024.8.30)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (13.9.3)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.20.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (7.0.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.18.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.16.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.1.2)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('de_core_news_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# convert json into flair data\n",
        "import json\n",
        "import random\n",
        "from typing import List, Dict, Tuple\n",
        "import spacy\n",
        "from collections import defaultdict\n",
        "\n",
        "class NERConverter:\n",
        "    def __init__(self):\n",
        "        self.nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "    def get_bioes_label(self, token_index: int, entity_length: int, current_position: int, label: str) -> str:\n",
        "        \"\"\"\n",
        "        Convert to BIOES format\n",
        "        - S-: Single token entity\n",
        "        - B-: Beginning of multi-token entity\n",
        "        - I-: Inside of multi-token entity\n",
        "        - E-: End of multi-token entity\n",
        "        - O: Outside\n",
        "        \"\"\"\n",
        "        if entity_length == 1:\n",
        "            return f'S-{label}'\n",
        "        if current_position == 0:\n",
        "            return f'B-{label}'\n",
        "        if current_position == entity_length - 1:\n",
        "            return f'E-{label}'\n",
        "        return f'I-{label}'\n",
        "\n",
        "    def convert_to_bioes_format(self, json_data: List[dict]) -> List[List[Tuple[str, str]]]:\n",
        "        \"\"\"Convert JSON annotations to BIOES format.\"\"\"\n",
        "        all_sentences = []\n",
        "\n",
        "        for item in json_data:\n",
        "            text = item['data']['Text']\n",
        "            doc = self.nlp(text)\n",
        "\n",
        "            # Initialize character-level labels\n",
        "            char_labels = ['O'] * len(text)\n",
        "\n",
        "            # First pass: identify entity boundaries and lengths\n",
        "            entity_spans = []\n",
        "            if item['annotations'] and len(item['annotations']) > 0:\n",
        "                for ann in item['annotations'][0]['result']:\n",
        "                    if 'value' in ann:\n",
        "                        start = ann['value']['start']\n",
        "                        end = ann['value']['end']\n",
        "                        label = ann['value']['labels'][0]\n",
        "                        entity_spans.append((start, end, label))\n",
        "\n",
        "            # Sort spans by start position\n",
        "            entity_spans.sort(key=lambda x: x[0])\n",
        "\n",
        "            # Second pass: apply BIOES labels\n",
        "            for start, end, label in entity_spans:\n",
        "                # Get tokens that are part of this entity\n",
        "                entity_text = text[start:end]\n",
        "                entity_doc = self.nlp(entity_text)\n",
        "                entity_length = len([token for token in entity_doc if not token.is_space])\n",
        "\n",
        "                # Set labels for the entire span\n",
        "                current_token_idx = 0\n",
        "                for i in range(start, end):\n",
        "                    if i == start or text[i-1].isspace():\n",
        "                        char_labels[i] = self.get_bioes_label(i, entity_length, current_token_idx, label)\n",
        "                        current_token_idx += 1\n",
        "                    else:\n",
        "                        char_labels[i] = char_labels[i-1]\n",
        "\n",
        "            # Convert to token-level labels\n",
        "            current_sentence = []\n",
        "            for sent in doc.sents:\n",
        "                for token in sent:\n",
        "                    # Get the most common label for the token's characters\n",
        "                    token_chars_labels = char_labels[token.idx:token.idx + len(token.text)]\n",
        "                    label_counts = defaultdict(int)\n",
        "                    for char_label in token_chars_labels:\n",
        "                        label_counts[char_label] += 1\n",
        "\n",
        "                    token_label = max(label_counts.items(), key=lambda x: x[1])[0]\n",
        "                    current_sentence.append((token.text, token_label))\n",
        "\n",
        "                if current_sentence:\n",
        "                    all_sentences.append(current_sentence)\n",
        "                    current_sentence = []\n",
        "\n",
        "        return all_sentences\n",
        "\n",
        "    def write_flair_file(self, sentences: List[List[Tuple[str, str]]], filename: str):\n",
        "        \"\"\"Write sentences in BIOES format to file.\"\"\"\n",
        "        with open(filename, 'w', encoding='utf-8') as f:\n",
        "            for sentence in sentences:\n",
        "                for token, label in sentence:\n",
        "                    f.write(f'{token} {label}\\n')\n",
        "                f.write('\\n')\n",
        "\n",
        "    def convert_and_split(self, json_data: List[dict], train_file: str, test_file: str, test_ratio: float = 0.2):\n",
        "        \"\"\"Convert JSON to BIOES format and split into train/test sets.\"\"\"\n",
        "        all_sentences = self.convert_to_bioes_format(json_data)\n",
        "\n",
        "        # Shuffle and split\n",
        "        random.shuffle(all_sentences)\n",
        "        split_idx = int(len(all_sentences) * (1 - test_ratio))\n",
        "\n",
        "        train_sentences = all_sentences[:split_idx]\n",
        "        test_sentences = all_sentences[split_idx:]\n",
        "\n",
        "        # Write to files\n",
        "        self.write_flair_file(train_sentences, train_file)\n",
        "        self.write_flair_file(test_sentences, test_file)\n",
        "\n",
        "        return len(train_sentences), len(test_sentences)\n",
        "\n",
        "def main():\n",
        "    # Load JSON data\n",
        "    with open('/content/drive/MyDrive/FYP/Implementation/Resume Dataset/200_resumes_annotated.json', 'r', encoding='utf-8') as f:\n",
        "        json_data = json.load(f)\n",
        "\n",
        "    # Convert and split data\n",
        "    converter = NERConverter()\n",
        "    train_count, test_count = converter.convert_and_split(\n",
        "        json_data,\n",
        "        train_file='flair_train.txt',\n",
        "        test_file='flair_test.txt',\n",
        "        test_ratio=0.2\n",
        "    )\n",
        "\n",
        "    print(f'Created {train_count} training sentences and {test_count} test sentences')\n",
        "\n",
        "main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JYAkAghgs9k5",
        "outputId": "25261181-194a-456f-cd79-ba164f104300"
      },
      "id": "JYAkAghgs9k5",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created 298 training sentences and 75 test sentences\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from flair.data import Corpus\n",
        "from flair.datasets import ColumnCorpus\n",
        "\n",
        "# Define columns for CoNLL (0: word, 1: label)\n",
        "columns = {0: 'text', 1: 'ner'}\n",
        "\n",
        "# Set data folder and file names\n",
        "data_folder = './'\n",
        "train_file = 'flair_train.txt'\n",
        "test_file = 'flair_test.txt'\n",
        "\n",
        "# Load the corpus\n",
        "corpus: Corpus = ColumnCorpus(data_folder, columns,\n",
        "                              train_file=train_file,\n",
        "                              test_file=test_file,\n",
        "                              dev_file=None)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vl2-GpGBjpsi",
        "outputId": "772fd2ba-d8ce-41b7-eb93-2b6e45c19e44"
      },
      "id": "vl2-GpGBjpsi",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-11-05 13:38:01,680 Reading data from .\n",
            "2024-11-05 13:38:01,681 Train: flair_train.txt\n",
            "2024-11-05 13:38:01,682 Dev: None\n",
            "2024-11-05 13:38:01,683 Test: flair_test.txt\n",
            "2024-11-05 13:38:03,442 No dev split found. Using 10% (i.e. 30 samples) of the train split as dev data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tag_dictionary = corpus.make_label_dictionary(label_type='ner')\n",
        "print(\"Labels:\", tag_dictionary.get_items())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d_skLRc8i44m",
        "outputId": "ec18dd18-8754-4b21-924d-14957db782aa"
      },
      "id": "d_skLRc8i44m",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-11-05 13:38:06,787 Computing label dictionary. Progress:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "0it [00:00, ?it/s]\n",
            "268it [00:00, 8924.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-11-05 13:38:06,830 Dictionary created for label 'ner' with 11 values: SKILL (seen 2126 times), JOB (seen 531 times), WORK (seen 459 times), COMPANY (seen 366 times), LOC (seen 219 times), DEG (seen 149 times), UNI (seen 148 times), PHONE (seen 140 times), NAME (seen 139 times), STUDY (seen 135 times), EMAIL (seen 110 times)\n",
            "Labels: ['SKILL', 'JOB', 'WORK', 'COMPANY', 'LOC', 'DEG', 'UNI', 'PHONE', 'NAME', 'STUDY', 'EMAIL']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "def count_labels(file_path):\n",
        "    with open(file_path, 'r') as file:\n",
        "        labels = [line.split()[-1] for line in file if line.strip()]\n",
        "    return Counter(labels)\n",
        "\n",
        "print(\"Train label distribution:\", count_labels('flair_train.txt'))\n",
        "print(\"Test label distribution:\", count_labels('flair_test.txt'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j5cXWOiGY5an",
        "outputId": "6686f639-1900-45d9-bb23-d79911dd9158"
      },
      "id": "j5cXWOiGY5an",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train label distribution: Counter({'O': 68953, 'S-SKILL': 1459, 'PER': 1196, 'B-SKILL': 988, 'E-SKILL': 984, 'E-JOB': 516, 'B-JOB': 505, 'E-COMPANY': 333, 'B-COMPANY': 330, 'I-JOB': 266, 'I-DEG': 262, 'I-COMPANY': 240, 'I-SKILL': 192, 'E-UNI': 166, 'B-UNI': 165, 'B-DEG': 159, 'E-DEG': 159, 'B-NAME': 154, 'E-NAME': 154, 'S-LOC': 149, 'E-PHONE': 129, 'B-PHONE': 127, 'I-UNI': 125, 'S-EMAIL': 117, 'B-LOC': 97, 'E-LOC': 97, 'I-PHONE': 83, 'S-JOB': 64, 'S-COMPANY': 61, 'S-PHONE': 21, 'I-NAME': 8, 'S-DEG': 5, 'I-LOC': 3, 'S-UNI': 2})\n",
            "Test label distribution: Counter({'O': 20140, 'S-SKILL': 332, 'PER': 315, 'B-SKILL': 225, 'E-SKILL': 225, 'E-JOB': 143, 'B-JOB': 142, 'E-COMPANY': 94, 'B-COMPANY': 92, 'I-JOB': 91, 'I-COMPANY': 75, 'I-DEG': 72, 'S-LOC': 56, 'B-UNI': 49, 'E-UNI': 49, 'I-UNI': 46, 'I-SKILL': 44, 'E-DEG': 43, 'B-DEG': 42, 'B-NAME': 37, 'E-NAME': 37, 'B-LOC': 31, 'E-LOC': 31, 'S-EMAIL': 31, 'B-PHONE': 28, 'E-PHONE': 28, 'I-PHONE': 23, 'S-COMPANY': 18, 'S-JOB': 11, 'S-PHONE': 8, 'I-LOC': 2, 'S-DEG': 2, 'I-NAME': 2, 'B-EMAIL': 1, 'E-EMAIL': 1})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create NER tagger\n",
        "from flair.embeddings import WordEmbeddings, StackedEmbeddings, TransformerWordEmbeddings, FlairEmbeddings\n",
        "from flair.models import SequenceTagger\n",
        "\n",
        "# using LSTM-CRF on top of frozen embeddings\n",
        "# combine flair and glove embeddings\n",
        "# embeddings = StackedEmbeddings([\n",
        "#                 WordEmbeddings('glove'),\n",
        "#                 FlairEmbeddings('news-forward'),\n",
        "#                 FlairEmbeddings('news-backward'),\n",
        "#             ])\n",
        "# tagger = SequenceTagger(hidden_size=256,\n",
        "#                          embeddings=embeddings,\n",
        "#                          tag_dictionary=tag_dictionary,\n",
        "#                          tag_type='ner',\n",
        "#                          use_crf=True,\n",
        "#                          tag_format = 'BIOES')\n",
        "\n",
        "# using transformer embedding\n",
        "# embeddings = TransformerWordEmbeddings('bert-base-uncased',\n",
        "#                                       fine_tune=True,\n",
        "#                                       layers='-1',\n",
        "#                                       subtoken_pooling='first')\n",
        "embeddings = TransformerWordEmbeddings(\n",
        "    'roberta-base',  # or 'bert-base-uncased'\n",
        "    fine_tune=True,\n",
        "    layers='-1,-2,-3,-4',  # Use last 4 layers\n",
        "    subtoken_pooling='first',\n",
        "    allow_long_sentences=True\n",
        ")\n",
        "tagger = SequenceTagger(hidden_size=256,\n",
        "                         embeddings=embeddings,\n",
        "                         tag_dictionary=tag_dictionary,\n",
        "                         tag_type='ner',\n",
        "                         use_crf=False,\n",
        "                         use_rnn=False,\n",
        "                         reproject_embeddings=False,\n",
        "                         tag_format = 'BIOES')"
      ],
      "metadata": {
        "id": "QEBUKmiAnaFm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22f1f124-7f70-4475-a3aa-bd76c07f9fb2"
      },
      "id": "QEBUKmiAnaFm",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-11-05 13:38:16,558 SequenceTagger predicts: Dictionary with 45 tags: O, S-SKILL, B-SKILL, E-SKILL, I-SKILL, S-JOB, B-JOB, E-JOB, I-JOB, S-WORK, B-WORK, E-WORK, I-WORK, S-COMPANY, B-COMPANY, E-COMPANY, I-COMPANY, S-LOC, B-LOC, E-LOC, I-LOC, S-DEG, B-DEG, E-DEG, I-DEG, S-UNI, B-UNI, E-UNI, I-UNI, S-PHONE, B-PHONE, E-PHONE, I-PHONE, S-NAME, B-NAME, E-NAME, I-NAME, S-STUDY, B-STUDY, E-STUDY, I-STUDY, S-EMAIL, B-EMAIL, E-EMAIL, I-EMAIL\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train flair ner model\n",
        "from flair.trainers import ModelTrainer\n",
        "from flair.training_utils import EvaluationMetric\n",
        "\n",
        "trainer = ModelTrainer(tagger, corpus)\n",
        "\n",
        "trainer.train(\n",
        "    base_path='flair_output/',\n",
        "    learning_rate=0.01,\n",
        "    mini_batch_size=8,\n",
        "    max_epochs=10,\n",
        "    train_with_dev=False\n",
        ")\n",
        "!cp -r ./flair_output /content/drive/MyDrive/FYP/Implementation/"
      ],
      "metadata": {
        "id": "XbuJ4VjCnoPU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31c2cc7c-b706-47fe-a1ab-54700766db07"
      },
      "id": "XbuJ4VjCnoPU",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-11-05 13:38:20,474 ----------------------------------------------------------------------------------------------------\n",
            "2024-11-05 13:38:20,478 Model: \"SequenceTagger(\n",
            "  (embeddings): TransformerWordEmbeddings(\n",
            "    (model): RobertaModel(\n",
            "      (embeddings): RobertaEmbeddings(\n",
            "        (word_embeddings): Embedding(50266, 768, padding_idx=1)\n",
            "        (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
            "        (token_type_embeddings): Embedding(1, 768)\n",
            "        (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (encoder): RobertaEncoder(\n",
            "        (layer): ModuleList(\n",
            "          (0-11): 12 x RobertaLayer(\n",
            "            (attention): RobertaAttention(\n",
            "              (self): RobertaSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): RobertaSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): RobertaIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (intermediate_act_fn): GELUActivation()\n",
            "            )\n",
            "            (output): RobertaOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (pooler): RobertaPooler(\n",
            "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (activation): Tanh()\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (locked_dropout): LockedDropout(p=0.5)\n",
            "  (linear): Linear(in_features=768, out_features=45, bias=True)\n",
            "  (loss_function): CrossEntropyLoss()\n",
            ")\"\n",
            "2024-11-05 13:38:20,479 ----------------------------------------------------------------------------------------------------\n",
            "2024-11-05 13:38:20,481 Corpus: 268 train + 30 dev + 75 test sentences\n",
            "2024-11-05 13:38:20,483 ----------------------------------------------------------------------------------------------------\n",
            "2024-11-05 13:38:20,484 Train:  268 sentences\n",
            "2024-11-05 13:38:20,486         (train_with_dev=False, train_with_test=False)\n",
            "2024-11-05 13:38:20,488 ----------------------------------------------------------------------------------------------------\n",
            "2024-11-05 13:38:20,488 Training Params:\n",
            "2024-11-05 13:38:20,489  - learning_rate: \"0.01\" \n",
            "2024-11-05 13:38:20,490  - mini_batch_size: \"8\"\n",
            "2024-11-05 13:38:20,491  - max_epochs: \"10\"\n",
            "2024-11-05 13:38:20,492  - shuffle: \"True\"\n",
            "2024-11-05 13:38:20,493 ----------------------------------------------------------------------------------------------------\n",
            "2024-11-05 13:38:20,494 Plugins:\n",
            "2024-11-05 13:38:20,495  - AnnealOnPlateau | patience: '3', anneal_factor: '0.5', min_learning_rate: '0.0001'\n",
            "2024-11-05 13:38:20,496 ----------------------------------------------------------------------------------------------------\n",
            "2024-11-05 13:38:20,497 Final evaluation on model from best epoch (best-model.pt)\n",
            "2024-11-05 13:38:20,498  - metric: \"('micro avg', 'f1-score')\"\n",
            "2024-11-05 13:38:20,498 ----------------------------------------------------------------------------------------------------\n",
            "2024-11-05 13:38:20,499 Computation:\n",
            "2024-11-05 13:38:20,500  - compute on device: cuda:0\n",
            "2024-11-05 13:38:20,501  - embedding storage: cpu\n",
            "2024-11-05 13:38:20,502 ----------------------------------------------------------------------------------------------------\n",
            "2024-11-05 13:38:20,503 Model training base path: \"flair_output\"\n",
            "2024-11-05 13:38:20,504 ----------------------------------------------------------------------------------------------------\n",
            "2024-11-05 13:38:20,505 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/flair/trainers/trainer.py:499: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler(enabled=use_amp and flair.device.type != \"cpu\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-11-05 13:38:23,854 epoch 1 - iter 3/34 - loss 3.19380148 - time (sec): 3.35 - samples/sec: 1918.33 - lr: 0.010000 - momentum: 0.000000\n",
            "2024-11-05 13:38:26,720 epoch 1 - iter 6/34 - loss 2.25984259 - time (sec): 6.21 - samples/sec: 2176.78 - lr: 0.010000 - momentum: 0.000000\n",
            "2024-11-05 13:38:29,390 epoch 1 - iter 9/34 - loss 1.90338231 - time (sec): 8.88 - samples/sec: 2113.57 - lr: 0.010000 - momentum: 0.000000\n",
            "2024-11-05 13:38:32,516 epoch 1 - iter 12/34 - loss 1.62646625 - time (sec): 12.01 - samples/sec: 2066.89 - lr: 0.010000 - momentum: 0.000000\n",
            "2024-11-05 13:38:34,747 epoch 1 - iter 15/34 - loss 1.46863888 - time (sec): 14.24 - samples/sec: 2198.24 - lr: 0.010000 - momentum: 0.000000\n",
            "2024-11-05 13:38:36,943 epoch 1 - iter 18/34 - loss 1.40264662 - time (sec): 16.44 - samples/sec: 2188.44 - lr: 0.010000 - momentum: 0.000000\n",
            "2024-11-05 13:38:39,428 epoch 1 - iter 21/34 - loss 1.30960729 - time (sec): 18.92 - samples/sec: 2214.76 - lr: 0.010000 - momentum: 0.000000\n",
            "2024-11-05 13:38:42,621 epoch 1 - iter 24/34 - loss 1.23445469 - time (sec): 22.11 - samples/sec: 2214.81 - lr: 0.010000 - momentum: 0.000000\n",
            "2024-11-05 13:38:45,590 epoch 1 - iter 27/34 - loss 1.18402187 - time (sec): 25.08 - samples/sec: 2233.79 - lr: 0.010000 - momentum: 0.000000\n",
            "2024-11-05 13:38:48,568 epoch 1 - iter 30/34 - loss 1.12599779 - time (sec): 28.06 - samples/sec: 2248.69 - lr: 0.010000 - momentum: 0.000000\n",
            "2024-11-05 13:38:51,826 epoch 1 - iter 33/34 - loss 1.08809983 - time (sec): 31.32 - samples/sec: 2217.11 - lr: 0.010000 - momentum: 0.000000\n",
            "2024-11-05 13:38:52,662 ----------------------------------------------------------------------------------------------------\n",
            "2024-11-05 13:38:52,668 EPOCH 1 done: loss 1.0760 - lr: 0.010000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:01<00:00,  1.93s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-11-05 13:38:54,624 DEV : loss 0.742318332195282 - f1-score (micro avg)  0.0\n",
            "2024-11-05 13:38:54,637  - 0 epochs without improvement\n",
            "2024-11-05 13:38:54,639 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-11-05 13:38:57,326 epoch 2 - iter 3/34 - loss 0.69149655 - time (sec): 2.68 - samples/sec: 2760.32 - lr: 0.010000 - momentum: 0.000000\n",
            "2024-11-05 13:39:00,279 epoch 2 - iter 6/34 - loss 0.67648150 - time (sec): 5.64 - samples/sec: 2382.85 - lr: 0.010000 - momentum: 0.000000\n",
            "2024-11-05 13:39:03,483 epoch 2 - iter 9/34 - loss 0.66847266 - time (sec): 8.84 - samples/sec: 2335.99 - lr: 0.010000 - momentum: 0.000000\n",
            "2024-11-05 13:39:06,161 epoch 2 - iter 12/34 - loss 0.70853672 - time (sec): 11.52 - samples/sec: 2266.92 - lr: 0.010000 - momentum: 0.000000\n",
            "2024-11-05 13:39:08,936 epoch 2 - iter 15/34 - loss 0.70680952 - time (sec): 14.29 - samples/sec: 2237.01 - lr: 0.010000 - momentum: 0.000000\n",
            "2024-11-05 13:39:11,402 epoch 2 - iter 18/34 - loss 0.71473979 - time (sec): 16.76 - samples/sec: 2201.14 - lr: 0.010000 - momentum: 0.000000\n",
            "2024-11-05 13:39:14,516 epoch 2 - iter 21/34 - loss 0.71097567 - time (sec): 19.87 - samples/sec: 2216.23 - lr: 0.010000 - momentum: 0.000000\n",
            "2024-11-05 13:39:16,984 epoch 2 - iter 24/34 - loss 0.71747325 - time (sec): 22.34 - samples/sec: 2250.87 - lr: 0.010000 - momentum: 0.000000\n",
            "2024-11-05 13:39:19,932 epoch 2 - iter 27/34 - loss 0.70710541 - time (sec): 25.29 - samples/sec: 2259.19 - lr: 0.010000 - momentum: 0.000000\n",
            "2024-11-05 13:39:23,184 epoch 2 - iter 30/34 - loss 0.70829328 - time (sec): 28.54 - samples/sec: 2258.78 - lr: 0.010000 - momentum: 0.000000\n",
            "2024-11-05 13:39:25,953 epoch 2 - iter 33/34 - loss 0.70737098 - time (sec): 31.31 - samples/sec: 2237.20 - lr: 0.010000 - momentum: 0.000000\n",
            "2024-11-05 13:39:26,514 ----------------------------------------------------------------------------------------------------\n",
            "2024-11-05 13:39:26,522 EPOCH 2 done: loss 0.7082 - lr: 0.010000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:02<00:00,  2.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-11-05 13:39:28,918 DEV : loss 0.7119558453559875 - f1-score (micro avg)  0.0\n",
            "2024-11-05 13:39:28,932  - 0 epochs without improvement\n",
            "2024-11-05 13:39:28,933 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-11-05 13:39:31,293 epoch 3 - iter 3/34 - loss 0.73565270 - time (sec): 2.36 - samples/sec: 2247.07 - lr: 0.010000 - momentum: 0.000000\n",
            "2024-11-05 13:39:34,260 epoch 3 - iter 6/34 - loss 0.75636115 - time (sec): 5.32 - samples/sec: 2448.78 - lr: 0.010000 - momentum: 0.000000\n",
            "2024-11-05 13:39:37,104 epoch 3 - iter 9/34 - loss 0.73262729 - time (sec): 8.17 - samples/sec: 2259.30 - lr: 0.010000 - momentum: 0.000000\n",
            "2024-11-05 13:39:40,673 epoch 3 - iter 12/34 - loss 0.68718236 - time (sec): 11.74 - samples/sec: 2250.65 - lr: 0.010000 - momentum: 0.000000\n",
            "2024-11-05 13:39:43,746 epoch 3 - iter 15/34 - loss 0.65712264 - time (sec): 14.81 - samples/sec: 2231.33 - lr: 0.010000 - momentum: 0.000000\n",
            "2024-11-05 13:39:46,953 epoch 3 - iter 18/34 - loss 0.65909184 - time (sec): 18.02 - samples/sec: 2197.97 - lr: 0.010000 - momentum: 0.000000\n",
            "2024-11-05 13:39:50,075 epoch 3 - iter 21/34 - loss 0.66672197 - time (sec): 21.14 - samples/sec: 2145.36 - lr: 0.010000 - momentum: 0.000000\n",
            "2024-11-05 13:39:53,607 epoch 3 - iter 24/34 - loss 0.64591905 - time (sec): 24.67 - samples/sec: 2182.31 - lr: 0.010000 - momentum: 0.000000\n",
            "2024-11-05 13:39:55,979 epoch 3 - iter 27/34 - loss 0.66135994 - time (sec): 27.04 - samples/sec: 2200.75 - lr: 0.010000 - momentum: 0.000000\n",
            "2024-11-05 13:39:58,436 epoch 3 - iter 30/34 - loss 0.65935560 - time (sec): 29.50 - samples/sec: 2201.65 - lr: 0.010000 - momentum: 0.000000\n",
            "2024-11-05 13:40:01,092 epoch 3 - iter 33/34 - loss 0.66520716 - time (sec): 32.15 - samples/sec: 2165.39 - lr: 0.010000 - momentum: 0.000000\n",
            "2024-11-05 13:40:01,730 ----------------------------------------------------------------------------------------------------\n",
            "2024-11-05 13:40:01,731 EPOCH 3 done: loss 0.6625 - lr: 0.010000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:02<00:00,  2.32s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-11-05 13:40:04,088 DEV : loss 0.733296811580658 - f1-score (micro avg)  0.0\n",
            "2024-11-05 13:40:04,103  - 1 epochs without improvement\n",
            "2024-11-05 13:40:04,105 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-11-05 13:40:06,805 epoch 4 - iter 3/34 - loss 0.54227865 - time (sec): 2.70 - samples/sec: 2550.23 - lr: 0.010000 - momentum: 0.000000\n",
            "2024-11-05 13:40:10,190 epoch 4 - iter 6/34 - loss 0.52266717 - time (sec): 6.08 - samples/sec: 2322.08 - lr: 0.010000 - momentum: 0.000000\n",
            "2024-11-05 13:40:13,491 epoch 4 - iter 9/34 - loss 0.54864343 - time (sec): 9.38 - samples/sec: 2320.81 - lr: 0.010000 - momentum: 0.000000\n",
            "2024-11-05 13:40:16,836 epoch 4 - iter 12/34 - loss 0.56441502 - time (sec): 12.73 - samples/sec: 2279.38 - lr: 0.010000 - momentum: 0.000000\n",
            "2024-11-05 13:40:19,572 epoch 4 - iter 15/34 - loss 0.59789616 - time (sec): 15.46 - samples/sec: 2210.44 - lr: 0.010000 - momentum: 0.000000\n",
            "2024-11-05 13:40:22,019 epoch 4 - iter 18/34 - loss 0.60459999 - time (sec): 17.91 - samples/sec: 2220.76 - lr: 0.010000 - momentum: 0.000000\n",
            "2024-11-05 13:40:25,048 epoch 4 - iter 21/34 - loss 0.60598304 - time (sec): 20.94 - samples/sec: 2188.21 - lr: 0.010000 - momentum: 0.000000\n",
            "2024-11-05 13:40:26,909 epoch 4 - iter 24/34 - loss 0.62244638 - time (sec): 22.80 - samples/sec: 2191.25 - lr: 0.010000 - momentum: 0.000000\n",
            "2024-11-05 13:40:29,847 epoch 4 - iter 27/34 - loss 0.63069653 - time (sec): 25.74 - samples/sec: 2215.65 - lr: 0.010000 - momentum: 0.000000\n",
            "2024-11-05 13:40:33,145 epoch 4 - iter 30/34 - loss 0.63490556 - time (sec): 29.04 - samples/sec: 2149.52 - lr: 0.010000 - momentum: 0.000000\n",
            "2024-11-05 13:40:36,381 epoch 4 - iter 33/34 - loss 0.62837231 - time (sec): 32.27 - samples/sec: 2172.37 - lr: 0.010000 - momentum: 0.000000\n",
            "2024-11-05 13:40:37,164 ----------------------------------------------------------------------------------------------------\n",
            "2024-11-05 13:40:37,168 EPOCH 4 done: loss 0.6278 - lr: 0.010000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:02<00:00,  2.25s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-11-05 13:40:39,464 DEV : loss 0.7423698306083679 - f1-score (micro avg)  0.0\n",
            "2024-11-05 13:40:39,477  - 2 epochs without improvement\n",
            "2024-11-05 13:40:39,479 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-11-05 13:40:42,289 epoch 5 - iter 3/34 - loss 0.58226707 - time (sec): 2.81 - samples/sec: 2811.35 - lr: 0.010000 - momentum: 0.000000\n",
            "2024-11-05 13:40:45,604 epoch 5 - iter 6/34 - loss 0.60176388 - time (sec): 6.12 - samples/sec: 2268.08 - lr: 0.010000 - momentum: 0.000000\n",
            "2024-11-05 13:40:49,265 epoch 5 - iter 9/34 - loss 0.61468719 - time (sec): 9.78 - samples/sec: 2285.23 - lr: 0.010000 - momentum: 0.000000\n",
            "2024-11-05 13:40:51,764 epoch 5 - iter 12/34 - loss 0.62484253 - time (sec): 12.28 - samples/sec: 2245.01 - lr: 0.010000 - momentum: 0.000000\n",
            "2024-11-05 13:40:54,116 epoch 5 - iter 15/34 - loss 0.63918528 - time (sec): 14.63 - samples/sec: 2257.62 - lr: 0.010000 - momentum: 0.000000\n",
            "2024-11-05 13:40:56,845 epoch 5 - iter 18/34 - loss 0.63956309 - time (sec): 17.36 - samples/sec: 2236.69 - lr: 0.010000 - momentum: 0.000000\n",
            "2024-11-05 13:40:59,734 epoch 5 - iter 21/34 - loss 0.63731051 - time (sec): 20.25 - samples/sec: 2252.87 - lr: 0.010000 - momentum: 0.000000\n",
            "2024-11-05 13:41:02,272 epoch 5 - iter 24/34 - loss 0.63237332 - time (sec): 22.79 - samples/sec: 2214.76 - lr: 0.010000 - momentum: 0.000000\n",
            "2024-11-05 13:41:05,821 epoch 5 - iter 27/34 - loss 0.61733378 - time (sec): 26.34 - samples/sec: 2185.63 - lr: 0.010000 - momentum: 0.000000\n",
            "2024-11-05 13:41:09,038 epoch 5 - iter 30/34 - loss 0.60406076 - time (sec): 29.56 - samples/sec: 2153.38 - lr: 0.010000 - momentum: 0.000000\n",
            "2024-11-05 13:41:11,597 epoch 5 - iter 33/34 - loss 0.59831648 - time (sec): 32.11 - samples/sec: 2170.74 - lr: 0.010000 - momentum: 0.000000\n",
            "2024-11-05 13:41:12,291 ----------------------------------------------------------------------------------------------------\n",
            "2024-11-05 13:41:12,293 EPOCH 5 done: loss 0.5977 - lr: 0.010000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:02<00:00,  2.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-11-05 13:41:14,708 DEV : loss 0.7176206111907959 - f1-score (micro avg)  0.0\n",
            "2024-11-05 13:41:14,722  - 3 epochs without improvement\n",
            "2024-11-05 13:41:14,727 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-11-05 13:41:17,071 epoch 6 - iter 3/34 - loss 0.51414941 - time (sec): 2.34 - samples/sec: 2788.25 - lr: 0.010000 - momentum: 0.000000\n",
            "2024-11-05 13:41:20,014 epoch 6 - iter 6/34 - loss 0.55494577 - time (sec): 5.28 - samples/sec: 2224.33 - lr: 0.010000 - momentum: 0.000000\n",
            "2024-11-05 13:41:22,720 epoch 6 - iter 9/34 - loss 0.55205187 - time (sec): 7.99 - samples/sec: 2310.72 - lr: 0.010000 - momentum: 0.000000\n",
            "2024-11-05 13:41:25,547 epoch 6 - iter 12/34 - loss 0.56251642 - time (sec): 10.82 - samples/sec: 2308.36 - lr: 0.010000 - momentum: 0.000000\n",
            "2024-11-05 13:41:28,022 epoch 6 - iter 15/34 - loss 0.56232563 - time (sec): 13.29 - samples/sec: 2294.34 - lr: 0.010000 - momentum: 0.000000\n",
            "2024-11-05 13:41:31,157 epoch 6 - iter 18/34 - loss 0.55959166 - time (sec): 16.43 - samples/sec: 2183.56 - lr: 0.010000 - momentum: 0.000000\n",
            "2024-11-05 13:41:34,493 epoch 6 - iter 21/34 - loss 0.55205532 - time (sec): 19.76 - samples/sec: 2199.12 - lr: 0.010000 - momentum: 0.000000\n",
            "2024-11-05 13:41:37,297 epoch 6 - iter 24/34 - loss 0.55393657 - time (sec): 22.57 - samples/sec: 2173.35 - lr: 0.010000 - momentum: 0.000000\n",
            "2024-11-05 13:41:40,388 epoch 6 - iter 27/34 - loss 0.55647994 - time (sec): 25.66 - samples/sec: 2156.86 - lr: 0.010000 - momentum: 0.000000\n",
            "2024-11-05 13:41:43,232 epoch 6 - iter 30/34 - loss 0.55470125 - time (sec): 28.50 - samples/sec: 2214.91 - lr: 0.010000 - momentum: 0.000000\n",
            "2024-11-05 13:41:46,049 epoch 6 - iter 33/34 - loss 0.56343430 - time (sec): 31.32 - samples/sec: 2188.10 - lr: 0.010000 - momentum: 0.000000\n",
            "2024-11-05 13:41:46,866 ----------------------------------------------------------------------------------------------------\n",
            "2024-11-05 13:41:46,870 EPOCH 6 done: loss 0.5589 - lr: 0.010000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:02<00:00,  2.61s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-11-05 13:41:49,518 DEV : loss 0.7045411467552185 - f1-score (micro avg)  0.0\n",
            "2024-11-05 13:41:49,531  - 0 epochs without improvement\n",
            "2024-11-05 13:41:49,533 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-11-05 13:41:51,722 epoch 7 - iter 3/34 - loss 0.56607083 - time (sec): 2.19 - samples/sec: 2836.94 - lr: 0.010000 - momentum: 0.000000\n",
            "2024-11-05 13:41:54,394 epoch 7 - iter 6/34 - loss 0.62180111 - time (sec): 4.86 - samples/sec: 2371.00 - lr: 0.010000 - momentum: 0.000000\n",
            "2024-11-05 13:41:57,165 epoch 7 - iter 9/34 - loss 0.58945594 - time (sec): 7.63 - samples/sec: 2356.11 - lr: 0.010000 - momentum: 0.000000\n",
            "2024-11-05 13:42:00,641 epoch 7 - iter 12/34 - loss 0.56000776 - time (sec): 11.10 - samples/sec: 2275.96 - lr: 0.010000 - momentum: 0.000000\n",
            "2024-11-05 13:42:03,818 epoch 7 - iter 15/34 - loss 0.54292259 - time (sec): 14.28 - samples/sec: 2206.53 - lr: 0.010000 - momentum: 0.000000\n",
            "2024-11-05 13:42:06,974 epoch 7 - iter 18/34 - loss 0.55414978 - time (sec): 17.44 - samples/sec: 2156.95 - lr: 0.010000 - momentum: 0.000000\n",
            "2024-11-05 13:42:09,822 epoch 7 - iter 21/34 - loss 0.56113469 - time (sec): 20.29 - samples/sec: 2112.06 - lr: 0.010000 - momentum: 0.000000\n",
            "2024-11-05 13:42:12,392 epoch 7 - iter 24/34 - loss 0.55548226 - time (sec): 22.85 - samples/sec: 2135.88 - lr: 0.010000 - momentum: 0.000000\n",
            "2024-11-05 13:42:15,076 epoch 7 - iter 27/34 - loss 0.55702892 - time (sec): 25.54 - samples/sec: 2151.34 - lr: 0.010000 - momentum: 0.000000\n",
            "2024-11-05 13:42:17,563 epoch 7 - iter 30/34 - loss 0.54538158 - time (sec): 28.03 - samples/sec: 2133.60 - lr: 0.010000 - momentum: 0.000000\n",
            "2024-11-05 13:42:21,583 epoch 7 - iter 33/34 - loss 0.54397266 - time (sec): 32.05 - samples/sec: 2164.81 - lr: 0.010000 - momentum: 0.000000\n",
            "2024-11-05 13:42:22,534 ----------------------------------------------------------------------------------------------------\n",
            "2024-11-05 13:42:22,536 EPOCH 7 done: loss 0.5428 - lr: 0.010000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:02<00:00,  2.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-11-05 13:42:24,950 DEV : loss 0.7055392265319824 - f1-score (micro avg)  0.0\n",
            "2024-11-05 13:42:24,963  - 1 epochs without improvement\n",
            "2024-11-05 13:42:24,964 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-11-05 13:42:27,816 epoch 8 - iter 3/34 - loss 0.49901831 - time (sec): 2.85 - samples/sec: 2492.21 - lr: 0.010000 - momentum: 0.000000\n",
            "2024-11-05 13:42:31,181 epoch 8 - iter 6/34 - loss 0.48410156 - time (sec): 6.21 - samples/sec: 2358.02 - lr: 0.010000 - momentum: 0.000000\n",
            "2024-11-05 13:42:34,222 epoch 8 - iter 9/34 - loss 0.51219524 - time (sec): 9.25 - samples/sec: 2210.00 - lr: 0.010000 - momentum: 0.000000\n",
            "2024-11-05 13:42:36,683 epoch 8 - iter 12/34 - loss 0.52570271 - time (sec): 11.71 - samples/sec: 2329.23 - lr: 0.010000 - momentum: 0.000000\n",
            "2024-11-05 13:42:40,349 epoch 8 - iter 15/34 - loss 0.53296080 - time (sec): 15.38 - samples/sec: 2172.13 - lr: 0.010000 - momentum: 0.000000\n",
            "2024-11-05 13:42:43,289 epoch 8 - iter 18/34 - loss 0.53056083 - time (sec): 18.32 - samples/sec: 2188.96 - lr: 0.010000 - momentum: 0.000000\n",
            "2024-11-05 13:42:46,357 epoch 8 - iter 21/34 - loss 0.52566589 - time (sec): 21.39 - samples/sec: 2160.22 - lr: 0.010000 - momentum: 0.000000\n",
            "2024-11-05 13:42:48,843 epoch 8 - iter 24/34 - loss 0.52711167 - time (sec): 23.87 - samples/sec: 2150.51 - lr: 0.010000 - momentum: 0.000000\n",
            "2024-11-05 13:42:51,271 epoch 8 - iter 27/34 - loss 0.52238788 - time (sec): 26.30 - samples/sec: 2165.73 - lr: 0.010000 - momentum: 0.000000\n",
            "2024-11-05 13:42:54,370 epoch 8 - iter 30/34 - loss 0.52991545 - time (sec): 29.40 - samples/sec: 2145.67 - lr: 0.010000 - momentum: 0.000000\n",
            "2024-11-05 13:42:57,631 epoch 8 - iter 33/34 - loss 0.52040362 - time (sec): 32.66 - samples/sec: 2126.08 - lr: 0.010000 - momentum: 0.000000\n",
            "2024-11-05 13:42:58,312 ----------------------------------------------------------------------------------------------------\n",
            "2024-11-05 13:42:58,313 EPOCH 8 done: loss 0.5195 - lr: 0.010000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:02<00:00,  2.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-11-05 13:43:00,707 DEV : loss 0.7120099663734436 - f1-score (micro avg)  0.0\n",
            "2024-11-05 13:43:00,723  - 2 epochs without improvement\n",
            "2024-11-05 13:43:00,724 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-11-05 13:43:02,713 epoch 9 - iter 3/34 - loss 0.54026778 - time (sec): 1.99 - samples/sec: 2706.92 - lr: 0.010000 - momentum: 0.000000\n",
            "2024-11-05 13:43:05,350 epoch 9 - iter 6/34 - loss 0.52981383 - time (sec): 4.62 - samples/sec: 2381.09 - lr: 0.010000 - momentum: 0.000000\n",
            "2024-11-05 13:43:08,667 epoch 9 - iter 9/34 - loss 0.50299070 - time (sec): 7.94 - samples/sec: 2412.40 - lr: 0.010000 - momentum: 0.000000\n",
            "2024-11-05 13:43:11,676 epoch 9 - iter 12/34 - loss 0.53049066 - time (sec): 10.95 - samples/sec: 2245.36 - lr: 0.010000 - momentum: 0.000000\n",
            "2024-11-05 13:43:14,238 epoch 9 - iter 15/34 - loss 0.52024821 - time (sec): 13.51 - samples/sec: 2194.15 - lr: 0.010000 - momentum: 0.000000\n",
            "2024-11-05 13:43:16,657 epoch 9 - iter 18/34 - loss 0.50776377 - time (sec): 15.93 - samples/sec: 2247.68 - lr: 0.010000 - momentum: 0.000000\n",
            "2024-11-05 13:43:20,152 epoch 9 - iter 21/34 - loss 0.49101308 - time (sec): 19.42 - samples/sec: 2245.59 - lr: 0.010000 - momentum: 0.000000\n",
            "2024-11-05 13:43:23,506 epoch 9 - iter 24/34 - loss 0.48838799 - time (sec): 22.78 - samples/sec: 2205.34 - lr: 0.010000 - momentum: 0.000000\n",
            "2024-11-05 13:43:26,965 epoch 9 - iter 27/34 - loss 0.47825588 - time (sec): 26.24 - samples/sec: 2189.70 - lr: 0.010000 - momentum: 0.000000\n",
            "2024-11-05 13:43:29,725 epoch 9 - iter 30/34 - loss 0.48487629 - time (sec): 29.00 - samples/sec: 2178.40 - lr: 0.010000 - momentum: 0.000000\n",
            "2024-11-05 13:43:33,139 epoch 9 - iter 33/34 - loss 0.48495034 - time (sec): 32.41 - samples/sec: 2158.94 - lr: 0.010000 - momentum: 0.000000\n",
            "2024-11-05 13:43:33,777 ----------------------------------------------------------------------------------------------------\n",
            "2024-11-05 13:43:33,779 EPOCH 9 done: loss 0.4853 - lr: 0.010000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:02<00:00,  2.24s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-11-05 13:43:36,049 DEV : loss 0.7066482901573181 - f1-score (micro avg)  0.0\n",
            "2024-11-05 13:43:36,062  - 3 epochs without improvement\n",
            "2024-11-05 13:43:36,063 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-11-05 13:43:38,547 epoch 10 - iter 3/34 - loss 0.49115268 - time (sec): 2.48 - samples/sec: 2662.81 - lr: 0.010000 - momentum: 0.000000\n",
            "2024-11-05 13:43:41,065 epoch 10 - iter 6/34 - loss 0.52474659 - time (sec): 5.00 - samples/sec: 2354.26 - lr: 0.010000 - momentum: 0.000000\n",
            "2024-11-05 13:43:44,404 epoch 10 - iter 9/34 - loss 0.49402041 - time (sec): 8.34 - samples/sec: 2245.02 - lr: 0.010000 - momentum: 0.000000\n",
            "2024-11-05 13:43:47,127 epoch 10 - iter 12/34 - loss 0.47796342 - time (sec): 11.06 - samples/sec: 2180.43 - lr: 0.010000 - momentum: 0.000000\n",
            "2024-11-05 13:43:49,792 epoch 10 - iter 15/34 - loss 0.49100609 - time (sec): 13.72 - samples/sec: 2132.93 - lr: 0.010000 - momentum: 0.000000\n",
            "2024-11-05 13:43:52,631 epoch 10 - iter 18/34 - loss 0.47776242 - time (sec): 16.56 - samples/sec: 2093.08 - lr: 0.010000 - momentum: 0.000000\n",
            "2024-11-05 13:43:55,662 epoch 10 - iter 21/34 - loss 0.47108429 - time (sec): 19.59 - samples/sec: 2097.42 - lr: 0.010000 - momentum: 0.000000\n",
            "2024-11-05 13:43:58,742 epoch 10 - iter 24/34 - loss 0.46774096 - time (sec): 22.67 - samples/sec: 2141.22 - lr: 0.010000 - momentum: 0.000000\n",
            "2024-11-05 13:44:02,387 epoch 10 - iter 27/34 - loss 0.46857156 - time (sec): 26.32 - samples/sec: 2114.73 - lr: 0.010000 - momentum: 0.000000\n",
            "2024-11-05 13:44:05,350 epoch 10 - iter 30/34 - loss 0.47185733 - time (sec): 29.28 - samples/sec: 2105.14 - lr: 0.010000 - momentum: 0.000000\n",
            "2024-11-05 13:44:08,530 epoch 10 - iter 33/34 - loss 0.47645602 - time (sec): 32.46 - samples/sec: 2120.75 - lr: 0.010000 - momentum: 0.000000\n",
            "2024-11-05 13:44:09,367 ----------------------------------------------------------------------------------------------------\n",
            "2024-11-05 13:44:09,368 EPOCH 10 done: loss 0.4727 - lr: 0.010000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:02<00:00,  2.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-11-05 13:44:11,860 DEV : loss 0.7083019018173218 - f1-score (micro avg)  0.0\n",
            "2024-11-05 13:44:11,873  - 4 epochs without improvement (above 'patience')-> annealing learning_rate to [0.005]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-11-05 13:44:13,271 ----------------------------------------------------------------------------------------------------\n",
            "2024-11-05 13:44:13,278 Testing using last state of model ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2/2 [00:05<00:00,  2.99s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-11-05 13:44:19,302 \n",
            "Results:\n",
            "- F-score (micro) 0.1675\n",
            "- F-score (macro) 0.1324\n",
            "- Accuracy 0.0934\n",
            "\n",
            "By class:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       SKILL     0.0000    0.0000    0.0000       557\n",
            "        WORK     0.5657    0.7795    0.6556       127\n",
            "         JOB     0.1429    0.0850    0.1066       153\n",
            "     COMPANY     0.0000    0.0000    0.0000       112\n",
            "         LOC     0.0000    0.0000    0.0000        87\n",
            "       PHONE     0.2727    0.3333    0.3000        36\n",
            "        NAME     0.4483    0.3514    0.3939        37\n",
            "         DEG     0.0000    0.0000    0.0000        45\n",
            "         UNI     0.0000    0.0000    0.0000        49\n",
            "       STUDY     0.0000    0.0000    0.0000        38\n",
            "       EMAIL     0.0000    0.0000    0.0000        32\n",
            "\n",
            "   micro avg     0.3774    0.1076    0.1675      1273\n",
            "   macro avg     0.1300    0.1408    0.1324      1273\n",
            "weighted avg     0.0943    0.1076    0.0981      1273\n",
            "\n",
            "2024-11-05 13:44:19,306 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate model\n",
        "from flair.data import Corpus\n",
        "from flair.datasets import ColumnCorpus\n",
        "from flair.models import SequenceTagger\n",
        "from flair.trainers import ModelTrainer\n",
        "\n",
        "# Load the trained model\n",
        "model = SequenceTagger.load('/content/drive/MyDrive/FYP/Implementation/flair_output/final-model.pt')\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "result = model.evaluate(corpus.test, gold_label_type='ner', mini_batch_size=32)\n",
        "\n",
        "# Print the results\n",
        "# print(\"Evaluation Loss:\", eval_loss)\n",
        "print(result.detailed_results)  # print the precision, recall, and F1-score per entity type"
      ],
      "metadata": {
        "id": "6KT8wj3Lns2c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0e2344a-5cf0-4500-9899-3a88b034c0b0"
      },
      "id": "6KT8wj3Lns2c",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-11-05 13:44:32,649 SequenceTagger predicts: Dictionary with 45 tags: O, S-SKILL, B-SKILL, E-SKILL, I-SKILL, S-JOB, B-JOB, E-JOB, I-JOB, S-WORK, B-WORK, E-WORK, I-WORK, S-COMPANY, B-COMPANY, E-COMPANY, I-COMPANY, S-LOC, B-LOC, E-LOC, I-LOC, S-DEG, B-DEG, E-DEG, I-DEG, S-UNI, B-UNI, E-UNI, I-UNI, S-PHONE, B-PHONE, E-PHONE, I-PHONE, S-NAME, B-NAME, E-NAME, I-NAME, S-STUDY, B-STUDY, E-STUDY, I-STUDY, S-EMAIL, B-EMAIL, E-EMAIL, I-EMAIL\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3/3 [00:04<00:00,  1.41s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Results:\n",
            "- F-score (micro) 0.1675\n",
            "- F-score (macro) 0.1324\n",
            "- Accuracy 0.0934\n",
            "\n",
            "By class:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       SKILL     0.0000    0.0000    0.0000       557\n",
            "        WORK     0.5657    0.7795    0.6556       127\n",
            "         JOB     0.1429    0.0850    0.1066       153\n",
            "     COMPANY     0.0000    0.0000    0.0000       112\n",
            "         LOC     0.0000    0.0000    0.0000        87\n",
            "       PHONE     0.2727    0.3333    0.3000        36\n",
            "        NAME     0.4483    0.3514    0.3939        37\n",
            "         DEG     0.0000    0.0000    0.0000        45\n",
            "         UNI     0.0000    0.0000    0.0000        49\n",
            "       STUDY     0.0000    0.0000    0.0000        38\n",
            "       EMAIL     0.0000    0.0000    0.0000        32\n",
            "\n",
            "   micro avg     0.3774    0.1076    0.1675      1273\n",
            "   macro avg     0.1300    0.1408    0.1324      1273\n",
            "weighted avg     0.0943    0.1076    0.0981      1273\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# make prediction\n",
        "import flair\n",
        "model = SequenceTagger.load('/content/drive/MyDrive/FYP/Implementation/flair_output/best-model.pt')\n",
        "resume_text = '''\n",
        "John Doe lives at 1234 Elm Street in Los Angeles, CA 90001. He can be reached at +1 (555) 123-4567 or via email at john.doe@example.com. John is a results-driven software engineer with over 5 years of experience in web development and cloud infrastructure, with strong knowledge of JavaScript, Python, and cloud technologies like AWS and Azure. Currently, he works as a Software Engineer at Google LLC in San Francisco, CA, where he has been employed since August 2019. In this role, he has developed scalable web applications using JavaScript, Node.js, and React, deployed and maintained cloud infrastructure on AWS, reducing downtime by 20%, and led a team of 4 engineers to enhance backend performance by 30%. Previously, he worked as a Junior Developer at Tech Innovators Inc. in Austin, TX, from July 2017 to July 2019, where he created RESTful APIs using Python and Flask, collaborated with front-end developers to build and deploy user-facing applications, and wrote unit and integration tests, improving code coverage by 15%.\n",
        "\n",
        "John holds a Master of Science in Computer Science from the University of California, Berkeley, with a graduation date of May 2017, and a Bachelor of Science in Information Technology from the University of Texas at Austin, graduated in May 2015. His skillset includes proficiency in programming languages like Python, JavaScript, and Java; frameworks such as React, Flask, and Django; cloud platforms including AWS, Google Cloud, and Azure; as well as other tools like Git, Docker, Kubernetes, and SQL. He is certified as an AWS Certified Solutions Architect – Associate, earned in 2020, and as a Google Professional Cloud Architect, earned in 2021'\n",
        "'''\n",
        "sentence = flair.data.Sentence(resume_text.lower())\n",
        "\n",
        "model.predict(sentence)\n",
        "\n",
        "print(sentence.to_tagged_string())"
      ],
      "metadata": {
        "id": "KOYkWF9Anwec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b13bfaad-2692-48d6-9be1-20854591bcdc"
      },
      "id": "KOYkWF9Anwec",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-11-05 13:44:42,059 SequenceTagger predicts: Dictionary with 47 tags: O, S-SKILL, B-SKILL, E-SKILL, I-SKILL, S-JOB, B-JOB, E-JOB, I-JOB, S-WORK, B-WORK, E-WORK, I-WORK, S-COMPANY, B-COMPANY, E-COMPANY, I-COMPANY, S-LOC, B-LOC, E-LOC, I-LOC, S-UNI, B-UNI, E-UNI, I-UNI, S-DEG, B-DEG, E-DEG, I-DEG, S-NAME, B-NAME, E-NAME, I-NAME, S-PHONE, B-PHONE, E-PHONE, I-PHONE, S-STUDY, B-STUDY, E-STUDY, I-STUDY, S-EMAIL, B-EMAIL, E-EMAIL, I-EMAIL, <START>, <STOP>\n",
            "Sentence[326]: \" john doe lives at 1234 elm street in los angeles, ca 90001. he can be reached at +1 (555) 123-4567 or via email at john.doe@example.com. john is a results-driven software engineer with over 5 years of experience in web development and cloud infrastructure, with strong knowledge of javascript, python, and cloud technologies like aws and azure. currently, he works as a software engineer at google llc in san francisco, ca, where he has been employed since august 2019. in this role, he has developed scalable web applications using javascript, node.js, and react, deployed and maintained cloud infrastructure on aws, reducing downtime by 20%, and led a team of 4 engineers to enhance backend performance by 30%. previously, he worked as a junior developer at tech innovators inc. in austin, tx, from july 2017 to july 2019, where he created restful apis using python and flask, collaborated with front-end developers to build and deploy user-facing applications, and wrote unit and integration tests, improving code coverage by 15%.  john holds a master of science in computer science from the university of california, berkeley, with a graduation date of may 2017, and a bachelor of science in information technology from the university of texas at austin, graduated in may 2015. his skillset includes proficiency in programming languages like python, javascript, and java; frameworks such as react, flask, and django; cloud platforms including aws, google cloud, and azure; as well as other tools like git, docker, kubernetes, and sql. he is certified as an aws certified solutions architect – associate, earned in 2020, and as a google professional cloud architect, earned in 2021'\" → [\"doe lives\"/NAME, \"1234 elm\"/NAME, \"los\"/DEG, \"90001\"/DEG, \"555\"/DEG, \"123-4567\"/DEG, \"via\"/DEG, \"at\"/EMAIL, \"john.doe\"/JOB, \"@\"/DEG, \"example.com\"/STUDY, \"john\"/DEG, \"results-driven\"/DEG, \"javascript\"/DEG, \"python\"/DEG, \"cloud\"/DEG, \"aws\"/DEG, \"azure\"/DEG, \"llc\"/DEG, \"francisco\"/DEG, \"2019\"/DEG, \"scalable\"/DEG, \"javascript\"/DEG, \"node.js\"/DEG, \"react\"/DEG, \"cloud\"/DEG, \"aws\"/DEG, \"downtime\"/DEG, \"backend\"/DEG, \"developer\"/DEG, \"innovators inc\"/NAME, \"austin\"/DEG, \"tx\"/DEG, \"2017\"/DEG, \"2019\"/DEG, \"restful apis\"/NAME, \"python\"/DEG, \"flask\"/DEG, \"collaborated\"/DEG, \"front-end\"/DEG, \"user-facing\"/DEG, \"berkeley\"/DEG, \"2017\"/DEG, \"austin\"/DEG, \"graduated\"/DEG, \"2015\"/DEG, \"skillset\"/DEG, \"proficiency\"/DEG, \"python\"/DEG, \"javascript\"/DEG, \"java\"/DEG, \"frameworks\"/DEG, \"react\"/DEG, \"flask\"/DEG, \"django\"/DEG, \"cloud\"/DEG, \"aws\"/DEG, \"cloud\"/DEG, \"azure\"/DEG, \"git\"/DEG, \"docker\"/DEG, \"kubernetes\"/DEG, \"sql\"/DEG, \"aws certified\"/NAME, \"architect\"/DEG, \"associate\"/DEG, \"earned\"/DEG, \"architect\"/DEG, \"earned\"/DEG, \"2021\"/EMAIL, \"'\"/JOB]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from flair.models import SequenceTagger\n",
        "from flair.data import Sentence\n",
        "\n",
        "# Load the pretrained NER model\n",
        "tagger = SequenceTagger.load(\"/content/drive/MyDrive/FYP/Implementation/flair_output/best-model.pt\")\n",
        "# Example text\n",
        "text = \"Apple is looking at buying U.K. startup for $1 billion.\"\n",
        "\n",
        "# Create a Sentence object\n",
        "sentence = Sentence(resume_text)\n",
        "\n",
        "# Predict entities\n",
        "tagger.predict(sentence)\n",
        "\n",
        "# Print the detected entities\n",
        "for entity in sentence.get_spans(\"ner\"):\n",
        "    print(f\"Entity: {entity.text}, Type: {entity.get_label('ner').value}, Confidence: {entity.score}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eh_ohqkhnuwA",
        "outputId": "a9d030fe-4db4-472c-eeea-e6e29a11322f"
      },
      "id": "Eh_ohqkhnuwA",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-11-05 13:44:49,701 SequenceTagger predicts: Dictionary with 47 tags: O, S-SKILL, B-SKILL, E-SKILL, I-SKILL, S-JOB, B-JOB, E-JOB, I-JOB, S-WORK, B-WORK, E-WORK, I-WORK, S-COMPANY, B-COMPANY, E-COMPANY, I-COMPANY, S-LOC, B-LOC, E-LOC, I-LOC, S-UNI, B-UNI, E-UNI, I-UNI, S-DEG, B-DEG, E-DEG, I-DEG, S-NAME, B-NAME, E-NAME, I-NAME, S-PHONE, B-PHONE, E-PHONE, I-PHONE, S-STUDY, B-STUDY, E-STUDY, I-STUDY, S-EMAIL, B-EMAIL, E-EMAIL, I-EMAIL, <START>, <STOP>\n",
            "Entity: Doe lives, Type: NAME, Confidence: 0.16702505946159363\n",
            "Entity: 1234 Elm, Type: NAME, Confidence: 0.11599351465702057\n",
            "Entity: Los, Type: DEG, Confidence: 0.18544061481952667\n",
            "Entity: 90001, Type: DEG, Confidence: 0.14748063683509827\n",
            "Entity: 555, Type: DEG, Confidence: 0.11017131805419922\n",
            "Entity: 123-4567, Type: DEG, Confidence: 0.11569119244813919\n",
            "Entity: via, Type: DEG, Confidence: 0.20629706978797913\n",
            "Entity: at, Type: EMAIL, Confidence: 0.19365909695625305\n",
            "Entity: john.doe, Type: JOB, Confidence: 0.10587572306394577\n",
            "Entity: @, Type: DEG, Confidence: 0.1225953996181488\n",
            "Entity: example.com, Type: STUDY, Confidence: 0.10775433480739594\n",
            "Entity: John, Type: DEG, Confidence: 0.1873975694179535\n",
            "Entity: results-driven, Type: DEG, Confidence: 0.1495516300201416\n",
            "Entity: JavaScript, Type: DEG, Confidence: 0.1738281399011612\n",
            "Entity: Python, Type: DEG, Confidence: 0.1625775396823883\n",
            "Entity: cloud, Type: DEG, Confidence: 0.1898547261953354\n",
            "Entity: AWS, Type: DEG, Confidence: 0.1078900545835495\n",
            "Entity: Azure, Type: DEG, Confidence: 0.1390189230442047\n",
            "Entity: LLC, Type: DEG, Confidence: 0.19518113136291504\n",
            "Entity: Francisco, Type: DEG, Confidence: 0.20789998769760132\n",
            "Entity: 2019, Type: DEG, Confidence: 0.1681929975748062\n",
            "Entity: scalable, Type: DEG, Confidence: 0.18266770243644714\n",
            "Entity: JavaScript, Type: DEG, Confidence: 0.16769887506961823\n",
            "Entity: Node.js, Type: DEG, Confidence: 0.11853489279747009\n",
            "Entity: React, Type: DEG, Confidence: 0.20138564705848694\n",
            "Entity: cloud, Type: DEG, Confidence: 0.17859530448913574\n",
            "Entity: AWS, Type: DEG, Confidence: 0.11059108376502991\n",
            "Entity: downtime, Type: DEG, Confidence: 0.15199507772922516\n",
            "Entity: backend, Type: DEG, Confidence: 0.15180251002311707\n",
            "Entity: Developer, Type: DEG, Confidence: 0.200774148106575\n",
            "Entity: Innovators Inc, Type: NAME, Confidence: 0.14714515209197998\n",
            "Entity: Austin, Type: DEG, Confidence: 0.17351219058036804\n",
            "Entity: TX, Type: DEG, Confidence: 0.14547361433506012\n",
            "Entity: 2017, Type: DEG, Confidence: 0.17111483216285706\n",
            "Entity: 2019, Type: DEG, Confidence: 0.1492062658071518\n",
            "Entity: RESTful APIs, Type: NAME, Confidence: 0.12886418029665947\n",
            "Entity: Python, Type: DEG, Confidence: 0.12615029513835907\n",
            "Entity: Flask, Type: DEG, Confidence: 0.11048925668001175\n",
            "Entity: collaborated, Type: DEG, Confidence: 0.1400829404592514\n",
            "Entity: front-end, Type: DEG, Confidence: 0.1426965743303299\n",
            "Entity: user-facing, Type: DEG, Confidence: 0.1417454183101654\n",
            "Entity: Berkeley, Type: DEG, Confidence: 0.21379657089710236\n",
            "Entity: 2017, Type: DEG, Confidence: 0.20121298730373383\n",
            "Entity: Austin, Type: DEG, Confidence: 0.1921633780002594\n",
            "Entity: graduated, Type: DEG, Confidence: 0.19784928858280182\n",
            "Entity: 2015, Type: DEG, Confidence: 0.20958878099918365\n",
            "Entity: skillset, Type: DEG, Confidence: 0.11280574649572372\n",
            "Entity: proficiency, Type: DEG, Confidence: 0.20423416793346405\n",
            "Entity: Python, Type: DEG, Confidence: 0.15512722730636597\n",
            "Entity: JavaScript, Type: DEG, Confidence: 0.1654430627822876\n",
            "Entity: Java, Type: DEG, Confidence: 0.19505003094673157\n",
            "Entity: frameworks, Type: DEG, Confidence: 0.18640774488449097\n",
            "Entity: React, Type: DEG, Confidence: 0.19585756957530975\n",
            "Entity: Flask, Type: DEG, Confidence: 0.10743413120508194\n",
            "Entity: Django, Type: DEG, Confidence: 0.10782385617494583\n",
            "Entity: cloud, Type: DEG, Confidence: 0.15763729810714722\n",
            "Entity: AWS, Type: DEG, Confidence: 0.10634929686784744\n",
            "Entity: Cloud, Type: DEG, Confidence: 0.18283122777938843\n",
            "Entity: Azure, Type: DEG, Confidence: 0.15222297608852386\n",
            "Entity: Git, Type: DEG, Confidence: 0.11355996131896973\n",
            "Entity: Docker, Type: DEG, Confidence: 0.11132988333702087\n",
            "Entity: Kubernetes, Type: DEG, Confidence: 0.11910903453826904\n",
            "Entity: SQL, Type: DEG, Confidence: 0.16887710988521576\n",
            "Entity: AWS Certified, Type: NAME, Confidence: 0.16041680797934532\n",
            "Entity: Architect, Type: DEG, Confidence: 0.1597680151462555\n",
            "Entity: Associate, Type: DEG, Confidence: 0.16229602694511414\n",
            "Entity: earned, Type: DEG, Confidence: 0.21766595542430878\n",
            "Entity: Architect, Type: DEG, Confidence: 0.18512634932994843\n",
            "Entity: earned, Type: DEG, Confidence: 0.16895930469036102\n",
            "Entity: 2021, Type: EMAIL, Confidence: 0.11030236631631851\n",
            "Entity: ', Type: JOB, Confidence: 0.16406425833702087\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}