{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chewzzz1014/fyp/blob/master/ner/src/train_ner_models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train NER Models"
      ],
      "metadata": {
        "id": "t0P9v82yDulr"
      },
      "id": "t0P9v82yDulr"
    },
    {
      "cell_type": "code",
      "source": [
        "# mount drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "5YToyjV-40ZV",
        "outputId": "085459b8-5ab4-4ebe-aada-8b306646bced",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "5YToyjV-40ZV",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir spacy_ner_data"
      ],
      "metadata": {
        "id": "VtZ7OFQtpG4-"
      },
      "id": "VtZ7OFQtpG4-",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Spacy NER"
      ],
      "metadata": {
        "id": "FMM7E6hNCEUv"
      },
      "id": "FMM7E6hNCEUv"
    },
    {
      "cell_type": "code",
      "source": [
        "# load json and convert into spacy format\n",
        "\n",
        "import json\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "import spacy\n",
        "import numpy as np\n",
        "np.float_ = np.float64\n",
        "from spacy.tokens import DocBin\n",
        "\n",
        "# load JSON data from Drive\n",
        "with open('/content/drive/MyDrive/FYP/Implementation/Resume Dataset/1100_resumes_annotated.json', \"r\") as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "# remove overlapped entities (one word has >1 entitiy)\n",
        "def remove_overlapping_entities(entities):\n",
        "    \"\"\"Remove overlapping entities from the list.\"\"\"\n",
        "    # sort entities by start position\n",
        "    entities = sorted(entities, key=lambda x: x[0])\n",
        "    non_overlapping = []\n",
        "    last_end = -1\n",
        "    for start, end, label in entities:\n",
        "        # only add to list if there's no overlap with the previous entity\n",
        "        if start >= last_end:\n",
        "            non_overlapping.append((start, end, label))\n",
        "            last_end = end\n",
        "    return non_overlapping\n",
        "\n",
        "# convert JSON data to Spacy's DocBin format\n",
        "def convert_to_spacy_format(data):\n",
        "    # load a blank Spacy model\n",
        "    nlp = spacy.blank(\"en\")\n",
        "    # container for our docs\n",
        "    doc_bin = DocBin()\n",
        "\n",
        "    for item in data:\n",
        "        # full document text\n",
        "        text = item['data']['Text']\n",
        "        entities = []\n",
        "\n",
        "        for annotation in item['annotations'][0]['result']:\n",
        "            start = annotation['value']['start']\n",
        "            end = annotation['value']['end']\n",
        "            label = annotation['value']['labels'][0]\n",
        "            entities.append((start, end, label))\n",
        "\n",
        "        # remove overlapping entities\n",
        "        entities = remove_overlapping_entities(entities)\n",
        "        # create a Spacy doc and add entities to it\n",
        "        doc = nlp.make_doc(text)\n",
        "        spans = [doc.char_span(start, end, label=label) for start, end, label in entities]\n",
        "        # filter out None spans if Spacy can't align the character indices with tokens\n",
        "        spans = [span for span in spans if span is not None]\n",
        "        # assign entities to the doc\n",
        "        doc.ents = spans\n",
        "        doc_bin.add(doc)\n",
        "\n",
        "    return doc_bin\n",
        "\n",
        "# split data into train and test sets\n",
        "train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)\n",
        "\n",
        "# convert train and test sets to Spacy format\n",
        "train_doc_bin = convert_to_spacy_format(train_data)\n",
        "test_doc_bin = convert_to_spacy_format(test_data)\n",
        "\n",
        "# save the train and test data to .spacy files in current runtime\n",
        "train_doc_bin.to_disk(\"spacy_ner_data/train_data.spacy\")\n",
        "test_doc_bin.to_disk(\"spacy_ner_data/test_data.spacy\")"
      ],
      "metadata": {
        "id": "R-8QBDX3gtkp"
      },
      "id": "R-8QBDX3gtkp",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check the distribution of entitiy labels\n",
        "\n",
        "import spacy\n",
        "from spacy.lang.en import English\n",
        "from spacy.tokens import DocBin\n",
        "\n",
        "# count number of label entities\n",
        "def count_entity_labels(file_path):\n",
        "    # load data from file_path and create DocBin\n",
        "    doc_bin = DocBin().from_disk(file_path)\n",
        "    label_counts = {}\n",
        "    for doc in doc_bin.get_docs(English().vocab):\n",
        "        # count occurence of label\n",
        "        for ent in doc.ents:\n",
        "            label = ent.label_\n",
        "            label_counts[label] = label_counts.get(label, 0) + 1\n",
        "    return label_counts\n",
        "\n",
        "# calculate and print label distribution in train and test data\n",
        "# sorted from largest to smallest\n",
        "train_label_counts = count_entity_labels(\"spacy_ner_data/train_data.spacy\")\n",
        "sorted_train_label_counts = sorted(train_label_counts.items(), key=lambda x: x[1], reverse=True)\n",
        "print(\"Train Data Entity Label Distribution:\")\n",
        "for label, count in sorted_train_label_counts:\n",
        "    print(f\"{label}: {count}\")\n",
        "\n",
        "test_label_counts = count_entity_labels(\"spacy_ner_data/test_data.spacy\")\n",
        "sorted_test_label_counts = sorted(test_label_counts.items(), key=lambda x: x[1], reverse=True)\n",
        "print(\"\\nTest Data Entity Label Distribution:\")\n",
        "for label, count in sorted_test_label_counts:\n",
        "    print(f\"{label}: {count}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iNbbPSw4i_fw",
        "outputId": "a819f2a5-22bb-4356-bb22-0f511b5bc332"
      },
      "id": "iNbbPSw4i_fw",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Data Entity Label Distribution:\n",
            "SKILL: 15539\n",
            "JOB: 4275\n",
            "LOC: 2963\n",
            "WORK PER: 2795\n",
            "COMPANY: 2606\n",
            "UNI: 1249\n",
            "DEG: 1091\n",
            "NAME: 883\n",
            "STUDY PER: 852\n",
            "PHONE: 816\n",
            "EMAIL: 775\n",
            "\n",
            "Test Data Entity Label Distribution:\n",
            "SKILL: 3812\n",
            "JOB: 1063\n",
            "LOC: 778\n",
            "WORK PER: 687\n",
            "COMPANY: 640\n",
            "UNI: 325\n",
            "DEG: 282\n",
            "NAME: 225\n",
            "STUDY PER: 212\n",
            "PHONE: 205\n",
            "EMAIL: 189\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create base_config.cfg and paste the config generated from spacy widget\n",
        "# need to update train and test file path\n",
        "!touch base_config.cfg"
      ],
      "metadata": {
        "id": "ruPln43fCDLm"
      },
      "id": "ruPln43fCDLm",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# install transformer\n",
        "!pip install git+https://github.com/explosion/spacy-transformers"
      ],
      "metadata": {
        "id": "NDpXuRK7G5NP",
        "outputId": "d7461964-9ecd-4281-f7cc-407492dd377a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "NDpXuRK7G5NP",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/explosion/spacy-transformers\n",
            "  Cloning https://github.com/explosion/spacy-transformers to /tmp/pip-req-build-qhcpto2d\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/explosion/spacy-transformers /tmp/pip-req-build-qhcpto2d\n",
            "  Resolved https://github.com/explosion/spacy-transformers to commit 40ee09d9b2b2b18f77fc3715329ce080691b6af9\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: spacy<4.1.0,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from spacy-transformers==1.3.6) (3.7.5)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy-transformers==1.3.6) (1.26.4)\n",
            "Collecting transformers<4.42.0,>=3.4.0 (from spacy-transformers==1.3.6)\n",
            "  Downloading transformers-4.41.2-py3-none-any.whl.metadata (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.8/43.8 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from spacy-transformers==1.3.6) (2.5.1+cu121)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from spacy-transformers==1.3.6) (2.5.0)\n",
            "Collecting spacy-alignments<1.0.0,>=0.7.2 (from spacy-transformers==1.3.6)\n",
            "  Downloading spacy_alignments-0.9.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<4.1.0,>=3.5.0->spacy-transformers==1.3.6) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4.1.0,>=3.5.0->spacy-transformers==1.3.6) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4.1.0,>=3.5.0->spacy-transformers==1.3.6) (1.0.11)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<4.1.0,>=3.5.0->spacy-transformers==1.3.6) (2.0.10)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<4.1.0,>=3.5.0->spacy-transformers==1.3.6) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<4.1.0,>=3.5.0->spacy-transformers==1.3.6) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<4.1.0,>=3.5.0->spacy-transformers==1.3.6) (1.1.3)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<4.1.0,>=3.5.0->spacy-transformers==1.3.6) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4.1.0,>=3.5.0->spacy-transformers==1.3.6) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4.1.0,>=3.5.0->spacy-transformers==1.3.6) (0.15.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4.1.0,>=3.5.0->spacy-transformers==1.3.6) (4.67.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4.1.0,>=3.5.0->spacy-transformers==1.3.6) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<4.1.0,>=3.5.0->spacy-transformers==1.3.6) (2.10.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<4.1.0,>=3.5.0->spacy-transformers==1.3.6) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<4.1.0,>=3.5.0->spacy-transformers==1.3.6) (75.1.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4.1.0,>=3.5.0->spacy-transformers==1.3.6) (24.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4.1.0,>=3.5.0->spacy-transformers==1.3.6) (3.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->spacy-transformers==1.3.6) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->spacy-transformers==1.3.6) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->spacy-transformers==1.3.6) (3.4.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->spacy-transformers==1.3.6) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->spacy-transformers==1.3.6) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.8.0->spacy-transformers==1.3.6) (1.3.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from transformers<4.42.0,>=3.4.0->spacy-transformers==1.3.6) (0.27.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers<4.42.0,>=3.4.0->spacy-transformers==1.3.6) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<4.42.0,>=3.4.0->spacy-transformers==1.3.6) (2024.11.6)\n",
            "Collecting tokenizers<0.20,>=0.19 (from transformers<4.42.0,>=3.4.0->spacy-transformers==1.3.6)\n",
            "  Downloading tokenizers-0.19.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<4.42.0,>=3.4.0->spacy-transformers==1.3.6) (0.4.5)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<4.1.0,>=3.5.0->spacy-transformers==1.3.6) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<4.1.0,>=3.5.0->spacy-transformers==1.3.6) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<4.1.0,>=3.5.0->spacy-transformers==1.3.6) (2.27.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<4.1.0,>=3.5.0->spacy-transformers==1.3.6) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<4.1.0,>=3.5.0->spacy-transformers==1.3.6) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<4.1.0,>=3.5.0->spacy-transformers==1.3.6) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<4.1.0,>=3.5.0->spacy-transformers==1.3.6) (2024.12.14)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<4.1.0,>=3.5.0->spacy-transformers==1.3.6) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<4.1.0,>=3.5.0->spacy-transformers==1.3.6) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<4.1.0,>=3.5.0->spacy-transformers==1.3.6) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<4.1.0,>=3.5.0->spacy-transformers==1.3.6) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<4.1.0,>=3.5.0->spacy-transformers==1.3.6) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<4.1.0,>=3.5.0->spacy-transformers==1.3.6) (0.20.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<4.1.0,>=3.5.0->spacy-transformers==1.3.6) (7.0.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<4.1.0,>=3.5.0->spacy-transformers==1.3.6) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<4.1.0,>=3.5.0->spacy-transformers==1.3.6) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<4.1.0,>=3.5.0->spacy-transformers==1.3.6) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<4.1.0,>=3.5.0->spacy-transformers==1.3.6) (2.18.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<4.1.0,>=3.5.0->spacy-transformers==1.3.6) (1.17.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<4.1.0,>=3.5.0->spacy-transformers==1.3.6) (0.1.2)\n",
            "Downloading spacy_alignments-0.9.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (313 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m314.0/314.0 kB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading transformers-4.41.2-py3-none-any.whl (9.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.1/9.1 MB\u001b[0m \u001b[31m106.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tokenizers-0.19.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m98.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: spacy-transformers\n",
            "  Building wheel for spacy-transformers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for spacy-transformers: filename=spacy_transformers-1.3.6-cp310-cp310-linux_x86_64.whl size=680951 sha256=4c8547b7749ed7b7a6c0fd2d295726663d74a61769846f79ba24953bceb34aff\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-jxemfqmj/wheels/83/b0/36/8f14149b7b5103f48d97f27c0ee666b64517660956b2a43299\n",
            "Successfully built spacy-transformers\n",
            "Installing collected packages: spacy-alignments, tokenizers, transformers, spacy-transformers\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.21.0\n",
            "    Uninstalling tokenizers-0.21.0:\n",
            "      Successfully uninstalled tokenizers-0.21.0\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.47.0\n",
            "    Uninstalling transformers-4.47.0:\n",
            "      Successfully uninstalled transformers-4.47.0\n",
            "Successfully installed spacy-alignments-0.9.1 spacy-transformers-1.3.6 tokenizers-0.19.1 transformers-4.41.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U spacy\n",
        "!pip install \"numpy<2\""
      ],
      "metadata": {
        "id": "VspN5ypufc2E",
        "outputId": "70c18601-75e6-4206-a610-d4404675f839",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "id": "VspN5ypufc2E",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (3.7.5)\n",
            "Collecting spacy\n",
            "  Downloading spacy-3.8.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (27 kB)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.11)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.9)\n",
            "Collecting thinc<8.4.0,>=8.3.0 (from spacy)\n",
            "  Downloading thinc-8.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (15 kB)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.5.0)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.15.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (4.67.1)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.26.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.10.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy) (75.1.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (24.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.5.0)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.27.1)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.12.14)\n",
            "Collecting blis<1.2.0,>=1.1.0 (from thinc<8.4.0,>=8.3.0->spacy)\n",
            "  Downloading blis-1.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.4.0,>=8.3.0->spacy) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.20.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.0.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.18.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
            "Downloading spacy-3.8.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (29.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m29.1/29.1 MB\u001b[0m \u001b[31m28.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading thinc-8.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m65.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading blis-1.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.2/9.2 MB\u001b[0m \u001b[31m101.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: blis, thinc, spacy\n",
            "  Attempting uninstall: blis\n",
            "    Found existing installation: blis 0.7.11\n",
            "    Uninstalling blis-0.7.11:\n",
            "      Successfully uninstalled blis-0.7.11\n",
            "  Attempting uninstall: thinc\n",
            "    Found existing installation: thinc 8.2.5\n",
            "    Uninstalling thinc-8.2.5:\n",
            "      Successfully uninstalled thinc-8.2.5\n",
            "  Attempting uninstall: spacy\n",
            "    Found existing installation: spacy 3.7.5\n",
            "    Uninstalling spacy-3.7.5:\n",
            "      Successfully uninstalled spacy-3.7.5\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "en-core-web-sm 3.7.1 requires spacy<3.8.0,>=3.7.2, but you have spacy 3.8.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed blis-1.1.0 spacy-3.8.3 thinc-8.3.3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "blis",
                  "spacy",
                  "thinc"
                ]
              },
              "id": "8dcb7f87858d4227be279abaec0e4ae5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy<2 in /usr/local/lib/python3.10/dist-packages (1.26.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# generate config.cfg from base_config.cfg\n",
        "!python -m spacy init fill-config base_config.cfg config.cfg"
      ],
      "metadata": {
        "id": "0aRjL9jqC-5k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb70377a-546e-477b-c947-0f8ff5d1a657"
      },
      "id": "0aRjL9jqC-5k",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[38;5;2m✔ Auto-filled config with all values\u001b[0m\n",
            "\u001b[38;5;2m✔ Saved config\u001b[0m\n",
            "config.cfg\n",
            "You can now add your data and train your pipeline:\n",
            "python -m spacy train config.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# vector used for spacy ner\n",
        "!python -m spacy download en_core_web_lg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9wb_aBw9X2NU",
        "outputId": "00761b57-1c02-4118-fb15-c5a93167d63d"
      },
      "id": "9wb_aBw9X2NU",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting en-core-web-lg==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-3.8.0/en_core_web_lg-3.8.0-py3-none-any.whl (400.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m400.7/400.7 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: en-core-web-lg\n",
            "Successfully installed en-core-web-lg-3.8.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_lg')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# debugging and profiling data.\n",
        "!python -m spacy debug data config.cfg"
      ],
      "metadata": {
        "id": "4CmZiCfjloyM",
        "outputId": "893ecea3-850a-410c-d26d-b210f8b57a55",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "4CmZiCfjloyM",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m\n",
            "============================ Data file validation ============================\u001b[0m\n",
            "tokenizer_config.json: 100% 25.0/25.0 [00:00<00:00, 150kB/s]\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "config.json: 100% 481/481 [00:00<00:00, 2.70MB/s]\n",
            "vocab.json: 100% 899k/899k [00:00<00:00, 4.17MB/s]\n",
            "merges.txt: 100% 456k/456k [00:00<00:00, 2.13MB/s]\n",
            "tokenizer.json: 100% 1.36M/1.36M [00:00<00:00, 3.13MB/s]\n",
            "model.safetensors: 100% 499M/499M [00:02<00:00, 232MB/s]\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "\u001b[38;5;2m✔ Pipeline can be initialized with data\u001b[0m\n",
            "\u001b[38;5;2m✔ Corpus is loadable\u001b[0m\n",
            "\u001b[1m\n",
            "=============================== Training stats ===============================\u001b[0m\n",
            "Language: en\n",
            "Training pipeline: transformer, ner\n",
            "880 training docs\n",
            "221 evaluation docs\n",
            "\u001b[38;5;3m⚠ 3 training examples also in evaluation data\u001b[0m\n",
            "\u001b[38;5;3m⚠ Low number of examples to train a new pipeline (880)\u001b[0m\n",
            "\u001b[1m\n",
            "============================== Vocab & Vectors ==============================\u001b[0m\n",
            "\u001b[38;5;4mℹ 435225 total word(s) in the data (28696 unique)\u001b[0m\n",
            "\u001b[38;5;4mℹ No word vectors present in the package\u001b[0m\n",
            "\u001b[1m\n",
            "========================== Named Entity Recognition ==========================\u001b[0m\n",
            "\u001b[38;5;4mℹ 11 label(s)\u001b[0m\n",
            "0 missing value(s) (tokens with '-' label)\n",
            "\u001b[38;5;2m✔ Good amount of examples for all labels\u001b[0m\n",
            "\u001b[38;5;2m✔ Examples without occurrences available for all labels\u001b[0m\n",
            "\u001b[38;5;2m✔ No entities consisting of or starting/ending with whitespace\u001b[0m\n",
            "\u001b[38;5;2m✔ No entities crossing sentence boundaries\u001b[0m\n",
            "\u001b[1m\n",
            "================================== Summary ==================================\u001b[0m\n",
            "\u001b[38;5;2m✔ 6 checks passed\u001b[0m\n",
            "\u001b[38;5;3m⚠ 2 warnings\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# debugging and profiling configs and implementations.\n",
        "!python -m spacy debug config config.cfg"
      ],
      "metadata": {
        "id": "WcsJmxNRkvrg",
        "outputId": "abe6be9c-e1e7-441c-8963-89248928ab94",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "WcsJmxNRkvrg",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m\n",
            "============================= Config validation =============================\u001b[0m\n",
            "\u001b[1m\n",
            "===================== Config validation for [initialize] =====================\u001b[0m\n",
            "\u001b[1m\n",
            "====================== Config validation for [training] ======================\u001b[0m\n",
            "\u001b[38;5;2m✔ Config is valid\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train model using hyperparameters set in config.cfg\n",
        "# save trained model in spacy_output/ dir\n",
        "\n",
        "# using cpu\n",
        "# !python -m spacy train config.cfg --output ./spacy_output\n",
        "\n",
        "# using gpu\n",
        "!python -m spacy train config.cfg --gpu-id 0 --output ./spacy_output\n",
        "\n",
        "# save output dir into drive\n",
        "!cp -r ./spacy_output /content/drive/MyDrive/FYP/Implementation/"
      ],
      "metadata": {
        "id": "Jav_l46BEDjF",
        "outputId": "3ee2d61a-90e5-4767-b2aa-7c40bf7a4542",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "Jav_l46BEDjF",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[38;5;2m✔ Created output directory: spacy_output\u001b[0m\n",
            "\u001b[38;5;4mℹ Saving to output directory: spacy_output\u001b[0m\n",
            "\u001b[38;5;4mℹ Using GPU: 0\u001b[0m\n",
            "\u001b[1m\n",
            "=========================== Initializing pipeline ===========================\u001b[0m\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
            "\u001b[1m\n",
            "============================= Training pipeline =============================\u001b[0m\n",
            "\u001b[38;5;4mℹ Pipeline: ['transformer', 'ner']\u001b[0m\n",
            "\u001b[38;5;4mℹ Initial learn rate: 0.0\u001b[0m\n",
            "E    #       LOSS TRANS...  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
            "---  ------  -------------  --------  ------  ------  ------  ------\n",
            "  0       0        6591.26   1430.35    3.50    1.91   20.65    0.03\n",
            "  0     200      192137.65  63564.72   33.94   45.36   27.11    0.34\n",
            "  1     400       20729.10  27951.65   61.40   64.22   58.81    0.61\n",
            "  2     600       11688.74  22539.74   63.49   57.04   71.60    0.63\n",
            "  2     800       10495.29  20862.88   66.81   67.58   66.06    0.67\n",
            "  3    1000        8383.68  17231.56   66.83   70.11   63.84    0.67\n",
            "  4    1200        8535.24  16741.70   68.00   74.98   62.20    0.68\n",
            "  5    1400        7348.44  15126.57   66.99   74.18   61.07    0.67\n",
            "  5    1600        7135.56  14469.59   65.09   59.53   71.81    0.65\n",
            "  6    1800        5946.13  12130.43   64.65   56.68   75.24    0.65\n",
            "  7    2000        5523.56  11327.70   66.28   61.19   72.30    0.66\n",
            "  8    2200        5767.03  11019.51   66.33   75.36   59.23    0.66\n",
            "  8    2400        4254.87   8607.55   67.41   69.76   65.22    0.67\n",
            "  9    2600        5159.58   8910.32   66.83   63.65   70.34    0.67\n",
            " 10    2800        3939.16   7888.98   67.53   67.38   67.68    0.68\n",
            "\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n",
            "spacy_output/model-last\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate trained model performance\n",
        "# store output and visualization into result/ dir\n",
        "\n",
        "# use cpu\n",
        "# !python -m spacy evaluate spacy_output/model-best spacy_ner_data/test_data.spacy -dp spacy_output\n",
        "\n",
        "# use gpu\n",
        "!python -m spacy evaluate spacy_output/model-best spacy_ner_data/test_data.spacy --gpu-id 0 -dp spacy_output"
      ],
      "metadata": {
        "id": "V2wzIOsWJgkG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3ae5caa-2ef3-47c0-b192-d23a18728043"
      },
      "id": "V2wzIOsWJgkG",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[38;5;4mℹ Using GPU: 0\u001b[0m\n",
            "/usr/local/lib/python3.10/dist-packages/spacy_transformers/layers/hf_shim.py:124: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  self._model.load_state_dict(torch.load(filelike, map_location=device))\n",
            "\u001b[1m\n",
            "================================== Results ==================================\u001b[0m\n",
            "\n",
            "TOK     100.00\n",
            "NER P   74.98 \n",
            "NER R   62.20 \n",
            "NER F   68.00 \n",
            "SPEED   6366  \n",
            "\n",
            "\u001b[1m\n",
            "=============================== NER (per type) ===============================\u001b[0m\n",
            "\n",
            "                P       R       F\n",
            "LOC         82.68   79.18   80.89\n",
            "PHONE       97.57   98.05   97.81\n",
            "NAME        91.63   92.44   92.04\n",
            "JOB         72.59   70.74   71.65\n",
            "SKILL       62.94   41.66   50.13\n",
            "COMPANY     76.86   71.09   73.86\n",
            "WORK PER    96.56   89.81   93.06\n",
            "UNI         68.24   71.38   69.77\n",
            "STUDY PER   78.76   71.70   75.06\n",
            "DEG         79.93   81.91   80.91\n",
            "EMAIL       95.34   97.35   96.34\n",
            "\n",
            "<IPython.core.display.HTML object>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/spacy/__main__.py\", line 4, in <module>\n",
            "    setup_cli()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/spacy/cli/_util.py\", line 87, in setup_cli\n",
            "    command(prog_name=COMMAND)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/click/core.py\", line 1157, in __call__\n",
            "    return self.main(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/typer/core.py\", line 743, in main\n",
            "    return _main(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/typer/core.py\", line 198, in _main\n",
            "    rv = self.invoke(ctx)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/click/core.py\", line 1688, in invoke\n",
            "    return _process_result(sub_ctx.command.invoke(sub_ctx))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/click/core.py\", line 1434, in invoke\n",
            "    return ctx.invoke(self.callback, **ctx.params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/click/core.py\", line 783, in invoke\n",
            "    return __callback(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/typer/main.py\", line 698, in wrapper\n",
            "    return callback(**use_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/spacy/cli/evaluate.py\", line 47, in evaluate_cli\n",
            "    evaluate(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/spacy/cli/evaluate.py\", line 141, in evaluate\n",
            "    render_parses(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/spacy/cli/evaluate.py\", line 208, in render_parses\n",
            "    file_.write(html)\n",
            "TypeError: write() argument must be str, not None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# make prediction\n",
        "\n",
        "import spacy_transformers\n",
        "import spacy\n",
        "import numpy as np\n",
        "np.float_ = np.float64\n",
        "import string\n",
        "from spacy import displacy\n",
        "\n",
        "resume_text = '''\n",
        "John Doe lives at 1234 Elm Street in Los Angeles, CA 90001. He can be reached at +1 (555) 123-4567 or via email at john.doe@example.com. John is a results-driven software engineer with over 5 years of experience in web development and cloud infrastructure, with strong knowledge of JavaScript, Python, and cloud technologies like AWS and Azure. Currently, he works as a Software Engineer at Google LLC in San Francisco, CA, where he has been employed since August 2019. In this role, he has developed scalable web applications using JavaScript, Node.js, and React, deployed and maintained cloud infrastructure on AWS, reducing downtime by 20%, and led a team of 4 engineers to enhance backend performance by 30%. Previously, he worked as a Junior Developer at Tech Innovators Inc. in Austin, TX, from July 2017 to July 2019, where he created RESTful APIs using Python and Flask, collaborated with front-end developers to build and deploy user-facing applications, and wrote unit and integration tests, improving code coverage by 15%.\n",
        "\n",
        "John holds a Master of Science in Computer Science from the University of California, Berkeley, with a graduation date of May 2017, and a Bachelor of Science in Information Technology from the University of Texas at Austin, graduated in May 2015. His skillset includes proficiency in programming languages like Python, JavaScript, and Java; frameworks such as React, Flask, and Django; cloud platforms including AWS, Google Cloud, and Azure; as well as other tools like Git, Docker, Kubernetes, and SQL. He is certified as an AWS Certified Solutions Architect – Associate, earned in 2020, and as a Google Professional Cloud Architect, earned in 2021'\n",
        "'''\n",
        "\n",
        "# convert text into small letter then remove punctuation\n",
        "resume_text = resume_text.lower()\n",
        "resume_text = resume_text.translate(str.maketrans('', '', string.punctuation))\n",
        "\n",
        "# load trained model\n",
        "nlp = spacy.load(\"/content/drive/MyDrive/FYP/Implementation/spacy_output/model-best\")\n",
        "\n",
        "# create a Spacy doc and add text to it\n",
        "doc = nlp(resume_text.lower())\n",
        "\n",
        "# print predicted entities in text\n",
        "# for ent in doc.ents:\n",
        "#     print(f\"{ent.text}: {ent.label_}\")\n",
        "\n",
        "# visualize predicted entities using displacy\n",
        "colors = {\n",
        "    \"NAME\": \"lightblue\",\n",
        "    \"LOC\": \"yellow\",\n",
        "    \"PHONE\": \"pink\",\n",
        "    \"EMAIL\": \"lightgreen\",\n",
        "    \"JOB\": \"orange\",\n",
        "    \"SKILL\": \"aqua\",\n",
        "    \"COMPANY\": \"violet\",\n",
        "    \"WORK PER\": \"salmon\",\n",
        "    \"DEG\": \"lightcoral\",\n",
        "    \"UNI\": \"lightgrey\",\n",
        "    \"STUDY PER\": \"peachpuff\",\n",
        "}\n",
        "options = {\"ents\": list(colors.keys()), \"colors\": colors}\n",
        "displacy.render(doc, style=\"ent\", jupyter=True, options=options)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 771
        },
        "id": "UXAlZZkEeeMc",
        "outputId": "9e35d319-de47-40c8-f19e-defaf1fb86b0"
      },
      "id": "UXAlZZkEeeMc",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/spacy/util.py:910: UserWarning: [W095] Model 'en_pipeline' (0.0.0) was trained with spaCy v3.8.3 and may not be 100% compatible with the current version (3.7.5). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
            "  warnings.warn(warn_msg)\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/util.py:1740: UserWarning: [W111] Jupyter notebook detected: if using `prefer_gpu()` or `require_gpu()`, include it in the same cell right before `spacy.load()` to ensure that the model is loaded on the correct device. More information: http://spacy.io/usage/v3#jupyter-notebook-gpu\n",
            "  warnings.warn(Warnings.W111)\n",
            "/usr/local/lib/python3.10/dist-packages/spacy_transformers/layers/hf_shim.py:124: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  self._model.load_state_dict(torch.load(filelike, map_location=device))\n",
            "/usr/local/lib/python3.10/dist-packages/thinc/shims/pytorch.py:114: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  # NB: Previously this was torch.cuda.amp.autocast, passing a boolean\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\"><br>\n",
              "<mark class=\"entity\" style=\"background: lightblue; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    john doe\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NAME</span>\n",
              "</mark>\n",
              " lives at 1234 elm street in \n",
              "<mark class=\"entity\" style=\"background: yellow; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    los angeles\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
              "</mark>\n",
              " ca 90001 he can be reached at \n",
              "<mark class=\"entity\" style=\"background: pink; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    1 555 1234567\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PHONE</span>\n",
              "</mark>\n",
              " or via email at \n",
              "<mark class=\"entity\" style=\"background: lightgreen; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    johndoeexamplecom\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">EMAIL</span>\n",
              "</mark>\n",
              " \n",
              "<mark class=\"entity\" style=\"background: lightblue; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    john is\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NAME</span>\n",
              "</mark>\n",
              " a resultsdriven \n",
              "<mark class=\"entity\" style=\"background: orange; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    software engineer\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">JOB</span>\n",
              "</mark>\n",
              " with over 5 years of experience in \n",
              "<mark class=\"entity\" style=\"background: aqua; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    web development\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">SKILL</span>\n",
              "</mark>\n",
              " and \n",
              "<mark class=\"entity\" style=\"background: aqua; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    cloud infrastructure\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">SKILL</span>\n",
              "</mark>\n",
              " with strong knowledge of \n",
              "<mark class=\"entity\" style=\"background: aqua; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    javascript\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">SKILL</span>\n",
              "</mark>\n",
              " \n",
              "<mark class=\"entity\" style=\"background: aqua; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    python\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">SKILL</span>\n",
              "</mark>\n",
              " and cloud technologies like \n",
              "<mark class=\"entity\" style=\"background: aqua; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    aws\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">SKILL</span>\n",
              "</mark>\n",
              " and \n",
              "<mark class=\"entity\" style=\"background: aqua; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    azure\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">SKILL</span>\n",
              "</mark>\n",
              " currently he works as \n",
              "<mark class=\"entity\" style=\"background: orange; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    a software engineer\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">JOB</span>\n",
              "</mark>\n",
              " at \n",
              "<mark class=\"entity\" style=\"background: violet; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    google llc\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">COMPANY</span>\n",
              "</mark>\n",
              " in \n",
              "<mark class=\"entity\" style=\"background: yellow; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    san francisco\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
              "</mark>\n",
              " ca where he has been employed since \n",
              "<mark class=\"entity\" style=\"background: salmon; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    august 2019\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">WORK PER</span>\n",
              "</mark>\n",
              " in this role he has developed scalable web applications using javascript \n",
              "<mark class=\"entity\" style=\"background: aqua; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    nodejs\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">SKILL</span>\n",
              "</mark>\n",
              " and react deployed and maintained cloud infrastructure on aws reducing downtime by 20 and led a team of 4 engineers to enhance backend performance by 30 previously he worked as \n",
              "<mark class=\"entity\" style=\"background: orange; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    a junior developer\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">JOB</span>\n",
              "</mark>\n",
              " at \n",
              "<mark class=\"entity\" style=\"background: violet; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    tech innovators inc\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">COMPANY</span>\n",
              "</mark>\n",
              " in \n",
              "<mark class=\"entity\" style=\"background: yellow; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    austin\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
              "</mark>\n",
              " tx from \n",
              "<mark class=\"entity\" style=\"background: salmon; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    july 2017 to july 2019\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">WORK PER</span>\n",
              "</mark>\n",
              " where he created \n",
              "<mark class=\"entity\" style=\"background: aqua; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    restful apis\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">SKILL</span>\n",
              "</mark>\n",
              " using python and \n",
              "<mark class=\"entity\" style=\"background: aqua; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    flask\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">SKILL</span>\n",
              "</mark>\n",
              " collaborated with \n",
              "<mark class=\"entity\" style=\"background: orange; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    frontend developers\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">JOB</span>\n",
              "</mark>\n",
              " to build and deploy userfacing applications and wrote unit and integration tests improving code coverage by 15<br><br>john holds \n",
              "<mark class=\"entity\" style=\"background: lightcoral; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    a master of science in computer science\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DEG</span>\n",
              "</mark>\n",
              " \n",
              "<mark class=\"entity\" style=\"background: lightgrey; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    from the university of california\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">UNI</span>\n",
              "</mark>\n",
              " \n",
              "<mark class=\"entity\" style=\"background: yellow; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    berkeley\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
              "</mark>\n",
              " with a graduation date of \n",
              "<mark class=\"entity\" style=\"background: peachpuff; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    may 2017\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">STUDY PER</span>\n",
              "</mark>\n",
              " and \n",
              "<mark class=\"entity\" style=\"background: lightcoral; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    a bachelor of science in information technology\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DEG</span>\n",
              "</mark>\n",
              " \n",
              "<mark class=\"entity\" style=\"background: lightgrey; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    from the university of texas\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">UNI</span>\n",
              "</mark>\n",
              " at \n",
              "<mark class=\"entity\" style=\"background: yellow; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    austin\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
              "</mark>\n",
              " graduated in \n",
              "<mark class=\"entity\" style=\"background: peachpuff; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    may 2015\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">STUDY PER</span>\n",
              "</mark>\n",
              " his skillset includes proficiency in programming languages like \n",
              "<mark class=\"entity\" style=\"background: aqua; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    python\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">SKILL</span>\n",
              "</mark>\n",
              " \n",
              "<mark class=\"entity\" style=\"background: aqua; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    javascript\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">SKILL</span>\n",
              "</mark>\n",
              " and \n",
              "<mark class=\"entity\" style=\"background: aqua; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    java\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">SKILL</span>\n",
              "</mark>\n",
              " frameworks such as \n",
              "<mark class=\"entity\" style=\"background: aqua; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    react flask\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">SKILL</span>\n",
              "</mark>\n",
              " and \n",
              "<mark class=\"entity\" style=\"background: aqua; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    django\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">SKILL</span>\n",
              "</mark>\n",
              " cloud platforms including \n",
              "<mark class=\"entity\" style=\"background: aqua; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    aws\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">SKILL</span>\n",
              "</mark>\n",
              " \n",
              "<mark class=\"entity\" style=\"background: aqua; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    google cloud\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">SKILL</span>\n",
              "</mark>\n",
              " and \n",
              "<mark class=\"entity\" style=\"background: aqua; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    azure\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">SKILL</span>\n",
              "</mark>\n",
              " as well as other tools like \n",
              "<mark class=\"entity\" style=\"background: aqua; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    git\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">SKILL</span>\n",
              "</mark>\n",
              " \n",
              "<mark class=\"entity\" style=\"background: aqua; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    docker\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">SKILL</span>\n",
              "</mark>\n",
              " \n",
              "<mark class=\"entity\" style=\"background: aqua; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    kubernetes\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">SKILL</span>\n",
              "</mark>\n",
              " and \n",
              "<mark class=\"entity\" style=\"background: aqua; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    sql\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">SKILL</span>\n",
              "</mark>\n",
              " he is certified as an aws certified \n",
              "<mark class=\"entity\" style=\"background: orange; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    solutions architect\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">JOB</span>\n",
              "</mark>\n",
              " – associate earned in 2020 and as a google professional cloud architect earned in 2021<br></div></span>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# make prediction\n",
        "\n",
        "import spacy\n",
        "import string\n",
        "from spacy import displacy\n",
        "\n",
        "resume_text = '''\n",
        "Zi Qing Chew\n",
        "chewziqing@gmail.com | 016-2892475 | Kuala Lumpur, Malaysia | linkedin.com/in/ziqingchew | github.com/chewzzz1014\n",
        "EDUCATION\n",
        "\n",
        "Universiti Putra Malaysia\t\t\t\t\t                                                   Oct 2021 - Current\n",
        "Bachelor in Computer Science with Honours\n",
        "Expected to graduate in July 2025. CGPA: 3.99\n",
        "\n",
        "WORK EXPERIENCE\n",
        "\n",
        "Ant International \t\t\t\t\t\t\t\t\t          \tJuly 2024 – Oct 2024\n",
        "Java Engineer Intern\t\t\t\t\t\t\t                               Kuala Lumpur, Malaysia\n",
        "Collaborated in developing an audit logging feature for Ant Group’s internal Foreign Exchange (FX) trade strategy system that records changes made by business users to trade strategies.\n",
        "Conducted comprehensive system analysis and project planning, delivering presentations to project stakeholders and QA teams prior to the development phase.\n",
        "Utilised Ant Group’s internal frameworks, middleware, and tools to implement the audit logging feature.\n",
        "Skills: Java, Spring, Sofaboot, Ant Group internal middlewares (ZDAL, DRM, Ant Scheduler, Msg Broker)\n",
        "Howuku  \t\t\t\t\t\t\t\t\t          \t             Feb 2023 – Sep 2023\n",
        "Software Developer Intern\t\t\t\t\t\t\t                    Kuala Lumpur, Malaysia\n",
        "Developed and optimized A/B testing features, including code editor and previewer for CSS and JavaScript modifications for experiment variations.\n",
        "Expanded A/B testing targeting rule by incorporating website visitor's OS, device, and browser rules.\n",
        "Automated experiment-stopping criteria and email notifications based on user-defined experiment termination conditions.\n",
        "Collaborated with cross-functional teams to debug, troubleshoot, and enhance Howuku platform features based on user feedback and performance data.\n",
        "Skills: JavaScript, Bootstrap, Vue.js, Express.js, MySQL\n",
        "\n",
        "PROJECTS\n",
        "\n",
        "Personal Portfolio Website (chewzzz1014.github.io/portfolio-website)\n",
        "Designed, developed and deployed personalised portfolio website featuring skills, selected projects, and downloadable resume.\n",
        "Skills: JavaScript, React.js, CSS, Bootstrap\n",
        "Depression Level Detection Chatbot (https://github.com/chewzzz1014/health-ease-project)\n",
        "Developed machine learning application that evaluates a message's depression level and provided tailored mental health advice and information based on the depression severity.\n",
        "Skills: Python, pandas, scikit-learn, Keras, FastAPI, Gradio\n",
        "Clothing Store Website (https://github.com/chewzzz1014/CSC3402-MVC-Project)\n",
        "Worked in team to build a CRUD Spring Boot application with attractive interfaces, data persistence, authentication and authorisation.\n",
        "Developed the backend of the application that involves querying the database, building REST endpoints and implementing Thymeleaf in HTML for dynamic contents.\n",
        "Skills: Spring Boot, Spring MVC, Thymeleaf, Hibernate, Bootstrap\n",
        "\n",
        "SKILLS\n",
        "Programming Languages: Java, Python, HTML, CSS, JavaScript, MySQL, OracleSQL\n",
        "Frameworks and Libraries: Spring, Spring Boot, TypeScript, Node.js, Express.js, React.js, Vue.js, Bootstrap, Tailwind CSS\n",
        "Tools: Git, Github, Jira, Tableau, Excel, Jupyter Notebook, Google Colab, VSCode, IntelliJ\n",
        "'''\n",
        "\n",
        "# convert text into small letter then remove punctuation\n",
        "# resume_text = resume_text.lower()\n",
        "resume_text = resume_text.translate(str.maketrans('', '', string.punctuation))\n",
        "\n",
        "# create a Spacy doc and add text to it\n",
        "doc = nlp(resume_text)\n",
        "\n",
        "# load trained model\n",
        "nlp = spacy.load(\"/content/drive/MyDrive/FYP/Implementation/spacy_output/model-best\")\n",
        "\n",
        "colors = {\n",
        "    \"NAME\": \"lightblue\",\n",
        "    \"LOC\": \"yellow\",\n",
        "    \"PHONE\": \"pink\",\n",
        "    \"EMAIL\": \"lightgreen\",\n",
        "    \"JOB\": \"orange\",\n",
        "    \"SKILL\": \"aqua\",\n",
        "    \"COMPANY\": \"violet\",\n",
        "    \"WORK PER\": \"salmon\",\n",
        "    \"DEG\": \"lightcoral\",\n",
        "    \"UNI\": \"lightgrey\",\n",
        "    \"STUDY PER\": \"peachpuff\",\n",
        "}\n",
        "options = {\"ents\": list(colors.keys()), \"colors\": colors}\n",
        "displacy.render(doc, style=\"ent\", jupyter=True, options=options)"
      ],
      "metadata": {
        "id": "H8YjohdI6_QJ",
        "outputId": "319d122f-dc4c-43c7-8438-3551ef2ffe9d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "id": "H8YjohdI6_QJ",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/thinc/shims/pytorch.py:114: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  # NB: Previously this was torch.cuda.amp.autocast, passing a boolean\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/util.py:910: UserWarning: [W095] Model 'en_pipeline' (0.0.0) was trained with spaCy v3.8.3 and may not be 100% compatible with the current version (3.7.5). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
            "  warnings.warn(warn_msg)\n",
            "/usr/local/lib/python3.10/dist-packages/spacy_transformers/layers/hf_shim.py:124: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  self._model.load_state_dict(torch.load(filelike, map_location=device))\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\"><br>\n",
              "<mark class=\"entity\" style=\"background: lightblue; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Zi Qing\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NAME</span>\n",
              "</mark>\n",
              " Chew<br>\n",
              "<mark class=\"entity\" style=\"background: lightgreen; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    chewziqinggmailcom\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">EMAIL</span>\n",
              "</mark>\n",
              "  \n",
              "<mark class=\"entity\" style=\"background: pink; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    0162892475\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PHONE</span>\n",
              "</mark>\n",
              "  \n",
              "<mark class=\"entity\" style=\"background: yellow; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Kuala\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
              "</mark>\n",
              " \n",
              "<mark class=\"entity\" style=\"background: yellow; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Lumpur\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
              "</mark>\n",
              " Malaysia  linkedincominziqingchew  githubcomchewzzz1014<br>EDUCATION<br><br>\n",
              "<mark class=\"entity\" style=\"background: lightgrey; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Universiti Putra\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">UNI</span>\n",
              "</mark>\n",
              " Malaysia\t\t\t\t\t                                                   Oct 2021  Current<br>\n",
              "<mark class=\"entity\" style=\"background: lightcoral; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Bachelor in Computer Science\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DEG</span>\n",
              "</mark>\n",
              " with Honours<br>Expected to graduate in July 2025 CGPA 399<br><br>WORK EXPERIENCE<br><br>\n",
              "<mark class=\"entity\" style=\"background: violet; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Ant International\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">COMPANY</span>\n",
              "</mark>\n",
              " \t\t\t\t\t\t\t\t\t          \tJuly 2024 – Oct 2024<br>\n",
              "<mark class=\"entity\" style=\"background: orange; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Java Engineer Intern\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">JOB</span>\n",
              "</mark>\n",
              "\t\t\t\t\t\t\t                               \n",
              "<mark class=\"entity\" style=\"background: yellow; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Kuala\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
              "</mark>\n",
              " Lumpur Malaysia<br>Collaborated in developing an audit logging feature for Ant Group’s internal Foreign Exchange FX trade strategy system that records changes made by business users to trade strategies<br>Conducted comprehensive system analysis and project planning delivering presentations to project stakeholders and QA teams prior to the development phase<br>Utilised Ant Group’s internal frameworks middleware and tools to implement the audit logging feature<br>Skills \n",
              "<mark class=\"entity\" style=\"background: aqua; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Java\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">SKILL</span>\n",
              "</mark>\n",
              " \n",
              "<mark class=\"entity\" style=\"background: aqua; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Spring\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">SKILL</span>\n",
              "</mark>\n",
              " Sofaboot Ant Group internal middlewares ZDAL DRM Ant Scheduler Msg Broker<br>Howuku  \t\t\t\t\t\t\t\t\t          \t             \n",
              "<mark class=\"entity\" style=\"background: salmon; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Feb 2023 –\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">WORK PER</span>\n",
              "</mark>\n",
              " Sep 2023<br>\n",
              "<mark class=\"entity\" style=\"background: orange; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Software Developer\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">JOB</span>\n",
              "</mark>\n",
              " Intern\t\t\t\t\t\t\t                    \n",
              "<mark class=\"entity\" style=\"background: yellow; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Kuala\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
              "</mark>\n",
              " \n",
              "<mark class=\"entity\" style=\"background: yellow; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Lumpur\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
              "</mark>\n",
              " Malaysia<br>Developed and optimized AB testing features including code editor and previewer for CSS and \n",
              "<mark class=\"entity\" style=\"background: aqua; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    JavaScript\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">SKILL</span>\n",
              "</mark>\n",
              " modifications for experiment variations<br>Expanded AB testing targeting rule by incorporating website visitors OS device and browser rules<br>Automated experimentstopping criteria and email notifications based on userdefined experiment termination conditions<br>Collaborated with crossfunctional teams to debug troubleshoot and enhance Howuku platform features based on user feedback and performance data<br>Skills JavaScript Bootstrap \n",
              "<mark class=\"entity\" style=\"background: aqua; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Vuejs\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">SKILL</span>\n",
              "</mark>\n",
              " \n",
              "<mark class=\"entity\" style=\"background: aqua; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Expressjs\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">SKILL</span>\n",
              "</mark>\n",
              " \n",
              "<mark class=\"entity\" style=\"background: aqua; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    MySQL\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">SKILL</span>\n",
              "</mark>\n",
              "<br><br>PROJECTS<br><br>Personal Portfolio Website chewzzz1014githubioportfoliowebsite<br>Designed developed and deployed personalised portfolio website featuring skills selected projects and downloadable resume<br>Skills JavaScript Reactjs CSS Bootstrap<br>Depression Level Detection Chatbot httpsgithubcomchewzzz1014healtheaseproject<br>Developed machine learning application that evaluates a messages depression level and provided tailored mental health advice and information based on the depression severity<br>Skills Python \n",
              "<mark class=\"entity\" style=\"background: aqua; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    pandas\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">SKILL</span>\n",
              "</mark>\n",
              " scikitlearn \n",
              "<mark class=\"entity\" style=\"background: aqua; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Keras\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">SKILL</span>\n",
              "</mark>\n",
              " FastAPI \n",
              "<mark class=\"entity\" style=\"background: aqua; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Gradio\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">SKILL</span>\n",
              "</mark>\n",
              "<br>Clothing Store Website httpsgithubcomchewzzz1014CSC3402MVCProject<br>Worked in team to build a CRUD \n",
              "<mark class=\"entity\" style=\"background: aqua; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Spring Boot\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">SKILL</span>\n",
              "</mark>\n",
              " application with attractive interfaces data persistence authentication and authorisation<br>Developed the backend of the application that involves querying the database building REST endpoints and implementing Thymeleaf in HTML for dynamic contents<br>Skills Spring Boot Spring MVC Thymeleaf Hibernate Bootstrap<br><br>SKILLS<br>Programming Languages Java Python HTML CSS JavaScript \n",
              "<mark class=\"entity\" style=\"background: aqua; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    MySQL\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">SKILL</span>\n",
              "</mark>\n",
              " OracleSQL<br>Frameworks and Libraries Spring Spring Boot TypeScript Nodejs Expressjs Reactjs Vuejs Bootstrap Tailwind CSS<br>Tools Git Github \n",
              "<mark class=\"entity\" style=\"background: aqua; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Jira\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">SKILL</span>\n",
              "</mark>\n",
              " \n",
              "<mark class=\"entity\" style=\"background: aqua; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Tableau\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">SKILL</span>\n",
              "</mark>\n",
              " \n",
              "<mark class=\"entity\" style=\"background: aqua; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Excel\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">SKILL</span>\n",
              "</mark>\n",
              " Jupyter Notebook \n",
              "<mark class=\"entity\" style=\"background: aqua; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Google Colab\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">SKILL</span>\n",
              "</mark>\n",
              " VSCode IntelliJ<br></div></span>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Flair NER"
      ],
      "metadata": {
        "id": "1z_niSalE0uT"
      },
      "id": "1z_niSalE0uT"
    },
    {
      "cell_type": "code",
      "source": [
        "# install flair library\n",
        "!pip install flair"
      ],
      "metadata": {
        "id": "lsEUGnPpnjuU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7804e811-830b-4b00-a2b7-741558bfd287"
      },
      "id": "lsEUGnPpnjuU",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting flair\n",
            "  Downloading flair-0.14.0-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting boto3>=1.20.27 (from flair)\n",
            "  Downloading boto3-1.35.79-py3-none-any.whl.metadata (6.7 kB)\n",
            "Collecting conllu<5.0.0,>=4.0 (from flair)\n",
            "  Downloading conllu-4.5.3-py2.py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: deprecated>=1.2.13 in /usr/local/lib/python3.10/dist-packages (from flair) (1.2.15)\n",
            "Collecting ftfy>=6.1.0 (from flair)\n",
            "  Downloading ftfy-6.3.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: gdown>=4.4.0 in /usr/local/lib/python3.10/dist-packages (from flair) (5.2.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from flair) (0.26.3)\n",
            "Collecting langdetect>=1.0.9 (from flair)\n",
            "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: lxml>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from flair) (5.3.0)\n",
            "Requirement already satisfied: matplotlib>=2.2.3 in /usr/local/lib/python3.10/dist-packages (from flair) (3.8.0)\n",
            "Requirement already satisfied: more-itertools>=8.13.0 in /usr/local/lib/python3.10/dist-packages (from flair) (10.5.0)\n",
            "Collecting mpld3>=0.3 (from flair)\n",
            "  Downloading mpld3-0.5.10-py3-none-any.whl.metadata (5.1 kB)\n",
            "Collecting pptree>=3.1 (from flair)\n",
            "  Downloading pptree-3.1.tar.gz (3.0 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from flair) (2.8.2)\n",
            "Collecting pytorch-revgrad>=0.2.0 (from flair)\n",
            "  Downloading pytorch_revgrad-0.2.0-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from flair) (2024.9.11)\n",
            "Requirement already satisfied: scikit-learn>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from flair) (1.5.2)\n",
            "Collecting segtok>=1.5.11 (from flair)\n",
            "  Downloading segtok-1.5.11-py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting sqlitedict>=2.0.0 (from flair)\n",
            "  Downloading sqlitedict-2.1.0.tar.gz (21 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tabulate>=0.8.10 in /usr/local/lib/python3.10/dist-packages (from flair) (0.9.0)\n",
            "Requirement already satisfied: torch!=1.8,>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from flair) (2.5.1+cu121)\n",
            "Requirement already satisfied: tqdm>=4.63.0 in /usr/local/lib/python3.10/dist-packages (from flair) (4.66.6)\n",
            "Collecting transformer-smaller-training-vocab>=0.2.3 (from flair)\n",
            "  Downloading transformer_smaller_training_vocab-0.4.0-py3-none-any.whl.metadata (8.1 kB)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.18.0 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]<5.0.0,>=4.18.0->flair) (4.46.3)\n",
            "Collecting wikipedia-api>=0.5.7 (from flair)\n",
            "  Downloading wikipedia_api-0.7.1.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting semver<4.0.0,>=3.0.0 (from flair)\n",
            "  Downloading semver-3.0.2-py3-none-any.whl.metadata (5.0 kB)\n",
            "Collecting bioc<3.0.0,>=2.0.0 (from flair)\n",
            "  Downloading bioc-2.1-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting jsonlines>=1.2.0 (from bioc<3.0.0,>=2.0.0->flair)\n",
            "  Downloading jsonlines-4.0.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting intervaltree (from bioc<3.0.0,>=2.0.0->flair)\n",
            "  Downloading intervaltree-3.1.0.tar.gz (32 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting docopt (from bioc<3.0.0,>=2.0.0->flair)\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting botocore<1.36.0,>=1.35.79 (from boto3>=1.20.27->flair)\n",
            "  Downloading botocore-1.35.79-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting jmespath<2.0.0,>=0.7.1 (from boto3>=1.20.27->flair)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting s3transfer<0.11.0,>=0.10.0 (from boto3>=1.20.27->flair)\n",
            "  Downloading s3transfer-0.10.4-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from deprecated>=1.2.13->flair) (1.17.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from ftfy>=6.1.0->flair) (0.2.13)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown>=4.4.0->flair) (4.12.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown>=4.4.0->flair) (3.16.1)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown>=4.4.0->flair) (2.32.3)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.10.0->flair) (2024.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.10.0->flair) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.10.0->flair) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.10.0->flair) (4.12.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from langdetect>=1.0.9->flair) (1.16.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.2.3->flair) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.2.3->flair) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.2.3->flair) (4.55.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.2.3->flair) (1.4.7)\n",
            "Requirement already satisfied: numpy<2,>=1.21 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.2.3->flair) (1.26.4)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.2.3->flair) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.2.3->flair) (3.2.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from mpld3>=0.3->flair) (3.1.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.2->flair) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.2->flair) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.2->flair) (3.5.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch!=1.8,>=1.5.0->flair) (3.4.2)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch!=1.8,>=1.5.0->flair) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch!=1.8,>=1.5.0->flair) (1.3.0)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.18.0->transformers[sentencepiece]<5.0.0,>=4.18.0->flair) (0.20.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.18.0->transformers[sentencepiece]<5.0.0,>=4.18.0->flair) (0.4.5)\n",
            "Requirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]<5.0.0,>=4.18.0->flair) (0.2.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]<5.0.0,>=4.18.0->flair) (4.25.5)\n",
            "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /usr/local/lib/python3.10/dist-packages (from botocore<1.36.0,>=1.35.79->boto3>=1.20.27->flair) (2.2.3)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonlines>=1.2.0->bioc<3.0.0,>=2.0.0->flair) (24.2.0)\n",
            "Requirement already satisfied: accelerate>=0.26.0 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece,torch]<5.0,>=4.1->transformer-smaller-training-vocab>=0.2.3->flair) (1.1.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown>=4.4.0->flair) (2.6)\n",
            "Collecting sortedcontainers<3.0,>=2.0 (from intervaltree->bioc<3.0.0,>=2.0.0->flair)\n",
            "  Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->mpld3>=0.3->flair) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown>=4.4.0->flair) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown>=4.4.0->flair) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown>=4.4.0->flair) (2024.8.30)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown>=4.4.0->flair) (1.7.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.26.0->transformers[sentencepiece,torch]<5.0,>=4.1->transformer-smaller-training-vocab>=0.2.3->flair) (5.9.5)\n",
            "Downloading flair-0.14.0-py3-none-any.whl (776 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m776.5/776.5 kB\u001b[0m \u001b[31m53.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bioc-2.1-py3-none-any.whl (33 kB)\n",
            "Downloading boto3-1.35.79-py3-none-any.whl (139 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.2/139.2 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading conllu-4.5.3-py2.py3-none-any.whl (16 kB)\n",
            "Downloading ftfy-6.3.1-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mpld3-0.5.10-py3-none-any.whl (202 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m202.6/202.6 kB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytorch_revgrad-0.2.0-py3-none-any.whl (4.6 kB)\n",
            "Downloading segtok-1.5.11-py3-none-any.whl (24 kB)\n",
            "Downloading semver-3.0.2-py3-none-any.whl (17 kB)\n",
            "Downloading transformer_smaller_training_vocab-0.4.0-py3-none-any.whl (14 kB)\n",
            "Downloading botocore-1.35.79-py3-none-any.whl (13.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m103.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Downloading jsonlines-4.0.0-py3-none-any.whl (8.7 kB)\n",
            "Downloading s3transfer-0.10.4-py3-none-any.whl (83 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.2/83.2 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
            "Building wheels for collected packages: langdetect, pptree, sqlitedict, wikipedia-api, docopt, intervaltree\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993222 sha256=16a403eda69d9e25a27603d4168e35fb6fa64b91b428b6c0aaf83a375cb08650\n",
            "  Stored in directory: /root/.cache/pip/wheels/95/03/7d/59ea870c70ce4e5a370638b5462a7711ab78fba2f655d05106\n",
            "  Building wheel for pptree (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pptree: filename=pptree-3.1-py3-none-any.whl size=4608 sha256=7167bae93c4d191f4b573b83886a3532e48cf1294670c19b5de4abe7deaca086\n",
            "  Stored in directory: /root/.cache/pip/wheels/9f/b6/0e/6f26eb9e6eb53ff2107a7888d72b5a6a597593956113037828\n",
            "  Building wheel for sqlitedict (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sqlitedict: filename=sqlitedict-2.1.0-py3-none-any.whl size=16864 sha256=ee6a15c9a662098c2201fcf5221d4793e6df71e1745ee573715822e649135d59\n",
            "  Stored in directory: /root/.cache/pip/wheels/79/d6/e7/304e0e6cb2221022c26d8161f7c23cd4f259a9e41e8bbcfabd\n",
            "  Building wheel for wikipedia-api (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wikipedia-api: filename=Wikipedia_API-0.7.1-py3-none-any.whl size=14346 sha256=1900f2b705dd55b1e2a76ce856e6dfdfa8bce8c61f27bf14eb51a9a70af3d4f1\n",
            "  Stored in directory: /root/.cache/pip/wheels/4c/96/18/b9201cc3e8b47b02b510460210cfd832ccf10c0c4dd0522962\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13706 sha256=a88cfe808e25db98e8af3c4b505149b11432f1fd146ab3ec470b90087dc887a2\n",
            "  Stored in directory: /root/.cache/pip/wheels/fc/ab/d4/5da2067ac95b36618c629a5f93f809425700506f72c9732fac\n",
            "  Building wheel for intervaltree (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for intervaltree: filename=intervaltree-3.1.0-py2.py3-none-any.whl size=26097 sha256=6e654b22daeee9282204595fbe87f47f8455966fb964b02fe3616e73483b7dd3\n",
            "  Stored in directory: /root/.cache/pip/wheels/fa/80/8c/43488a924a046b733b64de3fac99252674c892a4c3801c0a61\n",
            "Successfully built langdetect pptree sqlitedict wikipedia-api docopt intervaltree\n",
            "Installing collected packages: sqlitedict, sortedcontainers, pptree, docopt, semver, segtok, langdetect, jsonlines, jmespath, intervaltree, ftfy, conllu, wikipedia-api, botocore, bioc, s3transfer, pytorch-revgrad, mpld3, boto3, transformer-smaller-training-vocab, flair\n",
            "Successfully installed bioc-2.1 boto3-1.35.79 botocore-1.35.79 conllu-4.5.3 docopt-0.6.2 flair-0.14.0 ftfy-6.3.1 intervaltree-3.1.0 jmespath-1.0.1 jsonlines-4.0.0 langdetect-1.0.9 mpld3-0.5.10 pptree-3.1 pytorch-revgrad-0.2.0 s3transfer-0.10.4 segtok-1.5.11 semver-3.0.2 sortedcontainers-2.4.0 sqlitedict-2.1.0 transformer-smaller-training-vocab-0.4.0 wikipedia-api-0.7.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# convert json into flair data\n",
        "\n",
        "import json\n",
        "import random\n",
        "from typing import List, Dict, Tuple\n",
        "import spacy\n",
        "from collections import defaultdict\n",
        "\n",
        "class NERConverter:\n",
        "    def __init__(self):\n",
        "        # load pretrained model from Spacy library\n",
        "        # to create Spacy Doc object\n",
        "        self.nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "    # get BIOES label based on location of word\n",
        "    def get_bioes_label(self, token_index: int, entity_length: int, current_position: int, label: str) -> str:\n",
        "        \"\"\"\n",
        "        Convert to BIOES format\n",
        "        - S-: Single token entity\n",
        "        - B-: Beginning of multi-token entity\n",
        "        - I-: Inside of multi-token entity\n",
        "        - E-: End of multi-token entity\n",
        "        - O: Outside\n",
        "        \"\"\"\n",
        "        if entity_length == 1:\n",
        "            return f'S-{label}'\n",
        "        if current_position == 0:\n",
        "            return f'B-{label}'\n",
        "        if current_position == entity_length - 1:\n",
        "            return f'E-{label}'\n",
        "        return f'I-{label}'\n",
        "\n",
        "    # convert Label Studio's exported annotations in json format intto BIOES format\n",
        "    def convert_to_bioes_format(self, json_data: List[dict]) -> List[List[Tuple[str, str]]]:\n",
        "        \"\"\"Convert JSON annotations to BIOES format.\"\"\"\n",
        "        all_sentences = []\n",
        "\n",
        "        # process all annotation in json file\n",
        "        for item in json_data:\n",
        "            text = item['data']['Text']\n",
        "            doc = self.nlp(text)\n",
        "\n",
        "            # initialize character-level labels\n",
        "            char_labels = ['O'] * len(text)\n",
        "\n",
        "            # first pass: identify entity boundaries and lengths\n",
        "            entity_spans = []\n",
        "            if item['annotations'] and len(item['annotations']) > 0:\n",
        "                for ann in item['annotations'][0]['result']:\n",
        "                    if 'value' in ann:\n",
        "                        start = ann['value']['start']\n",
        "                        end = ann['value']['end']\n",
        "                        label = ann['value']['labels'][0]\n",
        "                        entity_spans.append((start, end, label))\n",
        "\n",
        "            # sort spans by start position\n",
        "            entity_spans.sort(key=lambda x: x[0])\n",
        "\n",
        "            # second pass: apply BIOES labels\n",
        "            for start, end, label in entity_spans:\n",
        "                # get tokens that are part of this entity\n",
        "                entity_text = text[start:end]\n",
        "                entity_doc = self.nlp(entity_text)\n",
        "                entity_length = len([token for token in entity_doc if not token.is_space])\n",
        "\n",
        "                # set labels for the entire span\n",
        "                current_token_idx = 0\n",
        "                for i in range(start, end):\n",
        "                    if i == start or text[i-1].isspace():\n",
        "                        char_labels[i] = self.get_bioes_label(i, entity_length, current_token_idx, label)\n",
        "                        current_token_idx += 1\n",
        "                    else:\n",
        "                        char_labels[i] = char_labels[i-1]\n",
        "\n",
        "            # convert to token-level labels\n",
        "            current_sentence = []\n",
        "            for sent in doc.sents:\n",
        "                for token in sent:\n",
        "                    # get the most common label for the token's characters\n",
        "                    token_chars_labels = char_labels[token.idx:token.idx + len(token.text)]\n",
        "                    label_counts = defaultdict(int)\n",
        "                    for char_label in token_chars_labels:\n",
        "                        label_counts[char_label] += 1\n",
        "\n",
        "                    token_label = max(label_counts.items(), key=lambda x: x[1])[0]\n",
        "                    current_sentence.append((token.text, token_label))\n",
        "\n",
        "                if current_sentence:\n",
        "                    all_sentences.append(current_sentence)\n",
        "                    current_sentence = []\n",
        "\n",
        "        return all_sentences\n",
        "\n",
        "    # write data in BIOES format into txt file\n",
        "    def write_flair_file(self, sentences: List[List[Tuple[str, str]]], filename: str):\n",
        "        \"\"\"Write sentences in BIOES format to file.\"\"\"\n",
        "        with open(filename, 'w', encoding='utf-8') as f:\n",
        "            for sentence in sentences:\n",
        "                for token, label in sentence:\n",
        "                    f.write(f'{token} {label}\\n')\n",
        "                f.write('\\n')\n",
        "\n",
        "    # convert json data into BIOES data\n",
        "    # split BIOES data into train and test\n",
        "    def convert_and_split(self, json_data: List[dict], train_file: str, test_file: str, test_ratio: float = 0.2):\n",
        "        \"\"\"Convert JSON to BIOES format and split into train/test sets.\"\"\"\n",
        "        all_sentences = self.convert_to_bioes_format(json_data)\n",
        "\n",
        "        # shuffle and split based on test_ratio\n",
        "        random.shuffle(all_sentences)\n",
        "        split_idx = int(len(all_sentences) * (1 - test_ratio))\n",
        "\n",
        "        # use list slicing to split\n",
        "        train_sentences = all_sentences[:split_idx]\n",
        "        test_sentences = all_sentences[split_idx:]\n",
        "\n",
        "        # write to txt files\n",
        "        self.write_flair_file(train_sentences, train_file)\n",
        "        self.write_flair_file(test_sentences, test_file)\n",
        "\n",
        "        return len(train_sentences), len(test_sentences)\n",
        "\n",
        "\n",
        "# load JSON data\n",
        "with open('/content/drive/MyDrive/FYP/Implementation/Resume Dataset/1100_resumes_annotated.json', 'r', encoding='utf-8') as f:\n",
        "  json_data = json.load(f)\n",
        "# with open('/content/1100_resumes_annotated.json', 'r', encoding='utf-8') as f:\n",
        "#   json_data = json.load(f)\n",
        "\n",
        "# load self-defined convert class\n",
        "converter = NERConverter()\n",
        "\n",
        "# convert json data into BIOES data and split into train and test\n",
        "train_count, test_count = converter.convert_and_split(\n",
        "    json_data,\n",
        "    train_file='flair_train.txt',\n",
        "    test_file='flair_test.txt',\n",
        "    test_ratio=0.2\n",
        ")\n",
        "print(f'Created {train_count} training sentences and {test_count} test sentences')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JYAkAghgs9k5",
        "outputId": "9138593d-5765-48f3-bd78-b92c9e10a767"
      },
      "id": "JYAkAghgs9k5",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created 1585 training sentences and 397 test sentences\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from flair.data import Corpus\n",
        "from flair.datasets import ColumnCorpus\n",
        "\n",
        "# define columns for CoNLL (0: word, 1: label)\n",
        "columns = {0: 'text', 1: 'ner'}\n",
        "\n",
        "# set data folder and train and test path\n",
        "data_folder = './'\n",
        "train_file = 'flair_train.txt'\n",
        "test_file = 'flair_test.txt'\n",
        "\n",
        "# load the corpus\n",
        "corpus: Corpus = ColumnCorpus(data_folder, columns,\n",
        "                              train_file=train_file,\n",
        "                              test_file=test_file,\n",
        "                              dev_file=None)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vl2-GpGBjpsi",
        "outputId": "de2b237f-ab6a-4b42-dbbe-8e1e53b46a61"
      },
      "id": "vl2-GpGBjpsi",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-12-12 08:49:56,886 Reading data from .\n",
            "2024-12-12 08:49:56,887 Train: flair_train.txt\n",
            "2024-12-12 08:49:56,888 Dev: None\n",
            "2024-12-12 08:49:56,889 Test: flair_test.txt\n",
            "2024-12-12 08:50:03,698 No dev split found. Using 10% (i.e. 158 samples) of the train split as dev data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# generate a dictionary of unique labels from the NER corpus.\n",
        "# this dictionary maps each named entity label in the dataset to an integer ID.\n",
        "tag_dictionary = corpus.make_label_dictionary(label_type='ner')\n",
        "print(\"Labels:\", tag_dictionary.get_items())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d_skLRc8i44m",
        "outputId": "d27d6b78-f728-4d0a-ea97-307772814ef6"
      },
      "id": "d_skLRc8i44m",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-12-12 08:50:07,914 Computing label dictionary. Progress:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "0it [00:00, ?it/s]\n",
            "1427it [00:00, 15331.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-12-12 08:50:08,055 Dictionary created for label 'ner' with 11 values: SKILL (seen 13598 times), JOB (seen 4002 times), LOC (seen 2659 times), WORK (seen 2596 times), COMPANY (seen 2355 times), UNI (seen 1175 times), DEG (seen 993 times), NAME (seen 788 times), STUDY (seen 778 times), PHONE (seen 752 times), EMAIL (seen 693 times)\n",
            "Labels: ['SKILL', 'JOB', 'LOC', 'WORK', 'COMPANY', 'UNI', 'DEG', 'NAME', 'STUDY', 'PHONE', 'EMAIL']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "# count frequency of each entity label\n",
        "def count_labels(file_path):\n",
        "    with open(file_path, 'r') as file:\n",
        "        labels = [line.split()[-1] for line in file if line.strip()]\n",
        "    return Counter(labels)\n",
        "\n",
        "# number of\n",
        "print(\"Train label distribution:\", count_labels('flair_train.txt'))\n",
        "print(\"Test label distribution:\", count_labels('flair_test.txt'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j5cXWOiGY5an",
        "outputId": "13703677-9cdc-4b6a-8a58-126dde1bcab1"
      },
      "id": "j5cXWOiGY5an",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train label distribution: Counter({'O': 376460, 'S-SKILL': 7652, 'B-SKILL': 7475, 'E-SKILL': 7475, 'PER': 6842, 'E-JOB': 3911, 'B-JOB': 3857, 'I-JOB': 2108, 'B-COMPANY': 2064, 'E-COMPANY': 2063, 'S-LOC': 1937, 'I-DEG': 1852, 'I-SKILL': 1473, 'I-COMPANY': 1419, 'E-UNI': 1250, 'B-UNI': 1247, 'I-UNI': 1148, 'E-DEG': 1071, 'B-DEG': 1070, 'E-LOC': 964, 'B-LOC': 962, 'E-NAME': 870, 'B-NAME': 868, 'S-EMAIL': 754, 'E-PHONE': 674, 'B-PHONE': 665, 'S-COMPANY': 529, 'S-JOB': 510, 'I-PHONE': 472, 'S-PHONE': 139, 'I-NAME': 33, 'I-LOC': 32, 'S-UNI': 31, 'S-DEG': 21, 'B-EMAIL': 3, 'E-EMAIL': 3, 'S-NAME': 1})\n",
            "Test label distribution: Counter({'O': 87769, 'S-SKILL': 2029, 'B-SKILL': 1883, 'E-SKILL': 1878, 'PER': 1612, 'E-JOB': 920, 'B-JOB': 914, 'I-JOB': 508, 'E-COMPANY': 480, 'B-COMPANY': 477, 'S-LOC': 456, 'I-DEG': 434, 'I-SKILL': 374, 'I-COMPANY': 349, 'E-UNI': 283, 'B-UNI': 282, 'B-DEG': 262, 'E-DEG': 261, 'I-UNI': 246, 'E-LOC': 241, 'B-LOC': 240, 'B-NAME': 235, 'E-NAME': 235, 'S-EMAIL': 191, 'B-PHONE': 180, 'E-PHONE': 180, 'I-PHONE': 145, 'S-COMPANY': 126, 'S-JOB': 115, 'S-PHONE': 44, 'I-NAME': 14, 'I-LOC': 9, 'S-UNI': 7, 'S-DEG': 5, 'S-NAME': 3})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create NER tagger\n",
        "from flair.embeddings import WordEmbeddings, StackedEmbeddings, TransformerWordEmbeddings, FlairEmbeddings\n",
        "from flair.models import SequenceTagger\n",
        "import torch.nn as nn\n",
        "\n",
        "# 1. using LSTM-CRF on top of frozen embeddings\n",
        "# combine flair and glove embeddings\n",
        "embeddings = StackedEmbeddings([\n",
        "    WordEmbeddings('glove'),  # GloVe word embeddings\n",
        "    FlairEmbeddings('news-forward'),  # Slightly heavier version of the forward Flair embeddings\n",
        "    FlairEmbeddings('news-backward')  # Slightly heavier version of the backward Flair embeddings\n",
        "])\n",
        "\n",
        "# 2. Configure tagger with memory and performance optimizations\n",
        "tagger = SequenceTagger(\n",
        "    hidden_size=128,  # Increased hidden size for more capacity\n",
        "    embeddings=embeddings,\n",
        "    tag_dictionary=tag_dictionary,\n",
        "    tag_type='ner',\n",
        "    use_crf=True,\n",
        "    tag_format='BIOES',\n",
        "    dropout=0.2,  # Reduced dropout for better capacity retention\n",
        "    rnn_layers=2,  # Increased layers to enhance representation learning\n",
        ")"
      ],
      "metadata": {
        "id": "QEBUKmiAnaFm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3cb90ef-3d6b-444d-a696-397553158223"
      },
      "id": "QEBUKmiAnaFm",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-12-12 08:50:23,733 https://flair.informatik.hu-berlin.de/resources/embeddings/token/glove.gensim.vectors.npy not found in cache, downloading to /tmp/tmptcelcvdt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 153M/153M [00:09<00:00, 16.4MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-12-12 08:50:34,014 copying /tmp/tmptcelcvdt to cache at /root/.flair/embeddings/glove.gensim.vectors.npy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-12-12 08:50:34,205 removing temp file /tmp/tmptcelcvdt\n",
            "2024-12-12 08:50:34,751 https://flair.informatik.hu-berlin.de/resources/embeddings/token/glove.gensim not found in cache, downloading to /tmp/tmptg1z30xv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20.5M/20.5M [00:02<00:00, 9.23MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-12-12 08:50:37,580 copying /tmp/tmptg1z30xv to cache at /root/.flair/embeddings/glove.gensim\n",
            "2024-12-12 08:50:37,611 removing temp file /tmp/tmptg1z30xv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-12-12 08:50:43,804 https://flair.informatik.hu-berlin.de/resources/embeddings/flair/news-forward-0.4.1.pt not found in cache, downloading to /tmp/tmp0s0e0krx\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 69.7M/69.7M [00:08<00:00, 9.05MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-12-12 08:50:52,381 copying /tmp/tmp0s0e0krx to cache at /root/.flair/embeddings/news-forward-0.4.1.pt\n",
            "2024-12-12 08:50:52,462 removing temp file /tmp/tmp0s0e0krx\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-12-12 08:50:54,551 https://flair.informatik.hu-berlin.de/resources/embeddings/flair/news-backward-0.4.1.pt not found in cache, downloading to /tmp/tmp1ki_xkkt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 69.7M/69.7M [00:06<00:00, 11.3MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-12-12 08:51:01,539 copying /tmp/tmp1ki_xkkt to cache at /root/.flair/embeddings/news-backward-0.4.1.pt\n",
            "2024-12-12 08:51:01,617 removing temp file /tmp/tmp1ki_xkkt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-12-12 08:51:01,912 SequenceTagger predicts: Dictionary with 45 tags: O, S-SKILL, B-SKILL, E-SKILL, I-SKILL, S-JOB, B-JOB, E-JOB, I-JOB, S-LOC, B-LOC, E-LOC, I-LOC, S-WORK, B-WORK, E-WORK, I-WORK, S-COMPANY, B-COMPANY, E-COMPANY, I-COMPANY, S-UNI, B-UNI, E-UNI, I-UNI, S-DEG, B-DEG, E-DEG, I-DEG, S-NAME, B-NAME, E-NAME, I-NAME, S-STUDY, B-STUDY, E-STUDY, I-STUDY, S-PHONE, B-PHONE, E-PHONE, I-PHONE, S-EMAIL, B-EMAIL, E-EMAIL, I-EMAIL\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train flair ner model\n",
        "\n",
        "from flair.trainers import ModelTrainer\n",
        "from flair.training_utils import EvaluationMetric\n",
        "import torch\n",
        "\n",
        "# define ModelTrained based on tagger and corpus\n",
        "trainer = ModelTrainer(tagger, corpus)\n",
        "\n",
        "# train Flair NER Model\n",
        "trainer.train(\n",
        "    base_path='flair_output/',\n",
        "    learning_rate=0.05,  # Lower learning rate for more stable training\n",
        "    mini_batch_size=16,  # Increased batch size (if memory permits)\n",
        "    max_epochs=50,  # More epochs to allow better model convergence\n",
        "    patience=5,  # Increased patience for early stopping\n",
        "    train_with_dev=True,\n",
        "    save_final_model=True,\n",
        "    use_amp=True,  # Mixed precision training for faster training\n",
        ")\n",
        "\n",
        "# save trained model to drive\n",
        "!cp -r ./flair_output /content/drive/MyDrive/FYP/Implementation/"
      ],
      "metadata": {
        "id": "XbuJ4VjCnoPU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "634055d1-823c-4528-c1ab-175c073afaf2"
      },
      "id": "XbuJ4VjCnoPU",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-12-04 12:06:51,350 ----------------------------------------------------------------------------------------------------\n",
            "2024-12-04 12:06:51,352 Model: \"SequenceTagger(\n",
            "  (embeddings): StackedEmbeddings(\n",
            "    (list_embedding_0): WordEmbeddings(\n",
            "      'glove'\n",
            "      (embedding): Embedding(400001, 100)\n",
            "    )\n",
            "    (list_embedding_1): FlairEmbeddings(\n",
            "      (lm): LanguageModel(\n",
            "        (drop): Dropout(p=0.05, inplace=False)\n",
            "        (encoder): Embedding(300, 100)\n",
            "        (rnn): LSTM(100, 2048)\n",
            "      )\n",
            "    )\n",
            "    (list_embedding_2): FlairEmbeddings(\n",
            "      (lm): LanguageModel(\n",
            "        (drop): Dropout(p=0.05, inplace=False)\n",
            "        (encoder): Embedding(300, 100)\n",
            "        (rnn): LSTM(100, 2048)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (dropout): Dropout(p=0.2, inplace=False)\n",
            "  (word_dropout): WordDropout(p=0.05)\n",
            "  (locked_dropout): LockedDropout(p=0.5)\n",
            "  (embedding2nn): Linear(in_features=4196, out_features=4196, bias=True)\n",
            "  (rnn): LSTM(4196, 128, num_layers=2, batch_first=True, dropout=0.5, bidirectional=True)\n",
            "  (linear): Linear(in_features=256, out_features=47, bias=True)\n",
            "  (loss_function): ViterbiLoss()\n",
            "  (crf): CRF()\n",
            ")\"\n",
            "2024-12-04 12:06:51,354 ----------------------------------------------------------------------------------------------------\n",
            "2024-12-04 12:06:51,356 Corpus: 1043 train + 116 dev + 290 test sentences\n",
            "2024-12-04 12:06:51,357 ----------------------------------------------------------------------------------------------------\n",
            "2024-12-04 12:06:51,360 Train:  1159 sentences\n",
            "2024-12-04 12:06:51,361         (train_with_dev=True, train_with_test=False)\n",
            "2024-12-04 12:06:51,362 ----------------------------------------------------------------------------------------------------\n",
            "2024-12-04 12:06:51,363 Training Params:\n",
            "2024-12-04 12:06:51,364  - learning_rate: \"0.05\" \n",
            "2024-12-04 12:06:51,365  - mini_batch_size: \"16\"\n",
            "2024-12-04 12:06:51,366  - max_epochs: \"50\"\n",
            "2024-12-04 12:06:51,367  - shuffle: \"True\"\n",
            "2024-12-04 12:06:51,368 ----------------------------------------------------------------------------------------------------\n",
            "2024-12-04 12:06:51,369 Plugins:\n",
            "2024-12-04 12:06:51,370  - AnnealOnPlateau | patience: '5', anneal_factor: '0.5', min_learning_rate: '0.0001'\n",
            "2024-12-04 12:06:51,370 ----------------------------------------------------------------------------------------------------\n",
            "2024-12-04 12:06:51,371 Final evaluation on model from best epoch (best-model.pt)\n",
            "2024-12-04 12:06:51,372  - metric: \"('micro avg', 'f1-score')\"\n",
            "2024-12-04 12:06:51,373 ----------------------------------------------------------------------------------------------------\n",
            "2024-12-04 12:06:51,374 Computation:\n",
            "2024-12-04 12:06:51,375  - compute on device: cuda:0\n",
            "2024-12-04 12:06:51,376  - embedding storage: cpu\n",
            "2024-12-04 12:06:51,377 ----------------------------------------------------------------------------------------------------\n",
            "2024-12-04 12:06:51,378 Model training base path: \"flair_output\"\n",
            "2024-12-04 12:06:51,379 ----------------------------------------------------------------------------------------------------\n",
            "2024-12-04 12:06:51,384 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/flair/trainers/trainer.py:499: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler(enabled=use_amp and flair.device.type != \"cpu\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-12-04 12:07:32,760 epoch 1 - iter 7/73 - loss 4.19854115 - time (sec): 41.38 - samples/sec: 769.52 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 12:08:18,910 epoch 1 - iter 14/73 - loss 4.20430475 - time (sec): 87.52 - samples/sec: 742.59 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 12:09:19,855 epoch 1 - iter 21/73 - loss 3.58259553 - time (sec): 148.47 - samples/sec: 653.92 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 12:10:06,312 epoch 1 - iter 28/73 - loss 2.94078037 - time (sec): 194.93 - samples/sec: 654.54 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 12:10:51,804 epoch 1 - iter 35/73 - loss 2.53528460 - time (sec): 240.42 - samples/sec: 655.64 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 12:11:31,874 epoch 1 - iter 42/73 - loss 2.27277629 - time (sec): 280.49 - samples/sec: 666.33 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 12:12:15,286 epoch 1 - iter 49/73 - loss 2.06623933 - time (sec): 323.90 - samples/sec: 669.77 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 12:12:53,527 epoch 1 - iter 56/73 - loss 1.91151579 - time (sec): 362.14 - samples/sec: 677.97 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 12:13:44,749 epoch 1 - iter 63/73 - loss 1.76397367 - time (sec): 413.36 - samples/sec: 678.33 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 12:14:24,571 epoch 1 - iter 70/73 - loss 1.65903328 - time (sec): 453.19 - samples/sec: 687.12 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 12:14:35,531 ----------------------------------------------------------------------------------------------------\n",
            "2024-12-04 12:14:35,533 EPOCH 1 done: loss 1.6347 - lr: 0.050000\n",
            "2024-12-04 12:14:35,535  - 0 epochs without improvement\n",
            "2024-12-04 12:14:35,538 ----------------------------------------------------------------------------------------------------\n",
            "2024-12-04 12:15:00,030 epoch 2 - iter 7/73 - loss 0.68926382 - time (sec): 24.49 - samples/sec: 1260.91 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 12:15:19,740 epoch 2 - iter 14/73 - loss 0.69195274 - time (sec): 44.20 - samples/sec: 1438.86 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 12:15:43,548 epoch 2 - iter 21/73 - loss 0.68900112 - time (sec): 68.01 - samples/sec: 1427.76 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 12:16:06,773 epoch 2 - iter 28/73 - loss 0.68338981 - time (sec): 91.23 - samples/sec: 1396.50 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 12:16:29,253 epoch 2 - iter 35/73 - loss 0.67568802 - time (sec): 113.71 - samples/sec: 1405.21 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 12:17:04,752 epoch 2 - iter 42/73 - loss 0.66565414 - time (sec): 149.21 - samples/sec: 1287.24 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 12:17:31,617 epoch 2 - iter 49/73 - loss 0.66378653 - time (sec): 176.08 - samples/sec: 1268.40 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 12:18:09,773 epoch 2 - iter 56/73 - loss 0.65705116 - time (sec): 214.23 - samples/sec: 1192.76 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 12:18:22,811 epoch 2 - iter 63/73 - loss 0.65926518 - time (sec): 227.27 - samples/sec: 1226.57 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 12:18:42,634 epoch 2 - iter 70/73 - loss 0.65671917 - time (sec): 247.09 - samples/sec: 1251.63 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 12:18:50,376 ----------------------------------------------------------------------------------------------------\n",
            "2024-12-04 12:18:50,382 EPOCH 2 done: loss 0.6559 - lr: 0.050000\n",
            "2024-12-04 12:18:50,387  - 0 epochs without improvement\n",
            "2024-12-04 12:18:50,390 ----------------------------------------------------------------------------------------------------\n",
            "2024-12-04 12:19:20,823 epoch 3 - iter 7/73 - loss 0.55054776 - time (sec): 30.43 - samples/sec: 1072.10 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 12:19:39,160 epoch 3 - iter 14/73 - loss 0.60436062 - time (sec): 48.77 - samples/sec: 1281.41 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 12:20:06,347 epoch 3 - iter 21/73 - loss 0.58067588 - time (sec): 75.95 - samples/sec: 1250.51 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 12:20:33,821 epoch 3 - iter 28/73 - loss 0.59034028 - time (sec): 103.43 - samples/sec: 1244.95 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 12:21:03,607 epoch 3 - iter 35/73 - loss 0.59459173 - time (sec): 133.21 - samples/sec: 1179.29 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 12:21:17,599 epoch 3 - iter 42/73 - loss 0.59959533 - time (sec): 147.21 - samples/sec: 1243.58 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 12:21:33,866 epoch 3 - iter 49/73 - loss 0.60299391 - time (sec): 163.47 - samples/sec: 1299.06 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 12:21:59,538 epoch 3 - iter 56/73 - loss 0.60178993 - time (sec): 189.14 - samples/sec: 1303.13 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 12:22:30,075 epoch 3 - iter 63/73 - loss 0.59703879 - time (sec): 219.68 - samples/sec: 1284.09 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 12:22:53,919 epoch 3 - iter 70/73 - loss 0.59413930 - time (sec): 243.53 - samples/sec: 1274.68 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 12:23:03,461 ----------------------------------------------------------------------------------------------------\n",
            "2024-12-04 12:23:03,463 EPOCH 3 done: loss 0.5922 - lr: 0.050000\n",
            "2024-12-04 12:23:03,467  - 0 epochs without improvement\n",
            "2024-12-04 12:23:03,469 ----------------------------------------------------------------------------------------------------\n",
            "2024-12-04 12:23:30,867 epoch 4 - iter 7/73 - loss 0.55414893 - time (sec): 27.40 - samples/sec: 1066.15 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 12:23:47,419 epoch 4 - iter 14/73 - loss 0.56944316 - time (sec): 43.95 - samples/sec: 1215.24 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 12:24:02,905 epoch 4 - iter 21/73 - loss 0.56821700 - time (sec): 59.43 - samples/sec: 1373.36 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 12:24:20,087 epoch 4 - iter 28/73 - loss 0.58267055 - time (sec): 76.62 - samples/sec: 1438.44 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 12:24:40,823 epoch 4 - iter 35/73 - loss 0.57609574 - time (sec): 97.35 - samples/sec: 1440.92 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 12:25:22,844 epoch 4 - iter 42/73 - loss 0.55748856 - time (sec): 139.37 - samples/sec: 1281.81 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 12:25:50,108 epoch 4 - iter 49/73 - loss 0.54807453 - time (sec): 166.64 - samples/sec: 1274.17 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 12:26:07,829 epoch 4 - iter 56/73 - loss 0.54712927 - time (sec): 184.36 - samples/sec: 1311.69 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 12:26:34,144 epoch 4 - iter 63/73 - loss 0.54025912 - time (sec): 210.67 - samples/sec: 1304.37 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 12:27:04,250 epoch 4 - iter 70/73 - loss 0.53440825 - time (sec): 240.78 - samples/sec: 1282.32 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 12:27:12,654 ----------------------------------------------------------------------------------------------------\n",
            "2024-12-04 12:27:12,658 EPOCH 4 done: loss 0.5334 - lr: 0.050000\n",
            "2024-12-04 12:27:12,661  - 0 epochs without improvement\n",
            "2024-12-04 12:27:12,663 ----------------------------------------------------------------------------------------------------\n",
            "2024-12-04 12:27:30,070 epoch 5 - iter 7/73 - loss 0.55518524 - time (sec): 17.40 - samples/sec: 1671.97 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 12:27:49,321 epoch 5 - iter 14/73 - loss 0.52704240 - time (sec): 36.66 - samples/sec: 1583.57 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 12:28:15,756 epoch 5 - iter 21/73 - loss 0.51234045 - time (sec): 63.09 - samples/sec: 1410.25 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 12:28:49,351 epoch 5 - iter 28/73 - loss 0.49746787 - time (sec): 96.69 - samples/sec: 1270.75 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 12:29:25,654 epoch 5 - iter 35/73 - loss 0.47830300 - time (sec): 132.99 - samples/sec: 1217.96 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 12:29:46,455 epoch 5 - iter 42/73 - loss 0.48463518 - time (sec): 153.79 - samples/sec: 1247.50 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 12:30:02,942 epoch 5 - iter 49/73 - loss 0.48754100 - time (sec): 170.28 - samples/sec: 1296.56 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 12:30:25,227 epoch 5 - iter 56/73 - loss 0.48807628 - time (sec): 192.56 - samples/sec: 1304.34 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 12:30:51,266 epoch 5 - iter 63/73 - loss 0.48597537 - time (sec): 218.60 - samples/sec: 1296.81 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 12:31:06,841 epoch 5 - iter 70/73 - loss 0.48836444 - time (sec): 234.18 - samples/sec: 1320.98 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 12:31:16,062 ----------------------------------------------------------------------------------------------------\n",
            "2024-12-04 12:31:16,067 EPOCH 5 done: loss 0.4857 - lr: 0.050000\n",
            "2024-12-04 12:31:16,070  - 0 epochs without improvement\n",
            "2024-12-04 12:31:16,072 ----------------------------------------------------------------------------------------------------\n",
            "2024-12-04 12:31:36,972 epoch 6 - iter 7/73 - loss 0.45186136 - time (sec): 20.90 - samples/sec: 1459.60 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 12:31:53,447 epoch 6 - iter 14/73 - loss 0.47200940 - time (sec): 37.37 - samples/sec: 1557.11 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 12:32:19,663 epoch 6 - iter 21/73 - loss 0.45361850 - time (sec): 63.59 - samples/sec: 1468.17 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 12:32:45,140 epoch 6 - iter 28/73 - loss 0.45518601 - time (sec): 89.07 - samples/sec: 1380.00 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 12:33:12,755 epoch 6 - iter 35/73 - loss 0.45251534 - time (sec): 116.68 - samples/sec: 1270.30 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 12:33:39,370 epoch 6 - iter 42/73 - loss 0.44891171 - time (sec): 143.30 - samples/sec: 1274.35 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 12:33:55,437 epoch 6 - iter 49/73 - loss 0.45294469 - time (sec): 159.36 - samples/sec: 1299.63 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 12:34:20,290 epoch 6 - iter 56/73 - loss 0.45072436 - time (sec): 184.22 - samples/sec: 1299.12 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 12:34:40,894 epoch 6 - iter 63/73 - loss 0.44949490 - time (sec): 204.82 - samples/sec: 1315.28 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 12:35:04,819 epoch 6 - iter 70/73 - loss 0.44863671 - time (sec): 228.75 - samples/sec: 1331.41 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 12:35:24,989 ----------------------------------------------------------------------------------------------------\n",
            "2024-12-04 12:35:24,995 EPOCH 6 done: loss 0.4431 - lr: 0.050000\n",
            "2024-12-04 12:35:24,999  - 0 epochs without improvement\n",
            "2024-12-04 12:35:25,000 ----------------------------------------------------------------------------------------------------\n",
            "2024-12-04 12:35:55,451 epoch 7 - iter 7/73 - loss 0.39876609 - time (sec): 30.45 - samples/sec: 986.83 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 12:36:19,800 epoch 7 - iter 14/73 - loss 0.39872961 - time (sec): 54.80 - samples/sec: 1074.88 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 12:36:39,841 epoch 7 - iter 21/73 - loss 0.40838968 - time (sec): 74.84 - samples/sec: 1222.00 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 12:37:01,721 epoch 7 - iter 28/73 - loss 0.41129042 - time (sec): 96.72 - samples/sec: 1270.62 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 12:37:23,558 epoch 7 - iter 35/73 - loss 0.40227492 - time (sec): 118.56 - samples/sec: 1308.00 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 12:37:47,942 epoch 7 - iter 42/73 - loss 0.40707348 - time (sec): 142.94 - samples/sec: 1285.80 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 12:38:06,889 epoch 7 - iter 49/73 - loss 0.40966666 - time (sec): 161.89 - samples/sec: 1323.22 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 12:38:29,398 epoch 7 - iter 56/73 - loss 0.41108033 - time (sec): 184.39 - samples/sec: 1324.68 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 12:38:49,196 epoch 7 - iter 63/73 - loss 0.41180328 - time (sec): 204.19 - samples/sec: 1336.84 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 12:39:23,082 epoch 7 - iter 70/73 - loss 0.40904157 - time (sec): 238.08 - samples/sec: 1303.75 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 12:39:31,488 ----------------------------------------------------------------------------------------------------\n",
            "2024-12-04 12:39:31,491 EPOCH 7 done: loss 0.4096 - lr: 0.050000\n",
            "2024-12-04 12:39:31,494  - 0 epochs without improvement\n",
            "2024-12-04 12:39:31,496 ----------------------------------------------------------------------------------------------------\n",
            "2024-12-04 12:39:48,755 epoch 8 - iter 7/73 - loss 0.42441066 - time (sec): 17.26 - samples/sec: 1539.72 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 12:40:17,451 epoch 8 - iter 14/73 - loss 0.38592475 - time (sec): 45.95 - samples/sec: 1464.90 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 12:40:38,424 epoch 8 - iter 21/73 - loss 0.38663666 - time (sec): 66.93 - samples/sec: 1425.24 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 12:41:03,014 epoch 8 - iter 28/73 - loss 0.38132591 - time (sec): 91.52 - samples/sec: 1413.09 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 12:41:23,255 epoch 8 - iter 35/73 - loss 0.38098339 - time (sec): 111.76 - samples/sec: 1431.60 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 12:41:41,511 epoch 8 - iter 42/73 - loss 0.38377097 - time (sec): 130.01 - samples/sec: 1472.32 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 12:42:23,364 epoch 8 - iter 49/73 - loss 0.38010670 - time (sec): 171.87 - samples/sec: 1295.57 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 12:42:49,906 epoch 8 - iter 56/73 - loss 0.37907822 - time (sec): 198.41 - samples/sec: 1274.90 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 12:43:15,248 epoch 8 - iter 63/73 - loss 0.37754217 - time (sec): 223.75 - samples/sec: 1277.68 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 12:43:31,177 epoch 8 - iter 70/73 - loss 0.38093582 - time (sec): 239.68 - samples/sec: 1301.94 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 12:43:35,871 ----------------------------------------------------------------------------------------------------\n",
            "2024-12-04 12:43:35,876 EPOCH 8 done: loss 0.3821 - lr: 0.050000\n",
            "2024-12-04 12:43:35,879  - 0 epochs without improvement\n",
            "2024-12-04 12:43:35,881 ----------------------------------------------------------------------------------------------------\n",
            "2024-12-04 12:43:54,041 epoch 9 - iter 7/73 - loss 0.40126432 - time (sec): 18.16 - samples/sec: 1674.69 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 12:44:12,869 epoch 9 - iter 14/73 - loss 0.38978012 - time (sec): 36.98 - samples/sec: 1649.65 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 12:44:36,304 epoch 9 - iter 21/73 - loss 0.38203929 - time (sec): 60.42 - samples/sec: 1516.27 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 12:45:09,472 epoch 9 - iter 28/73 - loss 0.37058658 - time (sec): 93.59 - samples/sec: 1333.88 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 12:45:34,779 epoch 9 - iter 35/73 - loss 0.37091949 - time (sec): 118.89 - samples/sec: 1306.16 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 12:46:00,877 epoch 9 - iter 42/73 - loss 0.36924543 - time (sec): 144.99 - samples/sec: 1264.82 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 12:46:28,647 epoch 9 - iter 49/73 - loss 0.36615024 - time (sec): 172.76 - samples/sec: 1257.24 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 12:46:52,432 epoch 9 - iter 56/73 - loss 0.36163717 - time (sec): 196.55 - samples/sec: 1262.75 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 12:47:18,123 epoch 9 - iter 63/73 - loss 0.36205769 - time (sec): 222.24 - samples/sec: 1267.75 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 12:47:37,002 epoch 9 - iter 70/73 - loss 0.36181206 - time (sec): 241.12 - samples/sec: 1283.04 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 12:47:49,609 ----------------------------------------------------------------------------------------------------\n",
            "2024-12-04 12:47:49,610 EPOCH 9 done: loss 0.3611 - lr: 0.050000\n",
            "2024-12-04 12:47:49,615  - 0 epochs without improvement\n",
            "2024-12-04 12:47:49,617 ----------------------------------------------------------------------------------------------------\n",
            "2024-12-04 12:48:12,186 epoch 10 - iter 7/73 - loss 0.35302692 - time (sec): 22.57 - samples/sec: 1267.82 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 12:48:33,106 epoch 10 - iter 14/73 - loss 0.35272931 - time (sec): 43.49 - samples/sec: 1348.73 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 12:48:55,003 epoch 10 - iter 21/73 - loss 0.35320624 - time (sec): 65.38 - samples/sec: 1391.87 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 12:49:17,912 epoch 10 - iter 28/73 - loss 0.33925732 - time (sec): 88.29 - samples/sec: 1387.28 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 12:49:34,120 epoch 10 - iter 35/73 - loss 0.34551512 - time (sec): 104.50 - samples/sec: 1452.44 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 12:49:52,426 epoch 10 - iter 42/73 - loss 0.34596578 - time (sec): 122.81 - samples/sec: 1469.08 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 12:50:28,392 epoch 10 - iter 49/73 - loss 0.33772171 - time (sec): 158.77 - samples/sec: 1361.81 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 12:50:51,683 epoch 10 - iter 56/73 - loss 0.33945118 - time (sec): 182.06 - samples/sec: 1364.09 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 12:51:16,327 epoch 10 - iter 63/73 - loss 0.33852240 - time (sec): 206.71 - samples/sec: 1346.70 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 12:51:44,809 epoch 10 - iter 70/73 - loss 0.33661832 - time (sec): 235.19 - samples/sec: 1325.68 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 12:51:49,042 ----------------------------------------------------------------------------------------------------\n",
            "2024-12-04 12:51:49,045 EPOCH 10 done: loss 0.3388 - lr: 0.050000\n",
            "2024-12-04 12:51:49,049  - 0 epochs without improvement\n",
            "2024-12-04 12:51:49,051 ----------------------------------------------------------------------------------------------------\n",
            "2024-12-04 12:52:10,156 epoch 11 - iter 7/73 - loss 0.32195907 - time (sec): 21.10 - samples/sec: 1425.33 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 12:52:29,744 epoch 11 - iter 14/73 - loss 0.32849303 - time (sec): 40.69 - samples/sec: 1436.61 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 12:52:54,462 epoch 11 - iter 21/73 - loss 0.32080032 - time (sec): 65.41 - samples/sec: 1386.02 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 12:53:13,036 epoch 11 - iter 28/73 - loss 0.32011076 - time (sec): 83.98 - samples/sec: 1457.36 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 12:53:41,141 epoch 11 - iter 35/73 - loss 0.32391569 - time (sec): 112.09 - samples/sec: 1389.54 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 12:54:09,459 epoch 11 - iter 42/73 - loss 0.32496594 - time (sec): 140.41 - samples/sec: 1323.70 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 12:54:27,481 epoch 11 - iter 49/73 - loss 0.32683084 - time (sec): 158.43 - samples/sec: 1353.55 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 12:55:04,107 epoch 11 - iter 56/73 - loss 0.32703109 - time (sec): 195.05 - samples/sec: 1264.63 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 12:55:24,177 epoch 11 - iter 63/73 - loss 0.32899072 - time (sec): 215.12 - samples/sec: 1274.16 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 12:55:56,574 epoch 11 - iter 70/73 - loss 0.32406043 - time (sec): 247.52 - samples/sec: 1252.83 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 12:56:02,416 ----------------------------------------------------------------------------------------------------\n",
            "2024-12-04 12:56:02,423 EPOCH 11 done: loss 0.3236 - lr: 0.050000\n",
            "2024-12-04 12:56:02,429  - 0 epochs without improvement\n",
            "2024-12-04 12:56:02,431 ----------------------------------------------------------------------------------------------------\n",
            "2024-12-04 12:56:25,364 epoch 12 - iter 7/73 - loss 0.33547074 - time (sec): 22.93 - samples/sec: 1339.61 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 12:56:48,196 epoch 12 - iter 14/73 - loss 0.33356573 - time (sec): 45.76 - samples/sec: 1347.23 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 12:57:07,722 epoch 12 - iter 21/73 - loss 0.32755401 - time (sec): 65.29 - samples/sec: 1363.61 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 12:57:51,440 epoch 12 - iter 28/73 - loss 0.30975119 - time (sec): 109.01 - samples/sec: 1164.81 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 12:58:14,355 epoch 12 - iter 35/73 - loss 0.31501876 - time (sec): 131.92 - samples/sec: 1166.18 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 12:58:38,760 epoch 12 - iter 42/73 - loss 0.30859393 - time (sec): 156.33 - samples/sec: 1195.35 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 12:59:00,876 epoch 12 - iter 49/73 - loss 0.30339966 - time (sec): 178.44 - samples/sec: 1231.19 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 12:59:21,000 epoch 12 - iter 56/73 - loss 0.30679756 - time (sec): 198.57 - samples/sec: 1249.49 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 12:59:35,871 epoch 12 - iter 63/73 - loss 0.31054132 - time (sec): 213.44 - samples/sec: 1295.70 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 13:00:03,329 epoch 12 - iter 70/73 - loss 0.31035335 - time (sec): 240.89 - samples/sec: 1286.71 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 13:00:09,337 ----------------------------------------------------------------------------------------------------\n",
            "2024-12-04 13:00:09,342 EPOCH 12 done: loss 0.3103 - lr: 0.050000\n",
            "2024-12-04 13:00:09,345  - 0 epochs without improvement\n",
            "2024-12-04 13:00:09,348 ----------------------------------------------------------------------------------------------------\n",
            "2024-12-04 13:00:32,870 epoch 13 - iter 7/73 - loss 0.29732059 - time (sec): 23.52 - samples/sec: 1198.77 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 13:00:58,534 epoch 13 - iter 14/73 - loss 0.29597003 - time (sec): 49.18 - samples/sec: 1168.15 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 13:01:22,946 epoch 13 - iter 21/73 - loss 0.29500177 - time (sec): 73.59 - samples/sec: 1251.96 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 13:01:51,289 epoch 13 - iter 28/73 - loss 0.28789313 - time (sec): 101.94 - samples/sec: 1229.15 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 13:02:07,786 epoch 13 - iter 35/73 - loss 0.29750499 - time (sec): 118.43 - samples/sec: 1303.49 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 13:02:26,141 epoch 13 - iter 42/73 - loss 0.29821314 - time (sec): 136.79 - samples/sec: 1348.69 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 13:02:49,877 epoch 13 - iter 49/73 - loss 0.29947033 - time (sec): 160.53 - samples/sec: 1345.39 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 13:03:13,357 epoch 13 - iter 56/73 - loss 0.30148378 - time (sec): 184.00 - samples/sec: 1337.55 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 13:03:32,116 epoch 13 - iter 63/73 - loss 0.30232717 - time (sec): 202.76 - samples/sec: 1358.32 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 13:04:15,877 epoch 13 - iter 70/73 - loss 0.29781340 - time (sec): 246.53 - samples/sec: 1254.70 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 13:04:25,733 ----------------------------------------------------------------------------------------------------\n",
            "2024-12-04 13:04:25,735 EPOCH 13 done: loss 0.2993 - lr: 0.050000\n",
            "2024-12-04 13:04:25,741  - 0 epochs without improvement\n",
            "2024-12-04 13:04:25,743 ----------------------------------------------------------------------------------------------------\n",
            "2024-12-04 13:04:43,694 epoch 14 - iter 7/73 - loss 0.27932318 - time (sec): 17.95 - samples/sec: 1509.98 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 13:05:08,371 epoch 14 - iter 14/73 - loss 0.28716114 - time (sec): 42.63 - samples/sec: 1386.26 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 13:05:23,626 epoch 14 - iter 21/73 - loss 0.29777755 - time (sec): 57.88 - samples/sec: 1495.34 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 13:05:50,196 epoch 14 - iter 28/73 - loss 0.28970578 - time (sec): 84.45 - samples/sec: 1408.24 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 13:06:11,891 epoch 14 - iter 35/73 - loss 0.29245084 - time (sec): 106.15 - samples/sec: 1398.17 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 13:06:35,483 epoch 14 - iter 42/73 - loss 0.28977915 - time (sec): 129.74 - samples/sec: 1379.40 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 13:07:00,327 epoch 14 - iter 49/73 - loss 0.28888760 - time (sec): 154.58 - samples/sec: 1347.86 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 13:07:24,386 epoch 14 - iter 56/73 - loss 0.28716144 - time (sec): 178.64 - samples/sec: 1342.28 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 13:07:42,246 epoch 14 - iter 63/73 - loss 0.28807203 - time (sec): 196.50 - samples/sec: 1366.57 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 13:08:20,741 epoch 14 - iter 70/73 - loss 0.28586918 - time (sec): 235.00 - samples/sec: 1303.71 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 13:08:30,875 ----------------------------------------------------------------------------------------------------\n",
            "2024-12-04 13:08:30,880 EPOCH 14 done: loss 0.2843 - lr: 0.050000\n",
            "2024-12-04 13:08:30,881  - 0 epochs without improvement\n",
            "2024-12-04 13:08:30,884 ----------------------------------------------------------------------------------------------------\n",
            "2024-12-04 13:08:53,721 epoch 15 - iter 7/73 - loss 0.27391891 - time (sec): 22.83 - samples/sec: 1331.87 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 13:09:18,849 epoch 15 - iter 14/73 - loss 0.26754934 - time (sec): 47.96 - samples/sec: 1260.44 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 13:09:42,672 epoch 15 - iter 21/73 - loss 0.26534976 - time (sec): 71.79 - samples/sec: 1258.18 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 13:10:21,518 epoch 15 - iter 28/73 - loss 0.26946299 - time (sec): 110.63 - samples/sec: 1121.11 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 13:10:42,796 epoch 15 - iter 35/73 - loss 0.26490945 - time (sec): 131.91 - samples/sec: 1196.51 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 13:11:10,456 epoch 15 - iter 42/73 - loss 0.26958897 - time (sec): 159.57 - samples/sec: 1196.94 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 13:11:27,876 epoch 15 - iter 49/73 - loss 0.27410486 - time (sec): 176.99 - samples/sec: 1244.83 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 13:11:48,113 epoch 15 - iter 56/73 - loss 0.27552738 - time (sec): 197.23 - samples/sec: 1279.23 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 13:12:15,030 epoch 15 - iter 63/73 - loss 0.27568147 - time (sec): 224.14 - samples/sec: 1257.17 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 13:12:39,851 epoch 15 - iter 70/73 - loss 0.27544598 - time (sec): 248.96 - samples/sec: 1252.30 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 13:12:45,577 ----------------------------------------------------------------------------------------------------\n",
            "2024-12-04 13:12:45,580 EPOCH 15 done: loss 0.2758 - lr: 0.050000\n",
            "2024-12-04 13:12:45,583  - 0 epochs without improvement\n",
            "2024-12-04 13:12:45,586 ----------------------------------------------------------------------------------------------------\n",
            "2024-12-04 13:13:08,534 epoch 16 - iter 7/73 - loss 0.26594764 - time (sec): 22.95 - samples/sec: 1445.70 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 13:13:32,103 epoch 16 - iter 14/73 - loss 0.26711112 - time (sec): 46.52 - samples/sec: 1367.71 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 13:14:00,318 epoch 16 - iter 21/73 - loss 0.26807248 - time (sec): 74.73 - samples/sec: 1255.50 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 13:14:25,088 epoch 16 - iter 28/73 - loss 0.26599716 - time (sec): 99.50 - samples/sec: 1254.25 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 13:14:44,869 epoch 16 - iter 35/73 - loss 0.27034475 - time (sec): 119.28 - samples/sec: 1278.37 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 13:15:07,235 epoch 16 - iter 42/73 - loss 0.27209941 - time (sec): 141.65 - samples/sec: 1315.13 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 13:15:29,098 epoch 16 - iter 49/73 - loss 0.27100885 - time (sec): 163.51 - samples/sec: 1320.54 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 13:16:09,298 epoch 16 - iter 56/73 - loss 0.26369729 - time (sec): 203.71 - samples/sec: 1246.53 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 13:16:29,990 epoch 16 - iter 63/73 - loss 0.26307157 - time (sec): 224.40 - samples/sec: 1266.78 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 13:16:50,534 epoch 16 - iter 70/73 - loss 0.26429430 - time (sec): 244.95 - samples/sec: 1268.21 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 13:16:56,438 ----------------------------------------------------------------------------------------------------\n",
            "2024-12-04 13:16:56,439 EPOCH 16 done: loss 0.2655 - lr: 0.050000\n",
            "2024-12-04 13:16:56,444  - 0 epochs without improvement\n",
            "2024-12-04 13:16:56,447 ----------------------------------------------------------------------------------------------------\n",
            "2024-12-04 13:17:12,482 epoch 17 - iter 7/73 - loss 0.25655446 - time (sec): 16.03 - samples/sec: 1737.97 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 13:17:34,425 epoch 17 - iter 14/73 - loss 0.26624363 - time (sec): 37.98 - samples/sec: 1559.62 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 13:18:00,920 epoch 17 - iter 21/73 - loss 0.26406787 - time (sec): 64.47 - samples/sec: 1404.49 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 13:18:19,712 epoch 17 - iter 28/73 - loss 0.26840110 - time (sec): 83.26 - samples/sec: 1390.54 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 13:18:37,373 epoch 17 - iter 35/73 - loss 0.26850786 - time (sec): 100.92 - samples/sec: 1424.80 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 13:19:04,990 epoch 17 - iter 42/73 - loss 0.26362606 - time (sec): 128.54 - samples/sec: 1385.74 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 13:19:38,974 epoch 17 - iter 49/73 - loss 0.25967899 - time (sec): 162.53 - samples/sec: 1294.17 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 13:20:02,954 epoch 17 - iter 56/73 - loss 0.25839379 - time (sec): 186.51 - samples/sec: 1302.76 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 13:20:37,816 epoch 17 - iter 63/73 - loss 0.25775066 - time (sec): 221.37 - samples/sec: 1251.20 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 13:21:00,085 epoch 17 - iter 70/73 - loss 0.25823382 - time (sec): 243.64 - samples/sec: 1265.82 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 13:21:07,964 ----------------------------------------------------------------------------------------------------\n",
            "2024-12-04 13:21:07,967 EPOCH 17 done: loss 0.2585 - lr: 0.050000\n",
            "2024-12-04 13:21:07,969  - 0 epochs without improvement\n",
            "2024-12-04 13:21:07,971 ----------------------------------------------------------------------------------------------------\n",
            "2024-12-04 13:21:35,771 epoch 18 - iter 7/73 - loss 0.24513681 - time (sec): 27.80 - samples/sec: 1101.28 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 13:22:00,076 epoch 18 - iter 14/73 - loss 0.24093794 - time (sec): 52.10 - samples/sec: 1176.26 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 13:22:18,032 epoch 18 - iter 21/73 - loss 0.24179488 - time (sec): 70.06 - samples/sec: 1279.32 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 13:22:34,404 epoch 18 - iter 28/73 - loss 0.25189546 - time (sec): 86.43 - samples/sec: 1348.73 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 13:22:52,823 epoch 18 - iter 35/73 - loss 0.25546633 - time (sec): 104.85 - samples/sec: 1376.11 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 13:23:09,732 epoch 18 - iter 42/73 - loss 0.25531472 - time (sec): 121.76 - samples/sec: 1439.35 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 13:24:00,369 epoch 18 - iter 49/73 - loss 0.25157970 - time (sec): 172.40 - samples/sec: 1239.05 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 13:24:25,870 epoch 18 - iter 56/73 - loss 0.25274621 - time (sec): 197.90 - samples/sec: 1244.78 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 13:24:42,751 epoch 18 - iter 63/73 - loss 0.25291337 - time (sec): 214.78 - samples/sec: 1288.32 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 13:25:09,501 epoch 18 - iter 70/73 - loss 0.24954558 - time (sec): 241.53 - samples/sec: 1283.21 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 13:25:17,852 ----------------------------------------------------------------------------------------------------\n",
            "2024-12-04 13:25:17,855 EPOCH 18 done: loss 0.2494 - lr: 0.050000\n",
            "2024-12-04 13:25:17,859  - 0 epochs without improvement\n",
            "2024-12-04 13:25:17,863 ----------------------------------------------------------------------------------------------------\n",
            "2024-12-04 13:25:40,042 epoch 19 - iter 7/73 - loss 0.25106343 - time (sec): 22.18 - samples/sec: 1419.31 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 13:26:01,677 epoch 19 - iter 14/73 - loss 0.25253228 - time (sec): 43.81 - samples/sec: 1437.50 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 13:26:21,905 epoch 19 - iter 21/73 - loss 0.24587602 - time (sec): 64.04 - samples/sec: 1397.37 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 13:26:53,301 epoch 19 - iter 28/73 - loss 0.24726682 - time (sec): 95.44 - samples/sec: 1283.83 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 13:27:18,301 epoch 19 - iter 35/73 - loss 0.24924509 - time (sec): 120.44 - samples/sec: 1246.79 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 13:27:41,551 epoch 19 - iter 42/73 - loss 0.24656712 - time (sec): 143.69 - samples/sec: 1261.73 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 13:28:03,555 epoch 19 - iter 49/73 - loss 0.24682730 - time (sec): 165.69 - samples/sec: 1295.13 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 13:28:28,751 epoch 19 - iter 56/73 - loss 0.24848489 - time (sec): 190.89 - samples/sec: 1272.38 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 13:28:54,976 epoch 19 - iter 63/73 - loss 0.24577152 - time (sec): 217.11 - samples/sec: 1272.80 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 13:29:22,666 epoch 19 - iter 70/73 - loss 0.24391254 - time (sec): 244.80 - samples/sec: 1260.63 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 13:29:31,650 ----------------------------------------------------------------------------------------------------\n",
            "2024-12-04 13:29:31,652 EPOCH 19 done: loss 0.2435 - lr: 0.050000\n",
            "2024-12-04 13:29:31,654  - 0 epochs without improvement\n",
            "2024-12-04 13:29:31,656 ----------------------------------------------------------------------------------------------------\n",
            "2024-12-04 13:29:53,814 epoch 20 - iter 7/73 - loss 0.22834499 - time (sec): 22.16 - samples/sec: 1418.10 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 13:30:18,200 epoch 20 - iter 14/73 - loss 0.23357917 - time (sec): 46.54 - samples/sec: 1350.19 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 13:30:41,041 epoch 20 - iter 21/73 - loss 0.23198707 - time (sec): 69.38 - samples/sec: 1369.17 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 13:31:04,634 epoch 20 - iter 28/73 - loss 0.23285260 - time (sec): 92.98 - samples/sec: 1363.46 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 13:31:21,182 epoch 20 - iter 35/73 - loss 0.23723998 - time (sec): 109.52 - samples/sec: 1398.66 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 13:31:46,611 epoch 20 - iter 42/73 - loss 0.23731087 - time (sec): 134.95 - samples/sec: 1363.06 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 13:32:19,843 epoch 20 - iter 49/73 - loss 0.23401830 - time (sec): 168.18 - samples/sec: 1292.47 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 13:32:38,297 epoch 20 - iter 56/73 - loss 0.23521669 - time (sec): 186.64 - samples/sec: 1323.40 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 13:33:00,098 epoch 20 - iter 63/73 - loss 0.23401488 - time (sec): 208.44 - samples/sec: 1333.60 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 13:33:33,843 epoch 20 - iter 70/73 - loss 0.23488594 - time (sec): 242.18 - samples/sec: 1278.60 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 13:33:39,801 ----------------------------------------------------------------------------------------------------\n",
            "2024-12-04 13:33:39,805 EPOCH 20 done: loss 0.2347 - lr: 0.050000\n",
            "2024-12-04 13:33:39,807  - 0 epochs without improvement\n",
            "2024-12-04 13:33:39,809 ----------------------------------------------------------------------------------------------------\n",
            "2024-12-04 13:33:57,341 epoch 21 - iter 7/73 - loss 0.23724676 - time (sec): 17.53 - samples/sec: 1670.70 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 13:34:18,906 epoch 21 - iter 14/73 - loss 0.23153959 - time (sec): 39.09 - samples/sec: 1543.59 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 13:34:41,969 epoch 21 - iter 21/73 - loss 0.23714954 - time (sec): 62.16 - samples/sec: 1434.61 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 13:35:03,065 epoch 21 - iter 28/73 - loss 0.23102398 - time (sec): 83.25 - samples/sec: 1449.01 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 13:35:29,556 epoch 21 - iter 35/73 - loss 0.23031346 - time (sec): 109.74 - samples/sec: 1391.00 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 13:36:14,264 epoch 21 - iter 42/73 - loss 0.22806148 - time (sec): 154.45 - samples/sec: 1217.14 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 13:36:41,058 epoch 21 - iter 49/73 - loss 0.22773943 - time (sec): 181.25 - samples/sec: 1214.45 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 13:37:01,966 epoch 21 - iter 56/73 - loss 0.22960225 - time (sec): 202.15 - samples/sec: 1245.92 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 13:37:19,561 epoch 21 - iter 63/73 - loss 0.22845331 - time (sec): 219.75 - samples/sec: 1276.60 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 13:37:41,943 epoch 21 - iter 70/73 - loss 0.22889456 - time (sec): 242.13 - samples/sec: 1280.24 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 13:37:49,897 ----------------------------------------------------------------------------------------------------\n",
            "2024-12-04 13:37:49,901 EPOCH 21 done: loss 0.2300 - lr: 0.050000\n",
            "2024-12-04 13:37:49,904  - 0 epochs without improvement\n",
            "2024-12-04 13:37:49,907 ----------------------------------------------------------------------------------------------------\n",
            "2024-12-04 13:38:15,618 epoch 22 - iter 7/73 - loss 0.19878832 - time (sec): 25.71 - samples/sec: 1326.55 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 13:38:37,829 epoch 22 - iter 14/73 - loss 0.22754952 - time (sec): 47.92 - samples/sec: 1295.66 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 13:38:54,917 epoch 22 - iter 21/73 - loss 0.23153889 - time (sec): 65.01 - samples/sec: 1375.82 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 13:39:12,970 epoch 22 - iter 28/73 - loss 0.23130325 - time (sec): 83.06 - samples/sec: 1431.01 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 13:39:38,388 epoch 22 - iter 35/73 - loss 0.22901121 - time (sec): 108.48 - samples/sec: 1403.54 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 13:40:04,214 epoch 22 - iter 42/73 - loss 0.22952262 - time (sec): 134.31 - samples/sec: 1359.64 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 13:40:38,509 epoch 22 - iter 49/73 - loss 0.22798046 - time (sec): 168.60 - samples/sec: 1306.84 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 13:40:57,161 epoch 22 - iter 56/73 - loss 0.22722905 - time (sec): 187.25 - samples/sec: 1328.73 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 13:41:13,424 epoch 22 - iter 63/73 - loss 0.22712522 - time (sec): 203.51 - samples/sec: 1353.22 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 13:41:52,815 epoch 22 - iter 70/73 - loss 0.22464256 - time (sec): 242.91 - samples/sec: 1278.48 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 13:41:57,743 ----------------------------------------------------------------------------------------------------\n",
            "2024-12-04 13:41:57,747 EPOCH 22 done: loss 0.2262 - lr: 0.050000\n",
            "2024-12-04 13:41:57,749  - 0 epochs without improvement\n",
            "2024-12-04 13:41:57,751 ----------------------------------------------------------------------------------------------------\n",
            "2024-12-04 13:42:19,353 epoch 23 - iter 7/73 - loss 0.21780394 - time (sec): 21.60 - samples/sec: 1373.91 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 13:42:41,705 epoch 23 - iter 14/73 - loss 0.21105459 - time (sec): 43.95 - samples/sec: 1384.44 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 13:43:02,431 epoch 23 - iter 21/73 - loss 0.22313394 - time (sec): 64.68 - samples/sec: 1399.09 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 13:43:22,729 epoch 23 - iter 28/73 - loss 0.22763866 - time (sec): 84.98 - samples/sec: 1385.85 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 13:43:48,724 epoch 23 - iter 35/73 - loss 0.22303715 - time (sec): 110.97 - samples/sec: 1376.61 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 13:44:12,015 epoch 23 - iter 42/73 - loss 0.22337236 - time (sec): 134.26 - samples/sec: 1365.18 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 13:44:36,694 epoch 23 - iter 49/73 - loss 0.22318760 - time (sec): 158.94 - samples/sec: 1339.33 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 13:44:53,917 epoch 23 - iter 56/73 - loss 0.22404706 - time (sec): 176.16 - samples/sec: 1361.96 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 13:45:33,964 epoch 23 - iter 63/73 - loss 0.22116020 - time (sec): 216.21 - samples/sec: 1266.90 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 13:46:02,326 epoch 23 - iter 70/73 - loss 0.21909174 - time (sec): 244.57 - samples/sec: 1259.56 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 13:46:11,643 ----------------------------------------------------------------------------------------------------\n",
            "2024-12-04 13:46:11,644 EPOCH 23 done: loss 0.2181 - lr: 0.050000\n",
            "2024-12-04 13:46:11,647  - 0 epochs without improvement\n",
            "2024-12-04 13:46:11,650 ----------------------------------------------------------------------------------------------------\n",
            "2024-12-04 13:46:34,377 epoch 24 - iter 7/73 - loss 0.22929498 - time (sec): 22.73 - samples/sec: 1327.30 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 13:46:57,007 epoch 24 - iter 14/73 - loss 0.22356948 - time (sec): 45.35 - samples/sec: 1322.85 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 13:47:18,926 epoch 24 - iter 21/73 - loss 0.21857793 - time (sec): 67.27 - samples/sec: 1343.77 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 13:47:49,772 epoch 24 - iter 28/73 - loss 0.21699960 - time (sec): 98.12 - samples/sec: 1275.55 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 13:48:09,385 epoch 24 - iter 35/73 - loss 0.21468806 - time (sec): 117.73 - samples/sec: 1330.74 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 13:48:25,513 epoch 24 - iter 42/73 - loss 0.21864562 - time (sec): 133.86 - samples/sec: 1366.92 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 13:48:46,372 epoch 24 - iter 49/73 - loss 0.21928057 - time (sec): 154.72 - samples/sec: 1379.97 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 13:49:13,790 epoch 24 - iter 56/73 - loss 0.21804074 - time (sec): 182.14 - samples/sec: 1357.12 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 13:49:31,728 epoch 24 - iter 63/73 - loss 0.21806340 - time (sec): 200.08 - samples/sec: 1374.80 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 13:49:53,576 epoch 24 - iter 70/73 - loss 0.21766969 - time (sec): 221.92 - samples/sec: 1368.55 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 13:50:18,476 ----------------------------------------------------------------------------------------------------\n",
            "2024-12-04 13:50:18,479 EPOCH 24 done: loss 0.2158 - lr: 0.050000\n",
            "2024-12-04 13:50:18,484  - 0 epochs without improvement\n",
            "2024-12-04 13:50:18,486 ----------------------------------------------------------------------------------------------------\n",
            "2024-12-04 13:50:54,351 epoch 25 - iter 7/73 - loss 0.20789297 - time (sec): 35.86 - samples/sec: 780.08 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 13:51:22,464 epoch 25 - iter 14/73 - loss 0.20156247 - time (sec): 63.98 - samples/sec: 952.22 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 13:51:50,969 epoch 25 - iter 21/73 - loss 0.20741268 - time (sec): 92.48 - samples/sec: 985.82 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 13:52:16,189 epoch 25 - iter 28/73 - loss 0.21741717 - time (sec): 117.70 - samples/sec: 1034.27 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 13:52:38,289 epoch 25 - iter 35/73 - loss 0.21673669 - time (sec): 139.80 - samples/sec: 1114.62 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 13:52:59,193 epoch 25 - iter 42/73 - loss 0.21332155 - time (sec): 160.71 - samples/sec: 1154.79 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 13:53:22,826 epoch 25 - iter 49/73 - loss 0.21222076 - time (sec): 184.34 - samples/sec: 1179.95 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 13:53:43,658 epoch 25 - iter 56/73 - loss 0.21115888 - time (sec): 205.17 - samples/sec: 1208.05 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 13:54:04,629 epoch 25 - iter 63/73 - loss 0.21137979 - time (sec): 226.14 - samples/sec: 1229.26 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 13:54:22,983 epoch 25 - iter 70/73 - loss 0.21201827 - time (sec): 244.50 - samples/sec: 1265.67 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 13:54:29,736 ----------------------------------------------------------------------------------------------------\n",
            "2024-12-04 13:54:29,739 EPOCH 25 done: loss 0.2117 - lr: 0.050000\n",
            "2024-12-04 13:54:29,741  - 0 epochs without improvement\n",
            "2024-12-04 13:54:29,743 ----------------------------------------------------------------------------------------------------\n",
            "2024-12-04 13:54:51,167 epoch 26 - iter 7/73 - loss 0.19856683 - time (sec): 21.42 - samples/sec: 1480.23 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 13:55:12,404 epoch 26 - iter 14/73 - loss 0.19737076 - time (sec): 42.66 - samples/sec: 1458.89 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 13:55:31,920 epoch 26 - iter 21/73 - loss 0.21012364 - time (sec): 62.17 - samples/sec: 1467.82 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 13:55:47,056 epoch 26 - iter 28/73 - loss 0.21119096 - time (sec): 77.31 - samples/sec: 1538.79 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 13:56:17,307 epoch 26 - iter 35/73 - loss 0.20901574 - time (sec): 107.56 - samples/sec: 1435.37 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 13:56:46,922 epoch 26 - iter 42/73 - loss 0.20747481 - time (sec): 137.18 - samples/sec: 1346.19 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 13:57:11,070 epoch 26 - iter 49/73 - loss 0.20855609 - time (sec): 161.32 - samples/sec: 1332.32 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 13:57:39,092 epoch 26 - iter 56/73 - loss 0.20837107 - time (sec): 189.35 - samples/sec: 1310.61 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 13:58:13,462 epoch 26 - iter 63/73 - loss 0.20668614 - time (sec): 223.72 - samples/sec: 1262.22 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 13:58:35,815 epoch 26 - iter 70/73 - loss 0.20707701 - time (sec): 246.07 - samples/sec: 1261.72 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 13:58:41,173 ----------------------------------------------------------------------------------------------------\n",
            "2024-12-04 13:58:41,177 EPOCH 26 done: loss 0.2076 - lr: 0.050000\n",
            "2024-12-04 13:58:41,180  - 0 epochs without improvement\n",
            "2024-12-04 13:58:41,183 ----------------------------------------------------------------------------------------------------\n",
            "2024-12-04 13:59:18,803 epoch 27 - iter 7/73 - loss 0.19175621 - time (sec): 37.62 - samples/sec: 923.25 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 13:59:47,643 epoch 27 - iter 14/73 - loss 0.19340266 - time (sec): 66.46 - samples/sec: 1018.43 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 14:00:10,752 epoch 27 - iter 21/73 - loss 0.19461006 - time (sec): 89.57 - samples/sec: 1146.86 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 14:00:25,497 epoch 27 - iter 28/73 - loss 0.20171171 - time (sec): 104.31 - samples/sec: 1242.61 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 14:00:47,390 epoch 27 - iter 35/73 - loss 0.20381079 - time (sec): 126.21 - samples/sec: 1288.45 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 14:01:09,696 epoch 27 - iter 42/73 - loss 0.20444628 - time (sec): 148.51 - samples/sec: 1279.83 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 14:01:34,711 epoch 27 - iter 49/73 - loss 0.20075346 - time (sec): 173.53 - samples/sec: 1266.17 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 14:01:50,741 epoch 27 - iter 56/73 - loss 0.20241085 - time (sec): 189.56 - samples/sec: 1298.20 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 14:02:20,967 epoch 27 - iter 63/73 - loss 0.20110750 - time (sec): 219.78 - samples/sec: 1260.72 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 14:02:39,949 epoch 27 - iter 70/73 - loss 0.20311065 - time (sec): 238.76 - samples/sec: 1291.92 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 14:02:47,424 ----------------------------------------------------------------------------------------------------\n",
            "2024-12-04 14:02:47,428 EPOCH 27 done: loss 0.2046 - lr: 0.050000\n",
            "2024-12-04 14:02:47,432  - 0 epochs without improvement\n",
            "2024-12-04 14:02:47,436 ----------------------------------------------------------------------------------------------------\n",
            "2024-12-04 14:03:08,681 epoch 28 - iter 7/73 - loss 0.19912892 - time (sec): 21.24 - samples/sec: 1345.91 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 14:03:40,503 epoch 28 - iter 14/73 - loss 0.19786783 - time (sec): 53.07 - samples/sec: 1118.90 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 14:03:59,108 epoch 28 - iter 21/73 - loss 0.19812462 - time (sec): 71.67 - samples/sec: 1249.19 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 14:04:19,237 epoch 28 - iter 28/73 - loss 0.19799428 - time (sec): 91.80 - samples/sec: 1309.81 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 14:04:41,100 epoch 28 - iter 35/73 - loss 0.20089778 - time (sec): 113.66 - samples/sec: 1312.28 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 14:05:01,806 epoch 28 - iter 42/73 - loss 0.20038879 - time (sec): 134.37 - samples/sec: 1327.83 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 14:05:23,493 epoch 28 - iter 49/73 - loss 0.20160630 - time (sec): 156.06 - samples/sec: 1345.94 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 14:05:45,915 epoch 28 - iter 56/73 - loss 0.20077526 - time (sec): 178.48 - samples/sec: 1346.40 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 14:06:26,475 epoch 28 - iter 63/73 - loss 0.19846560 - time (sec): 219.04 - samples/sec: 1269.30 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 14:06:46,388 epoch 28 - iter 70/73 - loss 0.19953475 - time (sec): 238.95 - samples/sec: 1290.26 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 14:06:56,501 ----------------------------------------------------------------------------------------------------\n",
            "2024-12-04 14:06:56,503 EPOCH 28 done: loss 0.2002 - lr: 0.050000\n",
            "2024-12-04 14:06:56,505  - 0 epochs without improvement\n",
            "2024-12-04 14:06:56,507 ----------------------------------------------------------------------------------------------------\n",
            "2024-12-04 14:07:24,284 epoch 29 - iter 7/73 - loss 0.19664687 - time (sec): 27.77 - samples/sec: 1303.90 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 14:07:48,946 epoch 29 - iter 14/73 - loss 0.19167543 - time (sec): 52.44 - samples/sec: 1261.29 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 14:08:13,073 epoch 29 - iter 21/73 - loss 0.18989429 - time (sec): 76.56 - samples/sec: 1303.86 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 14:08:36,739 epoch 29 - iter 28/73 - loss 0.19206513 - time (sec): 100.23 - samples/sec: 1298.24 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 14:08:56,721 epoch 29 - iter 35/73 - loss 0.19828578 - time (sec): 120.21 - samples/sec: 1326.45 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 14:09:21,043 epoch 29 - iter 42/73 - loss 0.19849257 - time (sec): 144.53 - samples/sec: 1295.73 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 14:09:43,010 epoch 29 - iter 49/73 - loss 0.19935339 - time (sec): 166.50 - samples/sec: 1310.00 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 14:10:15,766 epoch 29 - iter 56/73 - loss 0.19732761 - time (sec): 199.26 - samples/sec: 1264.27 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 14:10:48,799 epoch 29 - iter 63/73 - loss 0.19769987 - time (sec): 232.29 - samples/sec: 1218.87 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 14:11:06,082 epoch 29 - iter 70/73 - loss 0.19913479 - time (sec): 249.57 - samples/sec: 1238.36 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 14:11:13,714 ----------------------------------------------------------------------------------------------------\n",
            "2024-12-04 14:11:13,715 EPOCH 29 done: loss 0.1979 - lr: 0.050000\n",
            "2024-12-04 14:11:13,718  - 0 epochs without improvement\n",
            "2024-12-04 14:11:13,720 ----------------------------------------------------------------------------------------------------\n",
            "2024-12-04 14:11:34,861 epoch 30 - iter 7/73 - loss 0.21417341 - time (sec): 21.14 - samples/sec: 1460.53 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 14:11:55,169 epoch 30 - iter 14/73 - loss 0.20931393 - time (sec): 41.45 - samples/sec: 1410.02 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 14:12:35,548 epoch 30 - iter 21/73 - loss 0.19527968 - time (sec): 81.83 - samples/sec: 1119.42 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 14:13:07,085 epoch 30 - iter 28/73 - loss 0.19020182 - time (sec): 113.36 - samples/sec: 1101.82 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 14:13:27,123 epoch 30 - iter 35/73 - loss 0.19253367 - time (sec): 133.40 - samples/sec: 1155.13 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 14:13:51,202 epoch 30 - iter 42/73 - loss 0.19371938 - time (sec): 157.48 - samples/sec: 1176.88 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 14:14:13,719 epoch 30 - iter 49/73 - loss 0.19496289 - time (sec): 180.00 - samples/sec: 1200.93 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 14:14:36,954 epoch 30 - iter 56/73 - loss 0.19405178 - time (sec): 203.23 - samples/sec: 1217.55 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 14:14:57,298 epoch 30 - iter 63/73 - loss 0.19611551 - time (sec): 223.58 - samples/sec: 1237.77 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 14:15:22,021 epoch 30 - iter 70/73 - loss 0.19552211 - time (sec): 248.30 - samples/sec: 1247.72 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 14:15:27,718 ----------------------------------------------------------------------------------------------------\n",
            "2024-12-04 14:15:27,722 EPOCH 30 done: loss 0.1948 - lr: 0.050000\n",
            "2024-12-04 14:15:27,725  - 0 epochs without improvement\n",
            "2024-12-04 14:15:27,727 ----------------------------------------------------------------------------------------------------\n",
            "2024-12-04 14:15:45,993 epoch 31 - iter 7/73 - loss 0.19635375 - time (sec): 18.26 - samples/sec: 1597.09 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 14:16:05,195 epoch 31 - iter 14/73 - loss 0.20199667 - time (sec): 37.47 - samples/sec: 1439.89 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 14:16:27,535 epoch 31 - iter 21/73 - loss 0.19424670 - time (sec): 59.81 - samples/sec: 1409.88 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 14:16:47,288 epoch 31 - iter 28/73 - loss 0.19089289 - time (sec): 79.56 - samples/sec: 1431.29 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 14:17:20,040 epoch 31 - iter 35/73 - loss 0.18898302 - time (sec): 112.31 - samples/sec: 1329.44 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 14:17:42,328 epoch 31 - iter 42/73 - loss 0.19105692 - time (sec): 134.60 - samples/sec: 1347.42 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 14:18:04,292 epoch 31 - iter 49/73 - loss 0.19313694 - time (sec): 156.56 - samples/sec: 1353.70 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 14:18:36,423 epoch 31 - iter 56/73 - loss 0.19453120 - time (sec): 188.69 - samples/sec: 1287.33 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 14:19:03,448 epoch 31 - iter 63/73 - loss 0.19303357 - time (sec): 215.72 - samples/sec: 1268.64 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 14:19:25,358 epoch 31 - iter 70/73 - loss 0.19422429 - time (sec): 237.63 - samples/sec: 1282.41 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 14:19:39,294 ----------------------------------------------------------------------------------------------------\n",
            "2024-12-04 14:19:39,302 EPOCH 31 done: loss 0.1926 - lr: 0.050000\n",
            "2024-12-04 14:19:39,304  - 0 epochs without improvement\n",
            "2024-12-04 14:19:39,306 ----------------------------------------------------------------------------------------------------\n",
            "2024-12-04 14:20:07,746 epoch 32 - iter 7/73 - loss 0.18593948 - time (sec): 28.44 - samples/sec: 1112.05 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 14:20:33,779 epoch 32 - iter 14/73 - loss 0.17184247 - time (sec): 54.47 - samples/sec: 1223.54 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 14:20:53,378 epoch 32 - iter 21/73 - loss 0.18275189 - time (sec): 74.07 - samples/sec: 1331.72 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 14:21:10,978 epoch 32 - iter 28/73 - loss 0.19126913 - time (sec): 91.67 - samples/sec: 1381.02 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 14:21:42,889 epoch 32 - iter 35/73 - loss 0.18987977 - time (sec): 123.58 - samples/sec: 1304.14 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 14:22:03,840 epoch 32 - iter 42/73 - loss 0.19286735 - time (sec): 144.53 - samples/sec: 1314.69 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 14:22:20,603 epoch 32 - iter 49/73 - loss 0.19292232 - time (sec): 161.29 - samples/sec: 1355.72 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 14:22:43,202 epoch 32 - iter 56/73 - loss 0.19118992 - time (sec): 183.89 - samples/sec: 1349.35 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 14:23:05,185 epoch 32 - iter 63/73 - loss 0.19114148 - time (sec): 205.88 - samples/sec: 1349.64 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 14:23:35,256 epoch 32 - iter 70/73 - loss 0.19066340 - time (sec): 235.95 - samples/sec: 1304.36 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 14:23:46,852 ----------------------------------------------------------------------------------------------------\n",
            "2024-12-04 14:23:46,856 EPOCH 32 done: loss 0.1892 - lr: 0.050000\n",
            "2024-12-04 14:23:46,859  - 0 epochs without improvement\n",
            "2024-12-04 14:23:46,861 ----------------------------------------------------------------------------------------------------\n",
            "2024-12-04 14:24:06,746 epoch 33 - iter 7/73 - loss 0.20335585 - time (sec): 19.88 - samples/sec: 1401.23 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 14:24:29,490 epoch 33 - iter 14/73 - loss 0.19882132 - time (sec): 42.63 - samples/sec: 1352.10 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 14:24:55,171 epoch 33 - iter 21/73 - loss 0.19433260 - time (sec): 68.31 - samples/sec: 1320.58 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 14:25:41,805 epoch 33 - iter 28/73 - loss 0.18640128 - time (sec): 114.94 - samples/sec: 1106.21 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 14:25:59,250 epoch 33 - iter 35/73 - loss 0.18953784 - time (sec): 132.39 - samples/sec: 1175.32 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 14:26:18,311 epoch 33 - iter 42/73 - loss 0.19071789 - time (sec): 151.45 - samples/sec: 1179.96 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 14:26:43,728 epoch 33 - iter 49/73 - loss 0.18793391 - time (sec): 176.86 - samples/sec: 1204.88 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 14:27:03,075 epoch 33 - iter 56/73 - loss 0.18812100 - time (sec): 196.21 - samples/sec: 1250.60 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 14:27:29,008 epoch 33 - iter 63/73 - loss 0.18732585 - time (sec): 222.14 - samples/sec: 1270.17 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 14:27:50,477 epoch 33 - iter 70/73 - loss 0.18844054 - time (sec): 243.61 - samples/sec: 1280.36 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 14:27:55,654 ----------------------------------------------------------------------------------------------------\n",
            "2024-12-04 14:27:55,657 EPOCH 33 done: loss 0.1889 - lr: 0.050000\n",
            "2024-12-04 14:27:55,660  - 0 epochs without improvement\n",
            "2024-12-04 14:27:55,662 ----------------------------------------------------------------------------------------------------\n",
            "2024-12-04 14:28:18,581 epoch 34 - iter 7/73 - loss 0.19893926 - time (sec): 22.92 - samples/sec: 1348.79 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 14:28:49,291 epoch 34 - iter 14/73 - loss 0.18899231 - time (sec): 53.63 - samples/sec: 1189.65 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 14:29:07,229 epoch 34 - iter 21/73 - loss 0.19069793 - time (sec): 71.56 - samples/sec: 1323.24 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 14:29:26,699 epoch 34 - iter 28/73 - loss 0.18968332 - time (sec): 91.03 - samples/sec: 1343.52 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 14:29:46,272 epoch 34 - iter 35/73 - loss 0.18967991 - time (sec): 110.61 - samples/sec: 1371.00 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 14:30:20,197 epoch 34 - iter 42/73 - loss 0.18730698 - time (sec): 144.53 - samples/sec: 1256.85 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 14:30:41,922 epoch 34 - iter 49/73 - loss 0.18774096 - time (sec): 166.26 - samples/sec: 1282.85 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 14:31:05,981 epoch 34 - iter 56/73 - loss 0.18740422 - time (sec): 190.32 - samples/sec: 1288.70 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 14:31:30,578 epoch 34 - iter 63/73 - loss 0.18497634 - time (sec): 214.91 - samples/sec: 1288.46 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 14:31:58,763 epoch 34 - iter 70/73 - loss 0.18459173 - time (sec): 243.10 - samples/sec: 1271.67 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 14:32:05,185 ----------------------------------------------------------------------------------------------------\n",
            "2024-12-04 14:32:05,189 EPOCH 34 done: loss 0.1844 - lr: 0.050000\n",
            "2024-12-04 14:32:05,194  - 0 epochs without improvement\n",
            "2024-12-04 14:32:05,195 ----------------------------------------------------------------------------------------------------\n",
            "2024-12-04 14:32:28,871 epoch 35 - iter 7/73 - loss 0.17481210 - time (sec): 23.67 - samples/sec: 1401.84 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 14:32:49,397 epoch 35 - iter 14/73 - loss 0.18091456 - time (sec): 44.20 - samples/sec: 1485.14 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 14:33:15,948 epoch 35 - iter 21/73 - loss 0.17851514 - time (sec): 70.75 - samples/sec: 1367.58 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 14:33:37,651 epoch 35 - iter 28/73 - loss 0.18488100 - time (sec): 92.45 - samples/sec: 1373.62 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 14:33:56,126 epoch 35 - iter 35/73 - loss 0.18787292 - time (sec): 110.93 - samples/sec: 1402.64 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 14:34:26,591 epoch 35 - iter 42/73 - loss 0.18770640 - time (sec): 141.39 - samples/sec: 1316.58 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 14:34:54,278 epoch 35 - iter 49/73 - loss 0.18495223 - time (sec): 169.08 - samples/sec: 1309.34 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 14:35:13,137 epoch 35 - iter 56/73 - loss 0.18444306 - time (sec): 187.94 - samples/sec: 1317.43 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 14:35:37,757 epoch 35 - iter 63/73 - loss 0.18481027 - time (sec): 212.56 - samples/sec: 1325.55 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 14:35:59,717 epoch 35 - iter 70/73 - loss 0.18429325 - time (sec): 234.52 - samples/sec: 1315.93 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 14:36:10,067 ----------------------------------------------------------------------------------------------------\n",
            "2024-12-04 14:36:10,071 EPOCH 35 done: loss 0.1833 - lr: 0.050000\n",
            "2024-12-04 14:36:10,074  - 0 epochs without improvement\n",
            "2024-12-04 14:36:10,076 ----------------------------------------------------------------------------------------------------\n",
            "2024-12-04 14:36:33,901 epoch 36 - iter 7/73 - loss 0.20555589 - time (sec): 23.82 - samples/sec: 1342.30 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 14:36:51,312 epoch 36 - iter 14/73 - loss 0.19312191 - time (sec): 41.23 - samples/sec: 1472.28 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 14:37:16,952 epoch 36 - iter 21/73 - loss 0.18429339 - time (sec): 66.87 - samples/sec: 1428.76 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 14:37:37,924 epoch 36 - iter 28/73 - loss 0.18258150 - time (sec): 87.84 - samples/sec: 1426.77 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 14:37:58,639 epoch 36 - iter 35/73 - loss 0.18187162 - time (sec): 108.56 - samples/sec: 1437.75 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 14:38:23,876 epoch 36 - iter 42/73 - loss 0.18303997 - time (sec): 133.80 - samples/sec: 1368.74 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 14:39:00,501 epoch 36 - iter 49/73 - loss 0.18183054 - time (sec): 170.42 - samples/sec: 1262.27 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 14:39:20,414 epoch 36 - iter 56/73 - loss 0.18194070 - time (sec): 190.33 - samples/sec: 1298.63 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 14:39:56,355 epoch 36 - iter 63/73 - loss 0.17961498 - time (sec): 226.28 - samples/sec: 1254.79 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 14:40:13,303 epoch 36 - iter 70/73 - loss 0.18105661 - time (sec): 243.22 - samples/sec: 1273.32 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 14:40:20,166 ----------------------------------------------------------------------------------------------------\n",
            "2024-12-04 14:40:20,170 EPOCH 36 done: loss 0.1812 - lr: 0.050000\n",
            "2024-12-04 14:40:20,174  - 0 epochs without improvement\n",
            "2024-12-04 14:40:20,176 ----------------------------------------------------------------------------------------------------\n",
            "2024-12-04 14:40:35,519 epoch 37 - iter 7/73 - loss 0.18860327 - time (sec): 15.34 - samples/sec: 1756.91 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 14:41:06,754 epoch 37 - iter 14/73 - loss 0.18147721 - time (sec): 46.58 - samples/sec: 1291.29 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 14:41:33,599 epoch 37 - iter 21/73 - loss 0.17864637 - time (sec): 73.42 - samples/sec: 1295.40 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 14:41:58,594 epoch 37 - iter 28/73 - loss 0.17687986 - time (sec): 98.42 - samples/sec: 1286.10 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 14:42:26,224 epoch 37 - iter 35/73 - loss 0.17356335 - time (sec): 126.05 - samples/sec: 1272.91 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 14:42:45,246 epoch 37 - iter 42/73 - loss 0.17694861 - time (sec): 145.07 - samples/sec: 1326.24 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 14:43:09,937 epoch 37 - iter 49/73 - loss 0.17933358 - time (sec): 169.76 - samples/sec: 1325.75 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 14:43:29,673 epoch 37 - iter 56/73 - loss 0.17863627 - time (sec): 189.49 - samples/sec: 1337.73 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 14:43:58,224 epoch 37 - iter 63/73 - loss 0.17672846 - time (sec): 218.05 - samples/sec: 1308.63 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 14:44:19,741 epoch 37 - iter 70/73 - loss 0.17873470 - time (sec): 239.56 - samples/sec: 1300.44 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 14:44:25,948 ----------------------------------------------------------------------------------------------------\n",
            "2024-12-04 14:44:25,952 EPOCH 37 done: loss 0.1798 - lr: 0.050000\n",
            "2024-12-04 14:44:25,954  - 0 epochs without improvement\n",
            "2024-12-04 14:44:25,957 ----------------------------------------------------------------------------------------------------\n",
            "2024-12-04 14:44:47,389 epoch 38 - iter 7/73 - loss 0.15876185 - time (sec): 21.43 - samples/sec: 1653.05 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 14:45:11,941 epoch 38 - iter 14/73 - loss 0.16406796 - time (sec): 45.98 - samples/sec: 1423.37 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 14:45:38,462 epoch 38 - iter 21/73 - loss 0.16630652 - time (sec): 72.50 - samples/sec: 1331.94 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 14:46:00,657 epoch 38 - iter 28/73 - loss 0.17146955 - time (sec): 94.70 - samples/sec: 1309.32 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 14:46:19,442 epoch 38 - iter 35/73 - loss 0.17722232 - time (sec): 113.48 - samples/sec: 1326.27 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 14:46:36,874 epoch 38 - iter 42/73 - loss 0.17978333 - time (sec): 130.92 - samples/sec: 1354.33 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 14:46:58,385 epoch 38 - iter 49/73 - loss 0.17960125 - time (sec): 152.43 - samples/sec: 1367.67 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 14:47:17,251 epoch 38 - iter 56/73 - loss 0.17984413 - time (sec): 171.29 - samples/sec: 1395.08 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 14:47:57,182 epoch 38 - iter 63/73 - loss 0.17933916 - time (sec): 211.22 - samples/sec: 1297.27 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 14:48:22,597 epoch 38 - iter 70/73 - loss 0.17780222 - time (sec): 236.64 - samples/sec: 1301.79 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 14:48:30,456 ----------------------------------------------------------------------------------------------------\n",
            "2024-12-04 14:48:30,459 EPOCH 38 done: loss 0.1772 - lr: 0.050000\n",
            "2024-12-04 14:48:30,463  - 0 epochs without improvement\n",
            "2024-12-04 14:48:30,465 ----------------------------------------------------------------------------------------------------\n",
            "2024-12-04 14:48:56,248 epoch 39 - iter 7/73 - loss 0.17556571 - time (sec): 25.78 - samples/sec: 1134.59 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 14:49:14,093 epoch 39 - iter 14/73 - loss 0.17871771 - time (sec): 43.63 - samples/sec: 1379.21 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 14:49:40,810 epoch 39 - iter 21/73 - loss 0.17938856 - time (sec): 70.34 - samples/sec: 1322.50 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 14:50:19,001 epoch 39 - iter 28/73 - loss 0.17762953 - time (sec): 108.53 - samples/sec: 1178.70 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 14:50:44,478 epoch 39 - iter 35/73 - loss 0.17586283 - time (sec): 134.01 - samples/sec: 1205.39 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 14:51:04,629 epoch 39 - iter 42/73 - loss 0.17583239 - time (sec): 154.16 - samples/sec: 1252.27 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 14:51:31,651 epoch 39 - iter 49/73 - loss 0.17459614 - time (sec): 181.18 - samples/sec: 1224.56 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 14:51:54,593 epoch 39 - iter 56/73 - loss 0.17539517 - time (sec): 204.13 - samples/sec: 1214.83 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 14:52:14,355 epoch 39 - iter 63/73 - loss 0.17535471 - time (sec): 223.89 - samples/sec: 1243.52 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 14:52:39,131 epoch 39 - iter 70/73 - loss 0.17520228 - time (sec): 248.66 - samples/sec: 1261.20 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 14:52:43,021 ----------------------------------------------------------------------------------------------------\n",
            "2024-12-04 14:52:43,023 EPOCH 39 done: loss 0.1762 - lr: 0.050000\n",
            "2024-12-04 14:52:43,025  - 0 epochs without improvement\n",
            "2024-12-04 14:52:43,027 ----------------------------------------------------------------------------------------------------\n",
            "2024-12-04 14:53:03,997 epoch 40 - iter 7/73 - loss 0.19724726 - time (sec): 20.97 - samples/sec: 1323.47 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 14:53:40,847 epoch 40 - iter 14/73 - loss 0.17962538 - time (sec): 57.82 - samples/sec: 1106.15 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 14:54:08,940 epoch 40 - iter 21/73 - loss 0.17984582 - time (sec): 85.91 - samples/sec: 1155.97 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 14:54:34,499 epoch 40 - iter 28/73 - loss 0.17836699 - time (sec): 111.47 - samples/sec: 1167.87 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 14:54:55,594 epoch 40 - iter 35/73 - loss 0.17602523 - time (sec): 132.56 - samples/sec: 1198.23 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 14:55:13,673 epoch 40 - iter 42/73 - loss 0.17222852 - time (sec): 150.64 - samples/sec: 1257.25 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 14:55:36,480 epoch 40 - iter 49/73 - loss 0.17337128 - time (sec): 173.45 - samples/sec: 1273.18 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 14:55:53,642 epoch 40 - iter 56/73 - loss 0.17286397 - time (sec): 190.61 - samples/sec: 1303.64 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 14:56:14,946 epoch 40 - iter 63/73 - loss 0.17361652 - time (sec): 211.92 - samples/sec: 1320.93 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 14:56:38,304 epoch 40 - iter 70/73 - loss 0.17346651 - time (sec): 235.27 - samples/sec: 1322.18 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 14:56:43,524 ----------------------------------------------------------------------------------------------------\n",
            "2024-12-04 14:56:43,528 EPOCH 40 done: loss 0.1740 - lr: 0.050000\n",
            "2024-12-04 14:56:43,530  - 0 epochs without improvement\n",
            "2024-12-04 14:56:43,532 ----------------------------------------------------------------------------------------------------\n",
            "2024-12-04 14:57:10,897 epoch 41 - iter 7/73 - loss 0.17819408 - time (sec): 27.36 - samples/sec: 1208.50 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 14:57:30,213 epoch 41 - iter 14/73 - loss 0.17775140 - time (sec): 46.68 - samples/sec: 1368.96 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 14:58:05,898 epoch 41 - iter 21/73 - loss 0.16917667 - time (sec): 82.36 - samples/sec: 1190.32 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 14:58:26,538 epoch 41 - iter 28/73 - loss 0.17237809 - time (sec): 103.00 - samples/sec: 1257.20 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 14:58:56,622 epoch 41 - iter 35/73 - loss 0.17160192 - time (sec): 133.09 - samples/sec: 1195.10 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 14:59:18,027 epoch 41 - iter 42/73 - loss 0.17298726 - time (sec): 154.49 - samples/sec: 1225.36 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 14:59:44,370 epoch 41 - iter 49/73 - loss 0.17270201 - time (sec): 180.83 - samples/sec: 1215.46 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 15:00:07,713 epoch 41 - iter 56/73 - loss 0.17209077 - time (sec): 204.18 - samples/sec: 1228.44 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 15:00:26,572 epoch 41 - iter 63/73 - loss 0.17291145 - time (sec): 223.04 - samples/sec: 1253.73 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 15:00:47,747 epoch 41 - iter 70/73 - loss 0.17339778 - time (sec): 244.21 - samples/sec: 1273.27 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 15:00:53,944 ----------------------------------------------------------------------------------------------------\n",
            "2024-12-04 15:00:53,948 EPOCH 41 done: loss 0.1737 - lr: 0.050000\n",
            "2024-12-04 15:00:53,953  - 0 epochs without improvement\n",
            "2024-12-04 15:00:53,957 ----------------------------------------------------------------------------------------------------\n",
            "2024-12-04 15:01:13,369 epoch 42 - iter 7/73 - loss 0.17290281 - time (sec): 19.41 - samples/sec: 1502.24 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 15:01:35,249 epoch 42 - iter 14/73 - loss 0.16564084 - time (sec): 41.29 - samples/sec: 1492.58 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 15:02:02,675 epoch 42 - iter 21/73 - loss 0.16532390 - time (sec): 68.72 - samples/sec: 1393.69 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 15:02:23,597 epoch 42 - iter 28/73 - loss 0.16797834 - time (sec): 89.64 - samples/sec: 1356.30 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 15:02:57,209 epoch 42 - iter 35/73 - loss 0.16729930 - time (sec): 123.25 - samples/sec: 1265.52 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 15:03:25,304 epoch 42 - iter 42/73 - loss 0.16883378 - time (sec): 151.34 - samples/sec: 1255.97 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 15:03:49,369 epoch 42 - iter 49/73 - loss 0.17031479 - time (sec): 175.41 - samples/sec: 1258.83 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 15:04:14,818 epoch 42 - iter 56/73 - loss 0.17050547 - time (sec): 200.86 - samples/sec: 1258.60 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 15:04:34,072 epoch 42 - iter 63/73 - loss 0.17061425 - time (sec): 220.11 - samples/sec: 1274.64 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 15:04:53,269 epoch 42 - iter 70/73 - loss 0.17073851 - time (sec): 239.31 - samples/sec: 1291.90 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 15:05:00,766 ----------------------------------------------------------------------------------------------------\n",
            "2024-12-04 15:05:00,768 EPOCH 42 done: loss 0.1705 - lr: 0.050000\n",
            "2024-12-04 15:05:00,771  - 0 epochs without improvement\n",
            "2024-12-04 15:05:00,773 ----------------------------------------------------------------------------------------------------\n",
            "2024-12-04 15:05:18,887 epoch 43 - iter 7/73 - loss 0.16471137 - time (sec): 18.11 - samples/sec: 1690.06 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 15:06:02,938 epoch 43 - iter 14/73 - loss 0.16279746 - time (sec): 62.16 - samples/sec: 1021.69 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 15:06:18,312 epoch 43 - iter 21/73 - loss 0.16998166 - time (sec): 77.54 - samples/sec: 1180.16 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 15:06:36,841 epoch 43 - iter 28/73 - loss 0.16809755 - time (sec): 96.06 - samples/sec: 1269.88 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 15:07:08,096 epoch 43 - iter 35/73 - loss 0.16690190 - time (sec): 127.32 - samples/sec: 1224.90 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 15:07:30,247 epoch 43 - iter 42/73 - loss 0.17205156 - time (sec): 149.47 - samples/sec: 1236.01 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 15:07:46,551 epoch 43 - iter 49/73 - loss 0.17467728 - time (sec): 165.77 - samples/sec: 1255.88 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 15:08:12,038 epoch 43 - iter 56/73 - loss 0.17067275 - time (sec): 191.26 - samples/sec: 1270.31 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 15:08:37,464 epoch 43 - iter 63/73 - loss 0.16943836 - time (sec): 216.69 - samples/sec: 1281.07 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 15:08:55,300 epoch 43 - iter 70/73 - loss 0.17019033 - time (sec): 234.52 - samples/sec: 1311.94 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 15:09:03,056 ----------------------------------------------------------------------------------------------------\n",
            "2024-12-04 15:09:03,060 EPOCH 43 done: loss 0.1697 - lr: 0.050000\n",
            "2024-12-04 15:09:03,066  - 0 epochs without improvement\n",
            "2024-12-04 15:09:03,068 ----------------------------------------------------------------------------------------------------\n",
            "2024-12-04 15:09:25,683 epoch 44 - iter 7/73 - loss 0.17045352 - time (sec): 22.61 - samples/sec: 1383.81 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 15:09:53,499 epoch 44 - iter 14/73 - loss 0.16751453 - time (sec): 50.43 - samples/sec: 1301.26 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 15:10:16,702 epoch 44 - iter 21/73 - loss 0.16816426 - time (sec): 73.63 - samples/sec: 1297.32 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 15:10:39,603 epoch 44 - iter 28/73 - loss 0.16877730 - time (sec): 96.53 - samples/sec: 1300.39 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 15:10:55,859 epoch 44 - iter 35/73 - loss 0.17261830 - time (sec): 112.79 - samples/sec: 1354.33 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 15:11:15,127 epoch 44 - iter 42/73 - loss 0.17136081 - time (sec): 132.06 - samples/sec: 1393.50 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 15:11:50,104 epoch 44 - iter 49/73 - loss 0.16853371 - time (sec): 167.03 - samples/sec: 1321.17 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 15:12:13,893 epoch 44 - iter 56/73 - loss 0.16904965 - time (sec): 190.82 - samples/sec: 1326.73 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 15:12:38,788 epoch 44 - iter 63/73 - loss 0.16845853 - time (sec): 215.72 - samples/sec: 1307.05 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 15:12:57,407 epoch 44 - iter 70/73 - loss 0.16868219 - time (sec): 234.34 - samples/sec: 1316.92 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 15:13:04,779 ----------------------------------------------------------------------------------------------------\n",
            "2024-12-04 15:13:04,782 EPOCH 44 done: loss 0.1682 - lr: 0.050000\n",
            "2024-12-04 15:13:04,787  - 0 epochs without improvement\n",
            "2024-12-04 15:13:04,790 ----------------------------------------------------------------------------------------------------\n",
            "2024-12-04 15:13:43,413 epoch 45 - iter 7/73 - loss 0.14778231 - time (sec): 38.62 - samples/sec: 938.27 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 15:14:09,768 epoch 45 - iter 14/73 - loss 0.15825367 - time (sec): 64.98 - samples/sec: 1014.02 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 15:14:36,694 epoch 45 - iter 21/73 - loss 0.16273829 - time (sec): 91.90 - samples/sec: 1055.23 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 15:15:03,573 epoch 45 - iter 28/73 - loss 0.16373109 - time (sec): 118.78 - samples/sec: 1073.59 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 15:15:21,997 epoch 45 - iter 35/73 - loss 0.16399431 - time (sec): 137.20 - samples/sec: 1146.97 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 15:15:38,336 epoch 45 - iter 42/73 - loss 0.16696172 - time (sec): 153.54 - samples/sec: 1205.83 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 15:16:03,380 epoch 45 - iter 49/73 - loss 0.16812422 - time (sec): 178.59 - samples/sec: 1211.41 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 15:16:25,811 epoch 45 - iter 56/73 - loss 0.16734147 - time (sec): 201.02 - samples/sec: 1244.30 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 15:16:54,108 epoch 45 - iter 63/73 - loss 0.16553808 - time (sec): 229.32 - samples/sec: 1228.62 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 15:17:15,953 epoch 45 - iter 70/73 - loss 0.16643838 - time (sec): 251.16 - samples/sec: 1243.26 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 15:17:19,485 ----------------------------------------------------------------------------------------------------\n",
            "2024-12-04 15:17:19,488 EPOCH 45 done: loss 0.1671 - lr: 0.050000\n",
            "2024-12-04 15:17:19,491  - 0 epochs without improvement\n",
            "2024-12-04 15:17:19,494 ----------------------------------------------------------------------------------------------------\n",
            "2024-12-04 15:17:41,212 epoch 46 - iter 7/73 - loss 0.16493430 - time (sec): 21.72 - samples/sec: 1444.03 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 15:18:05,888 epoch 46 - iter 14/73 - loss 0.17272516 - time (sec): 46.39 - samples/sec: 1302.50 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 15:18:35,200 epoch 46 - iter 21/73 - loss 0.17173138 - time (sec): 75.70 - samples/sec: 1181.86 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 15:18:57,110 epoch 46 - iter 28/73 - loss 0.17415189 - time (sec): 97.61 - samples/sec: 1243.12 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 15:19:25,672 epoch 46 - iter 35/73 - loss 0.16966697 - time (sec): 126.18 - samples/sec: 1248.91 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 15:19:50,203 epoch 46 - iter 42/73 - loss 0.16936462 - time (sec): 150.71 - samples/sec: 1230.38 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 15:20:16,777 epoch 46 - iter 49/73 - loss 0.16922620 - time (sec): 177.28 - samples/sec: 1212.58 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 15:20:44,305 epoch 46 - iter 56/73 - loss 0.16737955 - time (sec): 204.81 - samples/sec: 1184.68 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 15:21:01,753 epoch 46 - iter 63/73 - loss 0.16703355 - time (sec): 222.26 - samples/sec: 1238.54 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 15:21:32,381 epoch 46 - iter 70/73 - loss 0.16635363 - time (sec): 252.88 - samples/sec: 1224.66 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 15:21:39,042 ----------------------------------------------------------------------------------------------------\n",
            "2024-12-04 15:21:39,047 EPOCH 46 done: loss 0.1666 - lr: 0.050000\n",
            "2024-12-04 15:21:39,050  - 0 epochs without improvement\n",
            "2024-12-04 15:21:39,052 ----------------------------------------------------------------------------------------------------\n",
            "2024-12-04 15:21:59,851 epoch 47 - iter 7/73 - loss 0.16479423 - time (sec): 20.80 - samples/sec: 1467.26 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 15:22:25,266 epoch 47 - iter 14/73 - loss 0.16218544 - time (sec): 46.21 - samples/sec: 1394.63 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 15:22:56,805 epoch 47 - iter 21/73 - loss 0.16241783 - time (sec): 77.75 - samples/sec: 1255.71 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 15:23:26,739 epoch 47 - iter 28/73 - loss 0.16081839 - time (sec): 107.68 - samples/sec: 1164.85 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 15:23:45,560 epoch 47 - iter 35/73 - loss 0.16200583 - time (sec): 126.51 - samples/sec: 1217.92 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 15:24:08,906 epoch 47 - iter 42/73 - loss 0.16440008 - time (sec): 149.85 - samples/sec: 1216.90 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 15:24:29,964 epoch 47 - iter 49/73 - loss 0.16219769 - time (sec): 170.91 - samples/sec: 1251.19 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 15:24:50,866 epoch 47 - iter 56/73 - loss 0.16175029 - time (sec): 191.81 - samples/sec: 1273.52 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 15:25:16,906 epoch 47 - iter 63/73 - loss 0.16257580 - time (sec): 217.85 - samples/sec: 1274.32 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 15:25:42,051 epoch 47 - iter 70/73 - loss 0.16347248 - time (sec): 243.00 - samples/sec: 1277.44 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 15:25:49,269 ----------------------------------------------------------------------------------------------------\n",
            "2024-12-04 15:25:49,273 EPOCH 47 done: loss 0.1636 - lr: 0.050000\n",
            "2024-12-04 15:25:49,278  - 0 epochs without improvement\n",
            "2024-12-04 15:25:49,280 ----------------------------------------------------------------------------------------------------\n",
            "2024-12-04 15:26:13,502 epoch 48 - iter 7/73 - loss 0.17113965 - time (sec): 24.22 - samples/sec: 1244.64 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 15:26:42,887 epoch 48 - iter 14/73 - loss 0.17083376 - time (sec): 53.61 - samples/sec: 1178.43 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 15:27:02,410 epoch 48 - iter 21/73 - loss 0.16943307 - time (sec): 73.13 - samples/sec: 1291.46 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 15:27:23,729 epoch 48 - iter 28/73 - loss 0.17087943 - time (sec): 94.45 - samples/sec: 1295.98 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 15:27:42,524 epoch 48 - iter 35/73 - loss 0.16750500 - time (sec): 113.24 - samples/sec: 1332.61 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 15:28:00,344 epoch 48 - iter 42/73 - loss 0.16827194 - time (sec): 131.06 - samples/sec: 1361.73 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 15:28:42,281 epoch 48 - iter 49/73 - loss 0.16464983 - time (sec): 173.00 - samples/sec: 1242.97 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 15:29:04,437 epoch 48 - iter 56/73 - loss 0.16264121 - time (sec): 195.16 - samples/sec: 1278.47 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 15:29:26,273 epoch 48 - iter 63/73 - loss 0.16447490 - time (sec): 216.99 - samples/sec: 1280.44 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 15:30:01,905 epoch 48 - iter 70/73 - loss 0.16391302 - time (sec): 252.62 - samples/sec: 1235.98 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 15:30:07,568 ----------------------------------------------------------------------------------------------------\n",
            "2024-12-04 15:30:07,571 EPOCH 48 done: loss 0.1634 - lr: 0.050000\n",
            "2024-12-04 15:30:07,573  - 0 epochs without improvement\n",
            "2024-12-04 15:30:07,575 ----------------------------------------------------------------------------------------------------\n",
            "2024-12-04 15:30:24,318 epoch 49 - iter 7/73 - loss 0.17816226 - time (sec): 16.74 - samples/sec: 1511.11 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 15:30:57,023 epoch 49 - iter 14/73 - loss 0.16063363 - time (sec): 49.45 - samples/sec: 1178.12 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 15:31:16,805 epoch 49 - iter 21/73 - loss 0.15738171 - time (sec): 69.23 - samples/sec: 1285.60 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 15:31:53,137 epoch 49 - iter 28/73 - loss 0.15461444 - time (sec): 105.56 - samples/sec: 1178.44 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 15:32:12,015 epoch 49 - iter 35/73 - loss 0.15984106 - time (sec): 124.44 - samples/sec: 1216.43 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 15:32:33,581 epoch 49 - iter 42/73 - loss 0.16133251 - time (sec): 146.00 - samples/sec: 1249.39 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 15:32:51,551 epoch 49 - iter 49/73 - loss 0.16376342 - time (sec): 163.97 - samples/sec: 1281.54 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 15:33:14,662 epoch 49 - iter 56/73 - loss 0.16273054 - time (sec): 187.08 - samples/sec: 1300.12 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 15:33:39,786 epoch 49 - iter 63/73 - loss 0.16217673 - time (sec): 212.21 - samples/sec: 1302.66 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 15:34:08,232 epoch 49 - iter 70/73 - loss 0.16184104 - time (sec): 240.65 - samples/sec: 1287.53 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 15:34:14,883 ----------------------------------------------------------------------------------------------------\n",
            "2024-12-04 15:34:14,885 EPOCH 49 done: loss 0.1614 - lr: 0.050000\n",
            "2024-12-04 15:34:14,888  - 0 epochs without improvement\n",
            "2024-12-04 15:34:14,891 ----------------------------------------------------------------------------------------------------\n",
            "2024-12-04 15:34:36,690 epoch 50 - iter 7/73 - loss 0.15302425 - time (sec): 21.80 - samples/sec: 1370.62 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 15:34:55,818 epoch 50 - iter 14/73 - loss 0.15910865 - time (sec): 40.92 - samples/sec: 1483.41 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 15:35:23,626 epoch 50 - iter 21/73 - loss 0.15567488 - time (sec): 68.73 - samples/sec: 1363.94 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 15:35:40,780 epoch 50 - iter 28/73 - loss 0.15894825 - time (sec): 85.89 - samples/sec: 1441.67 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 15:36:04,552 epoch 50 - iter 35/73 - loss 0.16104035 - time (sec): 109.66 - samples/sec: 1421.54 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 15:36:31,521 epoch 50 - iter 42/73 - loss 0.16193733 - time (sec): 136.63 - samples/sec: 1374.95 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 15:36:58,490 epoch 50 - iter 49/73 - loss 0.15814331 - time (sec): 163.60 - samples/sec: 1340.52 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 15:37:15,995 epoch 50 - iter 56/73 - loss 0.16022087 - time (sec): 181.10 - samples/sec: 1363.80 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 15:37:40,417 epoch 50 - iter 63/73 - loss 0.15980028 - time (sec): 205.52 - samples/sec: 1356.01 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 15:38:12,060 epoch 50 - iter 70/73 - loss 0.16105109 - time (sec): 237.17 - samples/sec: 1303.04 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-12-04 15:38:16,760 ----------------------------------------------------------------------------------------------------\n",
            "2024-12-04 15:38:16,761 EPOCH 50 done: loss 0.1618 - lr: 0.050000\n",
            "2024-12-04 15:38:16,764  - 1 epochs without improvement\n",
            "2024-12-04 15:38:23,605 ----------------------------------------------------------------------------------------------------\n",
            "2024-12-04 15:38:23,607 Testing using last state of model ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/5 [00:17<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "OutOfMemoryError",
          "evalue": "CUDA out of memory. Tried to allocate 5.38 GiB. GPU 0 has a total capacity of 14.75 GiB of which 1.19 GiB is free. Process 3542 has 13.55 GiB memory in use. Of the allocated memory 11.10 GiB is allocated by PyTorch, and 2.31 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-23a59c7addae>\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# train Flair NER Model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m trainer.train(\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mbase_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'flair_output/'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.05\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Lower learning rate for more stable training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/flair/trainers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, base_path, anneal_factor, patience, min_learning_rate, initial_extra_patience, anneal_with_restarts, learning_rate, decoder_learning_rate, mini_batch_size, eval_batch_size, mini_batch_chunk_size, max_epochs, optimizer, train_with_dev, train_with_test, reduce_transformer_vocab, main_evaluation_metric, monitor_test, monitor_train_sample, use_final_model_for_eval, gold_label_dictionary_for_eval, exclude_labels, sampler, shuffle, shuffle_first_epoch, embeddings_storage_mode, epoch, save_final_model, save_optimizer_state, save_model_each_k_epochs, create_file_logs, create_loss_file, write_weights, plugins, attach_default_scheduler, **kwargs)\u001b[0m\n\u001b[1;32m    198\u001b[0m         ]:\n\u001b[1;32m    199\u001b[0m             \u001b[0mlocal_variables\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_custom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mlocal_variables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m     def fine_tune(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/flair/trainers/trainer.py\u001b[0m in \u001b[0;36mtrain_custom\u001b[0;34m(self, base_path, learning_rate, decoder_learning_rate, mini_batch_size, eval_batch_size, mini_batch_chunk_size, max_epochs, optimizer, train_with_dev, train_with_test, max_grad_norm, reduce_transformer_vocab, main_evaluation_metric, monitor_test, monitor_train_sample, use_final_model_for_eval, gold_label_dictionary_for_eval, exclude_labels, sampler, shuffle, shuffle_first_epoch, embeddings_storage_mode, epoch, save_final_model, save_optimizer_state, save_model_each_k_epochs, create_file_logs, create_loss_file, write_weights, use_amp, plugins, **kwargs)\u001b[0m\n\u001b[1;32m    783\u001b[0m                     \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Testing using last state of model ...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    784\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 785\u001b[0;31m                 test_results = self.model.evaluate(\n\u001b[0m\u001b[1;32m    786\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    787\u001b[0m                     \u001b[0mgold_label_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel_type\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/flair/nn/model.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, data_points, gold_label_type, out_path, embedding_storage_mode, mini_batch_size, main_evaluation_metric, exclude_labels, gold_label_dictionary, return_loss, **kwargs)\u001b[0m\n\u001b[1;32m    295\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m                 \u001b[0;31m# predict for batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 297\u001b[0;31m                 loss_and_count = self.predict(\n\u001b[0m\u001b[1;32m    298\u001b[0m                     \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m                     \u001b[0membedding_storage_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0membedding_storage_mode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/flair/models/sequence_tagger_model.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, sentences, mini_batch_size, return_probabilities_for_all_classes, verbose, label_name, return_loss, embedding_storage_mode, force_token_predictions)\u001b[0m\n\u001b[1;32m    490\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m                 \u001b[0;31m# get features from forward propagation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 492\u001b[0;31m                 \u001b[0msentence_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    493\u001b[0m                 \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/flair/models/sequence_tagger_model.py\u001b[0m in \u001b[0;36m_prepare_tensors\u001b[0;34m(self, data_points)\u001b[0m\n\u001b[1;32m    284\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prepare_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_points\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mSentence\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSentence\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m         \u001b[0msentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdata_points\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_points\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mdata_points\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m         \u001b[0;31m# make a zero-padded tensor for the whole sentence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/flair/embeddings/token.py\u001b[0m in \u001b[0;36membed\u001b[0;34m(self, sentences, static_embeddings)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0membedding\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m             \u001b[0membedding\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/flair/embeddings/base.py\u001b[0m in \u001b[0;36membed\u001b[0;34m(self, data_points)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_everything_embedded\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_points\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_embeddings_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_points\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata_points\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/flair/embeddings/token.py\u001b[0m in \u001b[0;36m_add_embeddings_internal\u001b[0;34m(self, sentences)\u001b[0m\n\u001b[1;32m    813\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    814\u001b[0m             \u001b[0;31m# get hidden states from language model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 815\u001b[0;31m             all_hidden_states_in_lm = self.lm.get_representation(\n\u001b[0m\u001b[1;32m    816\u001b[0m                 \u001b[0mtext_sentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_marker\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_marker\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchars_per_chunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    817\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/flair/models/language_model.py\u001b[0m in \u001b[0;36mget_representation\u001b[0;34m(self, strings, start_marker, end_marker, chars_per_chunk)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0;31m# concatenate all chunks to make final output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_parts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 5.38 GiB. GPU 0 has a total capacity of 14.75 GiB of which 1.19 GiB is free. Process 3542 has 13.55 GiB memory in use. Of the allocated memory 11.10 GiB is allocated by PyTorch, and 2.31 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate model\n",
        "\n",
        "from flair.data import Corpus\n",
        "from flair.datasets import ColumnCorpus\n",
        "from flair.models import SequenceTagger\n",
        "from flair.trainers import ModelTrainer\n",
        "\n",
        "# load the trained model\n",
        "tagger = SequenceTagger.load('/content/drive/MyDrive/FYP/Implementation/flair_output/final-model.pt')\n",
        "# tagger = SequenceTagger.load('/content/final-model.pt')\n",
        "\n",
        "# evaluate the model on the test set\n",
        "result = tagger.evaluate(corpus.test, gold_label_type='ner', mini_batch_size=32)\n",
        "\n",
        "# print the results\n",
        "# print(\"Evaluation Loss:\", eval_loss)\n",
        "print(result.detailed_results)  # print the precision, recall, and F1-score per entity type"
      ],
      "metadata": {
        "id": "6KT8wj3Lns2c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a67c9f9-64d9-4232-df94-1bcf9811d565"
      },
      "id": "6KT8wj3Lns2c",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-12-12 08:51:38,310 SequenceTagger predicts: Dictionary with 47 tags: O, S-SKILL, B-SKILL, E-SKILL, I-SKILL, S-JOB, B-JOB, E-JOB, I-JOB, S-LOC, B-LOC, E-LOC, I-LOC, S-WORK, B-WORK, E-WORK, I-WORK, S-COMPANY, B-COMPANY, E-COMPANY, I-COMPANY, S-UNI, B-UNI, E-UNI, I-UNI, S-DEG, B-DEG, E-DEG, I-DEG, S-NAME, B-NAME, E-NAME, I-NAME, S-STUDY, B-STUDY, E-STUDY, I-STUDY, S-PHONE, B-PHONE, E-PHONE, I-PHONE, S-EMAIL, B-EMAIL, E-EMAIL, I-EMAIL, <START>, <STOP>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 13/13 [02:12<00:00, 10.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Results:\n",
            "- F-score (micro) 0.648\n",
            "- F-score (macro) 0.789\n",
            "- Accuracy 0.4826\n",
            "\n",
            "By class:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       SKILL     0.4602    0.5290    0.4922      3913\n",
            "         JOB     0.5969    0.7389    0.6604      1038\n",
            "         LOC     0.7701    0.9082    0.8334       697\n",
            "        WORK     0.8596    0.9259    0.8915       688\n",
            "     COMPANY     0.6742    0.7855    0.7256       606\n",
            "         UNI     0.6715    0.7938    0.7276       291\n",
            "         DEG     0.7381    0.8127    0.7736       267\n",
            "        NAME     0.9425    0.8950    0.9181       238\n",
            "       PHONE     0.9518    0.9559    0.9538       227\n",
            "       STUDY     0.6933    0.8418    0.7604       196\n",
            "       EMAIL     0.9078    0.9791    0.9421       191\n",
            "\n",
            "   micro avg     0.6063    0.6960    0.6480      8352\n",
            "   macro avg     0.7514    0.8333    0.7890      8352\n",
            "weighted avg     0.6105    0.6960    0.6499      8352\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# make prediction\n",
        "\n",
        "from flair.models import SequenceTagger\n",
        "from flair.data import Sentence\n",
        "import spacy, string\n",
        "from spacy import displacy\n",
        "\n",
        "# load trained Flair NER model\n",
        "# tagger = SequenceTagger.load('/content/drive/MyDrive/FYP/Implementation/flair_output/best-model.pt')\n",
        "# tagger = SequenceTagger.load('/content/final-model.pt')\n",
        "\n",
        "resume_text = '''\n",
        "John Doe lives at 1234 Elm Street in Los Angeles, CA 90001. He can be reached at +1 (555) 123-4567 or via email at john.doe@example.com. John is a results-driven software engineer with over 5 years of experience in web development and cloud infrastructure, with strong knowledge of JavaScript, Python, and cloud technologies like AWS and Azure. Currently, he works as a Software Engineer at Google LLC in San Francisco, CA, where he has been employed since August 2019. In this role, he has developed scalable web applications using JavaScript, Node.js, and React, deployed and maintained cloud infrastructure on AWS, reducing downtime by 20%, and led a team of 4 engineers to enhance backend performance by 30%. Previously, he worked as a Junior Developer at Tech Innovators Inc. in Austin, TX, from July 2017 to July 2019, where he created RESTful APIs using Python and Flask, collaborated with front-end developers to build and deploy user-facing applications, and wrote unit and integration tests, improving code coverage by 15%.\n",
        "\n",
        "John holds a Master of Science in Computer Science from the University of California, Berkeley, with a graduation date of May 2017, and a Bachelor of Science in Information Technology from the University of Texas at Austin, graduated in May 2015. His skillset includes proficiency in programming languages like Python, JavaScript, and Java; frameworks such as React, Flask, and Django; cloud platforms including AWS, Google Cloud, and Azure; as well as other tools like Git, Docker, Kubernetes, and SQL. He is certified as an AWS Certified Solutions Architect – Associate, earned in 2020, and as a Google Professional Cloud Architect, earned in 2021'\n",
        "'''\n",
        "\n",
        "# make into all small letter and remove punctuations\n",
        "resume_text = resume_text.lower()\n",
        "resume_text = resume_text.translate(str.maketrans('', '', string.punctuation))\n",
        "\n",
        "# step 1: predict entities using Flair trained model\n",
        "sentence = Sentence(resume_text)\n",
        "tagger.predict(sentence)\n",
        "\n",
        "# step 2: convert Flair predictions to spaCy doc format\n",
        "# initialize a blank spaCy NLP pipeline\n",
        "nlp = spacy.blank(\"en\")\n",
        "doc = nlp(resume_text)\n",
        "\n",
        "# extract entities from Flair prediction and convert to spaCy format\n",
        "ents = []\n",
        "for entity in sentence.get_spans('ner'):\n",
        "    start, end = entity.start_position, entity.end_position\n",
        "    label = entity.tag\n",
        "    span = doc.char_span(start, end, label=label)\n",
        "    if span is not None:\n",
        "        ents.append(span)\n",
        "\n",
        "# set the entities in the spaCy doc\n",
        "doc.ents = ents\n",
        "\n",
        "# step 3: visualization of prediction using displacy\n",
        "displacy.render(doc, style=\"ent\", jupyter=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 562
        },
        "id": "0DZ319Yi-1eq",
        "outputId": "8cf20b48-6378-4da4-ea42-0dee1cabc255"
      },
      "id": "0DZ319Yi-1eq",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/spacy/util.py:1740: UserWarning: [W111] Jupyter notebook detected: if using `prefer_gpu()` or `require_gpu()`, include it in the same cell right before `spacy.load()` to ensure that the model is loaded on the correct device. More information: http://spacy.io/usage/v3#jupyter-notebook-gpu\n",
            "  warnings.warn(Warnings.W111)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\"><br>\n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    john doe\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NAME</span>\n",
              "</mark>\n",
              " lives at 1234 elm street in \n",
              "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    los angeles\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
              "</mark>\n",
              " ca 90001 he can be reached at \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    1 555 1234567\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PHONE</span>\n",
              "</mark>\n",
              " or via email at \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    johndoeexamplecom john\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">EMAIL</span>\n",
              "</mark>\n",
              " is a resultsdriven \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    software engineer\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">JOB</span>\n",
              "</mark>\n",
              " with over 5 years of experience in \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    web development\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">SKILL</span>\n",
              "</mark>\n",
              " and \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    cloud infrastructure\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">SKILL</span>\n",
              "</mark>\n",
              " with strong knowledge of \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    javascript\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">SKILL</span>\n",
              "</mark>\n",
              " \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    python\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">SKILL</span>\n",
              "</mark>\n",
              " and cloud technologies like \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    aws\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">SKILL</span>\n",
              "</mark>\n",
              " and azure currently he works as \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    a software engineer\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">JOB</span>\n",
              "</mark>\n",
              " at \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    google llc\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">COMPANY</span>\n",
              "</mark>\n",
              " in \n",
              "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    san francisco\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
              "</mark>\n",
              " ca where he has been employed since \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    august 2019\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">WORK</span>\n",
              "</mark>\n",
              " in this role he has developed scalable web applications using \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    javascript\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">SKILL</span>\n",
              "</mark>\n",
              " \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    nodejs\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">SKILL</span>\n",
              "</mark>\n",
              " and react deployed and maintained \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    cloud infrastructure\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">SKILL</span>\n",
              "</mark>\n",
              " on aws reducing downtime by 20 and led a team of 4 engineers to enhance backend performance by 30 previously he worked as a \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    junior developer\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">JOB</span>\n",
              "</mark>\n",
              " \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    at tech innovators inc\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">COMPANY</span>\n",
              "</mark>\n",
              " in \n",
              "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    austin\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
              "</mark>\n",
              " tx \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    from july 2017 to july 2019\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">WORK</span>\n",
              "</mark>\n",
              " where he created \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    restful apis\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">SKILL</span>\n",
              "</mark>\n",
              " using \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    python\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">SKILL</span>\n",
              "</mark>\n",
              " and flask collaborated with \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    frontend developers\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">JOB</span>\n",
              "</mark>\n",
              " to build and deploy userfacing applications and wrote unit and integration tests improving code coverage by 15<br><br>john holds a \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    master of science in computer science\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DEG</span>\n",
              "</mark>\n",
              " from \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    the university of california\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">UNI</span>\n",
              "</mark>\n",
              " \n",
              "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    berkeley\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
              "</mark>\n",
              " with a graduation date of \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    may 2017\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">STUDY</span>\n",
              "</mark>\n",
              " and a \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    bachelor of science in information technology\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DEG</span>\n",
              "</mark>\n",
              " from \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    the university of texas at\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">UNI</span>\n",
              "</mark>\n",
              " \n",
              "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    austin\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
              "</mark>\n",
              " graduated in \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    may 2015\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">STUDY</span>\n",
              "</mark>\n",
              " his skillset includes proficiency in programming languages like \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    python\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">SKILL</span>\n",
              "</mark>\n",
              " \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    javascript\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">SKILL</span>\n",
              "</mark>\n",
              " and java frameworks such as react flask and django cloud platforms including \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    aws\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">SKILL</span>\n",
              "</mark>\n",
              " \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    google cloud\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">SKILL</span>\n",
              "</mark>\n",
              " and \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    azure\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">SKILL</span>\n",
              "</mark>\n",
              " as well as other tools like \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    git\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">SKILL</span>\n",
              "</mark>\n",
              " \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    docker\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">SKILL</span>\n",
              "</mark>\n",
              " \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    kubernetes\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">SKILL</span>\n",
              "</mark>\n",
              " and sql he is certified as an aws certified \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    solutions architect\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">JOB</span>\n",
              "</mark>\n",
              " – associate earned in 2020 and as a google professional \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    cloud architect\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">JOB</span>\n",
              "</mark>\n",
              " earned in 2021<br></div></span>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "resume_text_1 = '''\n",
        "Zi Qing Chew\n",
        "chewziqing@gmail.com | 016-2892475 | Kuala Lumpur, Malaysia | linkedin.com/in/ziqingchew | github.com/chewzzz1014\n",
        "EDUCATION\n",
        "\n",
        "Universiti Putra Malaysia\t\t\t\t\t                                                   Oct 2021 - Current\n",
        "Bachelor in Computer Science with Honours\n",
        "Expected to graduate in July 2025. CGPA: 3.99\n",
        "\n",
        "WORK EXPERIENCE\n",
        "\n",
        "Ant International \t\t\t\t\t\t\t\t\t          \tJuly 2024 – Oct 2024\n",
        "Java Engineer Intern\t\t\t\t\t\t\t                               Kuala Lumpur, Malaysia\n",
        "Collaborated in developing an audit logging feature for Ant Group’s internal Foreign Exchange (FX) trade strategy system that records changes made by business users to trade strategies.\n",
        "Conducted comprehensive system analysis and project planning, delivering presentations to project stakeholders and QA teams prior to the development phase.\n",
        "Utilised Ant Group’s internal frameworks, middleware, and tools to implement the audit logging feature.\n",
        "Skills: Java, Spring, Sofaboot, Ant Group internal middlewares (ZDAL, DRM, Ant Scheduler, Msg Broker)\n",
        "Howuku  \t\t\t\t\t\t\t\t\t          \t             Feb 2023 – Sep 2023\n",
        "Software Developer Intern\t\t\t\t\t\t\t                    Kuala Lumpur, Malaysia\n",
        "Developed and optimized A/B testing features, including code editor and previewer for CSS and JavaScript modifications for experiment variations.\n",
        "Expanded A/B testing targeting rule by incorporating website visitor's OS, device, and browser rules.\n",
        "Automated experiment-stopping criteria and email notifications based on user-defined experiment termination conditions.\n",
        "Collaborated with cross-functional teams to debug, troubleshoot, and enhance Howuku platform features based on user feedback and performance data.\n",
        "Skills: JavaScript, Bootstrap, Vue.js, Express.js, MySQL\n",
        "\n",
        "PROJECTS\n",
        "\n",
        "Personal Portfolio Website (chewzzz1014.github.io/portfolio-website)\n",
        "Designed, developed and deployed personalised portfolio website featuring skills, selected projects, and downloadable resume.\n",
        "Skills: JavaScript, React.js, CSS, Bootstrap\n",
        "Depression Level Detection Chatbot (https://github.com/chewzzz1014/health-ease-project)\n",
        "Developed machine learning application that evaluates a message's depression level and provided tailored mental health advice and information based on the depression severity.\n",
        "Skills: Python, pandas, scikit-learn, Keras, FastAPI, Gradio\n",
        "Clothing Store Website (https://github.com/chewzzz1014/CSC3402-MVC-Project)\n",
        "Worked in team to build a CRUD Spring Boot application with attractive interfaces, data persistence, authentication and authorisation.\n",
        "Developed the backend of the application that involves querying the database, building REST endpoints and implementing Thymeleaf in HTML for dynamic contents.\n",
        "Skills: Spring Boot, Spring MVC, Thymeleaf, Hibernate, Bootstrap\n",
        "\n",
        "SKILLS\n",
        "Programming Languages: Java, Python, HTML, CSS, JavaScript, MySQL, OracleSQL\n",
        "Frameworks and Libraries: Spring, Spring Boot, TypeScript, Node.js, Express.js, React.js, Vue.js, Bootstrap, Tailwind CSS\n",
        "Tools: Git, Github, Jira, Tableau, Excel, Jupyter Notebook, Google Colab, VSCode, IntelliJ\n",
        "'''"
      ],
      "metadata": {
        "id": "jqsShhe4c7cu"
      },
      "id": "jqsShhe4c7cu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# make prediction\n",
        "from flair.models import SequenceTagger\n",
        "from flair.data import Sentence\n",
        "import spacy, string\n",
        "from spacy import displacy\n",
        "\n",
        "\n",
        "# load trained Flair NER model\n",
        "# tagger = SequenceTagger.load('/content/drive/MyDrive/FYP/Implementation/flair_output/best-model.pt')\n",
        "# tagger = SequenceTagger.load('/content/final-model.pt')\n",
        "\n",
        "resume_text_1 = resume_text_1.lower()\n",
        "resume_text_1 = resume_text_1.translate(str.maketrans('', '', string.punctuation))\n",
        "\n",
        "# step 1: predict entities using Flair trained model\n",
        "sentence = Sentence(resume_text_1)\n",
        "tagger.predict(sentence)\n",
        "\n",
        "\n",
        "# step 2: convert Flair predictions to spaCy doc format\n",
        "# initialize a blank spaCy NLP pipeline\n",
        "nlp = spacy.blank(\"en\")\n",
        "doc = nlp(resume_text_1)\n",
        "\n",
        "\n",
        "# extract entities from Flair prediction and convert to spaCy format\n",
        "ents = []\n",
        "for entity in sentence.get_spans('ner'):\n",
        "    start, end = entity.start_position, entity.end_position\n",
        "    label = entity.tag\n",
        "    span = doc.char_span(start, end, label=label)\n",
        "    if span is not None:\n",
        "        ents.append(span)\n",
        "\n",
        "\n",
        "\n",
        "# set the entities in the spaCy doc\n",
        "doc.ents = ents\n",
        "\n",
        "\n",
        "\n",
        "# step 3: visualization of prediction using displacy\n",
        "displacy.render(doc, style=\"ent\", jupyter=True)"
      ],
      "metadata": {
        "id": "9PKi0AjLc_l3",
        "outputId": "81f70b55-a6bc-4c3b-cbf1-86ef13336b8d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "id": "9PKi0AjLc_l3",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\"><br>zi qing chew<br>\n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    chewziqinggmailcom\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">EMAIL</span>\n",
              "</mark>\n",
              "  \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    0162892475\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PHONE</span>\n",
              "</mark>\n",
              "  \n",
              "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    kuala\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
              "</mark>\n",
              " lumpur malaysia  linkedincominziqingchew  githubcomchewzzz1014<br>education<br><br>\n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    universiti putra malaysia\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">UNI</span>\n",
              "</mark>\n",
              "\t\t\t\t\t                                                   \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    oct 2021  current\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">STUDY</span>\n",
              "</mark>\n",
              "<br>\n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    bachelor in computer science\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DEG</span>\n",
              "</mark>\n",
              " with honours<br>expected to graduate in \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    july 2025\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">STUDY</span>\n",
              "</mark>\n",
              " cgpa 399<br><br>work experience<br><br>\n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    ant international\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">COMPANY</span>\n",
              "</mark>\n",
              " \t\t\t\t\t\t\t\t\t          \t\n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    july 2024 – oct 2024\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">WORK</span>\n",
              "</mark>\n",
              "<br>\n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    java engineer intern\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">JOB</span>\n",
              "</mark>\n",
              "\t\t\t\t\t\t\t                               \n",
              "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    kuala lumpur\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
              "</mark>\n",
              " malaysia<br>collaborated in developing an audit logging feature for ant group’s internal foreign exchange fx trade strategy system that records changes made by business users to trade strategies<br>conducted comprehensive system analysis and project planning delivering presentations to project stakeholders and qa teams prior to the development phase<br>utilised ant group’s internal frameworks middleware and tools to implement the audit logging feature<br>skills java spring sofaboot ant group internal middlewares zdal drm ant scheduler \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    msg broker\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">JOB</span>\n",
              "</mark>\n",
              "<br>\n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    howuku\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">COMPANY</span>\n",
              "</mark>\n",
              "  \t\t\t\t\t\t\t\t\t          \t             \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    feb 2023 – sep 2023\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">WORK</span>\n",
              "</mark>\n",
              "<br>\n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    software developer intern\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">JOB</span>\n",
              "</mark>\n",
              "\t\t\t\t\t\t\t                    \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    kuala lumpur malaysia\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">COMPANY</span>\n",
              "</mark>\n",
              "<br>developed and optimized \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    ab testing\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">SKILL</span>\n",
              "</mark>\n",
              " features including code editor and previewer for \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    css\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">SKILL</span>\n",
              "</mark>\n",
              " and javascript modifications for experiment variations<br>expanded ab testing targeting rule by incorporating website visitors os device and browser rules<br>automated experimentstopping criteria and email notifications based on userdefined experiment termination conditions<br>collaborated with crossfunctional teams to debug troubleshoot and enhance howuku platform features based on user feedback and performance data<br>skills \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    javascript\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">SKILL</span>\n",
              "</mark>\n",
              " \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    bootstrap\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">SKILL</span>\n",
              "</mark>\n",
              " \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    vuejs\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">SKILL</span>\n",
              "</mark>\n",
              " \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    expressjs\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">SKILL</span>\n",
              "</mark>\n",
              " \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    mysql\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">SKILL</span>\n",
              "</mark>\n",
              "<br><br>projects<br><br>personal portfolio website chewzzz1014githubioportfoliowebsite<br>designed developed and deployed personalised portfolio website featuring skills selected projects and downloadable resume<br>skills \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    javascript\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">SKILL</span>\n",
              "</mark>\n",
              " \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    reactjs\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">SKILL</span>\n",
              "</mark>\n",
              " \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    css\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">SKILL</span>\n",
              "</mark>\n",
              " \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    bootstrap\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">SKILL</span>\n",
              "</mark>\n",
              "<br>depression level detection chatbot httpsgithubcomchewzzz1014healtheaseproject<br>developed \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    machine learning\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">SKILL</span>\n",
              "</mark>\n",
              " application that evaluates a messages depression level and provided tailored mental health advice and information based on the depression severity<br>skills \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    python\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">SKILL</span>\n",
              "</mark>\n",
              " \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    pandas\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">SKILL</span>\n",
              "</mark>\n",
              " \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    scikitlearn\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">SKILL</span>\n",
              "</mark>\n",
              " \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    keras\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">SKILL</span>\n",
              "</mark>\n",
              " fastapi gradio<br>clothing store website httpsgithubcomchewzzz1014csc3402mvcproject<br>worked in team to build a crud spring boot application with attractive interfaces data persistence authentication and authorisation<br>developed the backend of the application that involves querying the database building rest endpoints and implementing thymeleaf in html for dynamic contents<br>skills \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    spring boot\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">SKILL</span>\n",
              "</mark>\n",
              " \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    spring mvc\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">SKILL</span>\n",
              "</mark>\n",
              " \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    thymeleaf\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">SKILL</span>\n",
              "</mark>\n",
              " \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    hibernate\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">SKILL</span>\n",
              "</mark>\n",
              " \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    bootstrap\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">SKILL</span>\n",
              "</mark>\n",
              "<br><br>skills<br>programming languages \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    java\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">SKILL</span>\n",
              "</mark>\n",
              " \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    python\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">SKILL</span>\n",
              "</mark>\n",
              " \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    html\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">SKILL</span>\n",
              "</mark>\n",
              " \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    css\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">SKILL</span>\n",
              "</mark>\n",
              " \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    javascript\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">SKILL</span>\n",
              "</mark>\n",
              " \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    mysql\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">SKILL</span>\n",
              "</mark>\n",
              " \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    oraclesql\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">SKILL</span>\n",
              "</mark>\n",
              "<br>frameworks and libraries \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    spring spring boot\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">SKILL</span>\n",
              "</mark>\n",
              " \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    typescript\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">SKILL</span>\n",
              "</mark>\n",
              " \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    nodejs\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">SKILL</span>\n",
              "</mark>\n",
              " \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    expressjs\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">SKILL</span>\n",
              "</mark>\n",
              " \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    reactjs\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">SKILL</span>\n",
              "</mark>\n",
              " \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    vuejs\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">SKILL</span>\n",
              "</mark>\n",
              " \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    bootstrap\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">SKILL</span>\n",
              "</mark>\n",
              " \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    tailwind\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">SKILL</span>\n",
              "</mark>\n",
              " \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    css\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">SKILL</span>\n",
              "</mark>\n",
              "<br>tools \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    git\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">SKILL</span>\n",
              "</mark>\n",
              " \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    github\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">SKILL</span>\n",
              "</mark>\n",
              " \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    jira\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">SKILL</span>\n",
              "</mark>\n",
              " \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    tableau\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">SKILL</span>\n",
              "</mark>\n",
              " \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    excel\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">SKILL</span>\n",
              "</mark>\n",
              " \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    jupyter\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">SKILL</span>\n",
              "</mark>\n",
              " notebook google colab vscode intellij<br></div></span>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}