{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chewzzz1014/fyp/blob/master/ner/src/train_ner_models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train NER Models"
      ],
      "metadata": {
        "id": "t0P9v82yDulr"
      },
      "id": "t0P9v82yDulr"
    },
    {
      "cell_type": "code",
      "source": [
        "# mount drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "5YToyjV-40ZV",
        "outputId": "07c78acd-d399-4fb8-d78b-84f089d75cca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "5YToyjV-40ZV",
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import random\n",
        "\n",
        "def load_json(file_path):\n",
        "    with open(file_path, 'r') as f:\n",
        "        return json.load(f)\n",
        "\n",
        "def save_json(data, file_path):\n",
        "    with open(file_path, 'w') as f:\n",
        "        json.dump(data, f)\n",
        "\n",
        "def split_data(data, train_ratio=0.8):\n",
        "    # Shuffle the data\n",
        "    random.shuffle(data)\n",
        "\n",
        "    # Calculate the split index\n",
        "    split_index = int(len(data) * train_ratio)\n",
        "\n",
        "    # Split the data\n",
        "    train_data = data[split_index:]\n",
        "    test_data = data[:split_index]\n",
        "\n",
        "    return train_data, test_data\n",
        "\n",
        "# Load the JSON data\n",
        "json_file_path = '/content/drive/MyDrive/FYP/Implementation/Resume Dataset/10_resumes_annotated.json'\n",
        "data = load_json(json_file_path)\n",
        "\n",
        "# Split the data\n",
        "train_data, test_data = split_data(data)\n",
        "\n",
        "# Save the splits\n",
        "save_json(train_data, 'train_data.json')\n",
        "save_json(test_data, 'test_data.json')"
      ],
      "metadata": {
        "id": "UdxvFdzNTPuE"
      },
      "id": "UdxvFdzNTPuE",
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Spacy NER"
      ],
      "metadata": {
        "id": "FMM7E6hNCEUv"
      },
      "id": "FMM7E6hNCEUv"
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "id": "572d77b5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "572d77b5",
        "outputId": "239a726b-cd6c-4387-9f8a-bc6feffd8a8c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘spacy_ner_data’: File exists\n",
            "\u001b[38;5;3m⚠ Can't automatically detect NER format. Conversion may not succeed.\n",
            "See https://spacy.io/api/cli#convert\u001b[0m\n",
            "\u001b[38;5;3m⚠ No sentence boundaries found to use with option `-n 1`. Use `-s` to\n",
            "automatically segment sentences or `-n 0` to disable.\u001b[0m\n",
            "\u001b[38;5;3m⚠ No sentence boundaries found. Use `-s` to automatically segment\n",
            "sentences.\u001b[0m\n",
            "\u001b[38;5;3m⚠ No document delimiters found. Use `-n` to automatically group\n",
            "sentences into documents.\u001b[0m\n",
            "\u001b[38;5;2m✔ Generated output file (1 documents):\n",
            "spacy_ner_data/train_data.spacy\u001b[0m\n",
            "\u001b[38;5;3m⚠ Can't automatically detect NER format. Conversion may not succeed.\n",
            "See https://spacy.io/api/cli#convert\u001b[0m\n",
            "\u001b[38;5;3m⚠ No sentence boundaries found to use with option `-n 1`. Use `-s` to\n",
            "automatically segment sentences or `-n 0` to disable.\u001b[0m\n",
            "\u001b[38;5;3m⚠ No sentence boundaries found. Use `-s` to automatically segment\n",
            "sentences.\u001b[0m\n",
            "\u001b[38;5;3m⚠ No document delimiters found. Use `-n` to automatically group\n",
            "sentences into documents.\u001b[0m\n",
            "\u001b[38;5;2m✔ Generated output file (1 documents):\n",
            "spacy_ner_data/test_data.spacy\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# create dir to place spacy ner data\n",
        "!mkdir spacy_ner_data\n",
        "\n",
        "# convert CONLL2003 annotation data into spacy data\n",
        "!python -m spacy convert 'train_data.json' spacy_ner_data -c ner\n",
        "!python -m spacy convert \"test_data.json\" spacy_ner_data -c ner"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create base_config.cfg and paste the config generated from spacy widget\n",
        "# update train and test file path\n",
        "!touch base_config.cfg"
      ],
      "metadata": {
        "id": "ruPln43fCDLm"
      },
      "id": "ruPln43fCDLm",
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# generate config.cfg from base_config.cfg\n",
        "!python -m spacy init fill-config base_config.cfg config.cfg"
      ],
      "metadata": {
        "id": "0aRjL9jqC-5k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d32ac19-0889-4751-98f7-124b8eed2ddb"
      },
      "id": "0aRjL9jqC-5k",
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[38;5;2m✔ Auto-filled config with all values\u001b[0m\n",
            "\u001b[38;5;2m✔ Saved config\u001b[0m\n",
            "config.cfg\n",
            "You can now add your data and train your pipeline:\n",
            "python -m spacy train config.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train model using hyperparameters set in config.cfg\n",
        "# trained model in output/ dir\n",
        "!python -m spacy train config.cfg --output ./output"
      ],
      "metadata": {
        "id": "Jav_l46BEDjF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "606fb51f-139c-4d90-8246-9d9c33ff2f8b"
      },
      "id": "Jav_l46BEDjF",
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[38;5;2m✔ Created output directory: output\u001b[0m\n",
            "\u001b[38;5;4mℹ Saving to output directory: output\u001b[0m\n",
            "\u001b[38;5;4mℹ Using CPU\u001b[0m\n",
            "\u001b[1m\n",
            "=========================== Initializing pipeline ===========================\u001b[0m\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/spacy/language.py\", line 1327, in initialize\n",
            "    init_vocab(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/spacy/training/initialize.py\", line 142, in init_vocab\n",
            "    load_vectors_into_model(nlp, vectors)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/spacy/training/initialize.py\", line 164, in load_vectors_into_model\n",
            "    vectors_nlp = load_model(name, vocab=nlp.vocab, exclude=exclude)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/spacy/util.py\", line 472, in load_model\n",
            "    raise IOError(Errors.E050.format(name=name))\n",
            "OSError: [E050] Can't find model 'en_core_web_lg'. It doesn't seem to be a Python package or a valid path to a data directory.\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/spacy/__main__.py\", line 4, in <module>\n",
            "    setup_cli()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/spacy/cli/_util.py\", line 87, in setup_cli\n",
            "    command(prog_name=COMMAND)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/click/core.py\", line 1157, in __call__\n",
            "    return self.main(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/typer/core.py\", line 728, in main\n",
            "    return _main(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/typer/core.py\", line 197, in _main\n",
            "    rv = self.invoke(ctx)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/click/core.py\", line 1688, in invoke\n",
            "    return _process_result(sub_ctx.command.invoke(sub_ctx))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/click/core.py\", line 1434, in invoke\n",
            "    return ctx.invoke(self.callback, **ctx.params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/click/core.py\", line 783, in invoke\n",
            "    return __callback(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/typer/main.py\", line 703, in wrapper\n",
            "    return callback(**use_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/spacy/cli/train.py\", line 54, in train_cli\n",
            "    train(config_path, output_path, use_gpu=use_gpu, overrides=overrides)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/spacy/cli/train.py\", line 81, in train\n",
            "    nlp = init_nlp(config, use_gpu=use_gpu)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/spacy/training/initialize.py\", line 95, in init_nlp\n",
            "    nlp.initialize(lambda: train_corpus(nlp), sgd=optimizer)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/spacy/language.py\", line 1331, in initialize\n",
            "    raise IOError(Errors.E884.format(vectors=I[\"vectors\"]))\n",
            "OSError: [E884] The pipeline could not be initialized because the vectors could not be found at 'en_core_web_lg'. If your pipeline was already initialized/trained before, call 'resume_training' instead of 'initialize', or initialize only the components that are new.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate trained model performance\n",
        "# store output and visualization into result/ dir\n",
        "!python -m spacy evaluate output/model-best spacy_ner_data/test.spacy -dp result"
      ],
      "metadata": {
        "id": "V2wzIOsWJgkG"
      },
      "id": "V2wzIOsWJgkG",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# download trained model"
      ],
      "metadata": {
        "id": "9sJdwj4GEKTM"
      },
      "id": "9sJdwj4GEKTM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Flair NER"
      ],
      "metadata": {
        "id": "1z_niSalE0uT"
      },
      "id": "1z_niSalE0uT"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install flair"
      ],
      "metadata": {
        "id": "lsEUGnPpnjuU"
      },
      "id": "lsEUGnPpnjuU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load data\n",
        "import flair\n",
        "from flair.datasets import ColumnCorpus\n",
        "\n",
        "# Define columns\n",
        "columns = {0: 'text', 1: 'ner'}\n",
        "\n",
        "# Specify the path to your training and test data\n",
        "data_folder = 'path/to/your/data'  # Update this path\n",
        "train_file = 'train.txt'  # Your training file\n",
        "test_file = 'test.txt'    # Your testing file\n",
        "\n",
        "# Create the corpus\n",
        "corpus = ColumnCorpus(data_folder,\n",
        "                      { 'train': train_file,\n",
        "                        'test': test_file },\n",
        "                      columns=columns)"
      ],
      "metadata": {
        "id": "WDsFt8DnE2OL"
      },
      "id": "WDsFt8DnE2OL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create NER tagger\n",
        "from flair.models import SequenceTagger\n",
        "\n",
        "tagger = SequenceTagger(hidden_size=256,\n",
        "                         embeddings='glove',\n",
        "                         tag_dictionary=corpus.make_tag_dictionary(tag_type='ner'),\n",
        "                         tag_type='ner',\n",
        "                         use_crf=True)\n"
      ],
      "metadata": {
        "id": "QEBUKmiAnaFm"
      },
      "id": "QEBUKmiAnaFm",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train model\n",
        "from flair.trainers import ModelTrainer\n",
        "\n",
        "trainer = ModelTrainer(tagger, corpus)\n",
        "\n",
        "trainer.train('path/to/save/model',  # Update this path\n",
        "               learning_rate=0.1,\n",
        "               mini_batch_size=32,\n",
        "               max_epochs=10)"
      ],
      "metadata": {
        "id": "XbuJ4VjCnoPU"
      },
      "id": "XbuJ4VjCnoPU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate model\n",
        "result, score = trainer.evaluate(corpus.test)\n",
        "print(result)\n",
        "print(score)"
      ],
      "metadata": {
        "id": "6KT8wj3Lns2c"
      },
      "id": "6KT8wj3Lns2c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# make prediction\n",
        "model = SequenceTagger.load('path/to/save/model')\n",
        "sentence = flair.data.Sentence(\"Your text here.\")\n",
        "\n",
        "model.predict(sentence)\n",
        "\n",
        "print(sentence.to_tagged_string())"
      ],
      "metadata": {
        "id": "KOYkWF9Anwec"
      },
      "id": "KOYkWF9Anwec",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}