{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chewzzz1014/fyp/blob/master/ner/src/train_ner_models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train NER Models"
      ],
      "metadata": {
        "id": "t0P9v82yDulr"
      },
      "id": "t0P9v82yDulr"
    },
    {
      "cell_type": "code",
      "source": [
        "# mount drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "5YToyjV-40ZV",
        "outputId": "91b8c8f7-4872-441d-ccc5-66db326b3406",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "5YToyjV-40ZV",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir spacy_ner_data"
      ],
      "metadata": {
        "id": "VtZ7OFQtpG4-"
      },
      "id": "VtZ7OFQtpG4-",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "import spacy\n",
        "from spacy.tokens import DocBin\n",
        "\n",
        "# Load JSON data\n",
        "with open('/content/drive/MyDrive/FYP/Implementation/Resume Dataset/100_resumes_annotated.json', \"r\") as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "def remove_overlapping_entities(entities):\n",
        "    \"\"\"Remove overlapping entities from the list.\"\"\"\n",
        "    entities = sorted(entities, key=lambda x: x[0])  # Sort by start position\n",
        "    non_overlapping = []\n",
        "    last_end = -1\n",
        "    for start, end, label in entities:\n",
        "        if start >= last_end:  # Only add if there's no overlap with the previous entity\n",
        "            non_overlapping.append((start, end, label))\n",
        "            last_end = end\n",
        "    return non_overlapping\n",
        "\n",
        "# Function to convert JSON data to Spacy's DocBin format\n",
        "def convert_to_spacy_format(data):\n",
        "    nlp = spacy.blank(\"en\")  # Load a blank Spacy model\n",
        "    doc_bin = DocBin()  # Container for our docs\n",
        "\n",
        "    for item in data:\n",
        "        text = item['data']['Text']  # Full document text\n",
        "        entities = []\n",
        "\n",
        "        for annotation in item['annotations'][0]['result']:\n",
        "            start = annotation['value']['start']\n",
        "            end = annotation['value']['end']\n",
        "            label = annotation['value']['labels'][0]  # Entity label\n",
        "            entities.append((start, end, label))\n",
        "\n",
        "        entities = remove_overlapping_entities(entities)  # Remove overlapping entities\n",
        "        # Create a Spacy doc and add entities to it\n",
        "        doc = nlp.make_doc(text)\n",
        "        spans = [doc.char_span(start, end, label=label) for start, end, label in entities]\n",
        "        # Filter out None spans if Spacy can't align the character indices with tokens\n",
        "        spans = [span for span in spans if span is not None]\n",
        "        doc.ents = spans  # Assign entities to the doc\n",
        "        doc_bin.add(doc)\n",
        "\n",
        "    return doc_bin\n",
        "\n",
        "# Split data into train and test sets\n",
        "train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)\n",
        "\n",
        "# Convert train and test sets to Spacy format\n",
        "train_doc_bin = convert_to_spacy_format(train_data)\n",
        "test_doc_bin = convert_to_spacy_format(test_data)\n",
        "\n",
        "# Save the train and test data to .spacy files\n",
        "train_doc_bin.to_disk(\"spacy_ner_data/train_data.spacy\")\n",
        "test_doc_bin.to_disk(\"spacy_ner_data/test_data.spacy\")"
      ],
      "metadata": {
        "id": "R-8QBDX3gtkp"
      },
      "id": "R-8QBDX3gtkp",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Spacy NER"
      ],
      "metadata": {
        "id": "FMM7E6hNCEUv"
      },
      "id": "FMM7E6hNCEUv"
    },
    {
      "cell_type": "code",
      "source": [
        "# create base_config.cfg and paste the config generated from spacy widget\n",
        "# update train and test file path\n",
        "!touch base_config.cfg"
      ],
      "metadata": {
        "id": "ruPln43fCDLm"
      },
      "id": "ruPln43fCDLm",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# generate config.cfg from base_config.cfg\n",
        "!python -m spacy init fill-config base_config.cfg config.cfg"
      ],
      "metadata": {
        "id": "0aRjL9jqC-5k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cac54dfe-e4c0-409c-ec3c-9f807b20bcf1"
      },
      "id": "0aRjL9jqC-5k",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[38;5;2m✔ Auto-filled config with all values\u001b[0m\n",
            "\u001b[38;5;2m✔ Saved config\u001b[0m\n",
            "config.cfg\n",
            "You can now add your data and train your pipeline:\n",
            "python -m spacy train config.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download en_core_web_lg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9wb_aBw9X2NU",
        "outputId": "72b5a8a9-b834-4bc5-e6b0-f53f6d091410"
      },
      "id": "9wb_aBw9X2NU",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting en-core-web-lg==3.7.1\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-3.7.1/en_core_web_lg-3.7.1-py3-none-any.whl (587.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m587.7/587.7 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /usr/local/lib/python3.10/dist-packages (from en-core-web-lg==3.7.1) (3.7.5)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.12.5)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (4.66.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.9.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (75.1.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (24.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.4.1)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.26.4)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.23.4)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2024.8.30)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (13.9.3)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.20.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (7.0.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.18.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.16.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.1.2)\n",
            "Installing collected packages: en-core-web-lg\n",
            "Successfully installed en-core-web-lg-3.7.1\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_lg')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train model using hyperparameters set in config.cfg\n",
        "# save trained model in spacy-output/ dir\n",
        "!python -m spacy train config.cfg --output ./spacy-output"
      ],
      "metadata": {
        "id": "Jav_l46BEDjF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27197557-4a61-408f-89a3-34e9fed7601d"
      },
      "id": "Jav_l46BEDjF",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[38;5;4mℹ Saving to output directory: spacy-output\u001b[0m\n",
            "\u001b[38;5;4mℹ Using CPU\u001b[0m\n",
            "\u001b[1m\n",
            "=========================== Initializing pipeline ===========================\u001b[0m\n",
            "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
            "\u001b[1m\n",
            "============================= Training pipeline =============================\u001b[0m\n",
            "\u001b[38;5;4mℹ Pipeline: ['tok2vec', 'ner']\u001b[0m\n",
            "\u001b[38;5;4mℹ Initial learn rate: 0.001\u001b[0m\n",
            "E    #       LOSS TOK2VEC  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
            "---  ------  ------------  --------  ------  ------  ------  ------\n",
            "  0       0          0.00    311.54    0.00    0.00    0.00    0.00\n",
            "  2     200        727.25  13365.40   30.91   46.99   23.03    0.31\n",
            "  5     400       1523.59   9725.39   39.50   41.25   37.88    0.39\n",
            "  7     600        209.56   6266.99   40.28   36.05   45.65    0.40\n",
            " 10     800        342.38   4632.03   41.02   37.42   45.38    0.41\n",
            " 12    1000       1274.97   3608.79   38.70   42.97   35.21    0.39\n",
            " 15    1200        224.03   2632.41   41.37   42.51   40.29    0.41\n",
            " 17    1400        246.44   2273.57   40.72   42.02   39.49    0.41\n",
            " 20    1600        240.64   2111.41   39.61   44.63   35.61    0.40\n",
            " 22    1800        255.28   1618.13   38.90   41.07   36.95    0.39\n",
            " 25    2000        267.60   1486.09   35.72   40.86   31.73    0.36\n",
            " 27    2200        251.77   1274.52   40.95   39.33   42.70    0.41\n",
            " 30    2400        288.03   1285.91   39.45   40.83   38.15    0.39\n",
            " 32    2600        267.45   1084.94   40.18   38.59   41.90    0.40\n",
            " 35    2800        992.31   1207.52   39.04   44.24   34.94    0.39\n",
            "\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n",
            "spacy-output/model-last\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate trained model performance\n",
        "# store output and visualization into result/ dir\n",
        "!python -m spacy evaluate spacy-output/model-best spacy_ner_data/test_data.spacy -dp spacy-output"
      ],
      "metadata": {
        "id": "V2wzIOsWJgkG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22f952af-3788-4283-f9f9-9a88724d92d3"
      },
      "id": "V2wzIOsWJgkG",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[38;5;4mℹ Using CPU\u001b[0m\n",
            "\u001b[1m\n",
            "================================== Results ==================================\u001b[0m\n",
            "\n",
            "TOK     100.00\n",
            "NER P   42.51 \n",
            "NER R   40.29 \n",
            "NER F   41.37 \n",
            "SPEED   2090  \n",
            "\n",
            "\u001b[1m\n",
            "=============================== NER (per type) ===============================\u001b[0m\n",
            "\n",
            "                 P        R       F\n",
            "NAME        100.00    66.67   80.00\n",
            "PHONE        92.86    72.22   81.25\n",
            "EMAIL        69.23   100.00   81.82\n",
            "SKILL        31.60    30.10   30.83\n",
            "JOB          44.62    52.73   48.33\n",
            "WORK PER     72.13    77.19   74.58\n",
            "COMPANY      44.74    41.46   43.04\n",
            "DEG          82.35    73.68   77.78\n",
            "STUDY PER   100.00    37.50   54.55\n",
            "UNI          43.75    41.18   42.42\n",
            "LOC         100.00    33.33   50.00\n",
            "\n",
            "<IPython.core.display.HTML object>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/spacy/__main__.py\", line 4, in <module>\n",
            "    setup_cli()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/spacy/cli/_util.py\", line 87, in setup_cli\n",
            "    command(prog_name=COMMAND)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/click/core.py\", line 1157, in __call__\n",
            "    return self.main(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/typer/core.py\", line 728, in main\n",
            "    return _main(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/typer/core.py\", line 197, in _main\n",
            "    rv = self.invoke(ctx)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/click/core.py\", line 1688, in invoke\n",
            "    return _process_result(sub_ctx.command.invoke(sub_ctx))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/click/core.py\", line 1434, in invoke\n",
            "    return ctx.invoke(self.callback, **ctx.params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/click/core.py\", line 783, in invoke\n",
            "    return __callback(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/typer/main.py\", line 703, in wrapper\n",
            "    return callback(**use_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/spacy/cli/evaluate.py\", line 47, in evaluate_cli\n",
            "    evaluate(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/spacy/cli/evaluate.py\", line 141, in evaluate\n",
            "    render_parses(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/spacy/cli/evaluate.py\", line 208, in render_parses\n",
            "    file_.write(html)\n",
            "TypeError: write() argument must be str, not None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# make prediction\n",
        "import spacy\n",
        "resume_text = '''\n",
        "John Doe lives at 1234 Elm Street in Los Angeles, CA 90001. He can be reached at +1 (555) 123-4567 or via email at john.doe@example.com. John is a results-driven software engineer with over 5 years of experience in web development and cloud infrastructure, with strong knowledge of JavaScript, Python, and cloud technologies like AWS and Azure. Currently, he works as a Software Engineer at Google LLC in San Francisco, CA, where he has been employed since August 2019. In this role, he has developed scalable web applications using JavaScript, Node.js, and React, deployed and maintained cloud infrastructure on AWS, reducing downtime by 20%, and led a team of 4 engineers to enhance backend performance by 30%. Previously, he worked as a Junior Developer at Tech Innovators Inc. in Austin, TX, from July 2017 to July 2019, where he created RESTful APIs using Python and Flask, collaborated with front-end developers to build and deploy user-facing applications, and wrote unit and integration tests, improving code coverage by 15%.\n",
        "\n",
        "John holds a Master of Science in Computer Science from the University of California, Berkeley, with a graduation date of May 2017, and a Bachelor of Science in Information Technology from the University of Texas at Austin, graduated in May 2015. His skillset includes proficiency in programming languages like Python, JavaScript, and Java; frameworks such as React, Flask, and Django; cloud platforms including AWS, Google Cloud, and Azure; as well as other tools like Git, Docker, Kubernetes, and SQL. He is certified as an AWS Certified Solutions Architect – Associate, earned in 2020, and as a Google Professional Cloud Architect, earned in 2021'\n",
        "'''\n",
        "nlp = spacy.load(\"spacy-output/model-best\")\n",
        "doc = nlp(resume_text.lower())\n",
        "\n",
        "print(doc.ents)\n",
        "\n",
        "for ent in doc.ents:\n",
        "    print(f\"{ent.text}: {ent.label_}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UXAlZZkEeeMc",
        "outputId": "0f9fc270-c8fe-4d24-ffa5-6dd5e31e7c7f"
      },
      "id": "UXAlZZkEeeMc",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(john doe lives at, john.doe@example.com, software engineer, august 2019, at tech, july 2017 to july 2019, aws, – associate, a, cloud architect)\n",
            "john doe lives at: COMPANY\n",
            "john.doe@example.com: EMAIL\n",
            "software engineer: JOB\n",
            "august 2019: WORK PER\n",
            "at tech: COMPANY\n",
            "july 2017 to july 2019: WORK PER\n",
            "aws: SKILL\n",
            "– associate: JOB\n",
            "a: SKILL\n",
            "cloud architect: JOB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from spacy import displacy\n",
        "displacy.render(doc, style=\"ent\", jupyter=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 562
        },
        "id": "LtxtV7GufiOw",
        "outputId": "ee175866-68e7-47d6-beea-1daf124059a9"
      },
      "id": "LtxtV7GufiOw",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\"><br>\n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    john doe lives at\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">COMPANY</span>\n",
              "</mark>\n",
              " 1234 elm street in los angeles, ca 90001. he can be reached at +1 (555) 123-4567 or via email at \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    john.doe@example.com\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">EMAIL</span>\n",
              "</mark>\n",
              ". john is a results-driven software engineer with over 5 years of experience in web development and cloud infrastructure, with strong knowledge of javascript, python, and cloud technologies like aws and azure. currently, he works as a \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    software engineer\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">JOB</span>\n",
              "</mark>\n",
              " at google llc in san francisco, ca, where he has been employed since \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    august 2019\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">WORK PER</span>\n",
              "</mark>\n",
              ". in this role, he has developed scalable web applications using javascript, node.js, and react, deployed and maintained cloud infrastructure on aws, reducing downtime by 20%, and led a team of 4 engineers to enhance backend performance by 30%. previously, he worked as a junior developer \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    at tech\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">COMPANY</span>\n",
              "</mark>\n",
              " innovators inc. in austin, tx, from \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    july 2017 to july 2019\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">WORK PER</span>\n",
              "</mark>\n",
              ", where he created restful apis using python and flask, collaborated with front-end developers to build and deploy user-facing applications, and wrote unit and integration tests, improving code coverage by 15%.<br><br>john holds a master of science in computer science from the university of california, berkeley, with a graduation date of may 2017, and a bachelor of science in information technology from the university of texas at austin, graduated in may 2015. his skillset includes proficiency in programming languages like python, javascript, and java; frameworks such as react, flask, and django; cloud platforms including \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    aws\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">SKILL</span>\n",
              "</mark>\n",
              ", google cloud, and azure; as well as other tools like git, docker, kubernetes, and sql. he is certified as an aws certified solutions architect \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    – associate\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">JOB</span>\n",
              "</mark>\n",
              ", earned in 2020, and as \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    a\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">SKILL</span>\n",
              "</mark>\n",
              " google professional \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    cloud architect\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">JOB</span>\n",
              "</mark>\n",
              ", earned in 2021'<br></div></span>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# download trained model"
      ],
      "metadata": {
        "id": "9sJdwj4GEKTM"
      },
      "id": "9sJdwj4GEKTM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Flair NER"
      ],
      "metadata": {
        "id": "1z_niSalE0uT"
      },
      "id": "1z_niSalE0uT"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install flair"
      ],
      "metadata": {
        "id": "lsEUGnPpnjuU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9fa941fa-3ae6-4511-80d4-3c0c98e8f2b2"
      },
      "id": "lsEUGnPpnjuU",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting flair\n",
            "  Downloading flair-0.14.0-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting boto3>=1.20.27 (from flair)\n",
            "  Downloading boto3-1.35.54-py3-none-any.whl.metadata (6.7 kB)\n",
            "Collecting conllu<5.0.0,>=4.0 (from flair)\n",
            "  Downloading conllu-4.5.3-py2.py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: deprecated>=1.2.13 in /usr/local/lib/python3.10/dist-packages (from flair) (1.2.14)\n",
            "Collecting ftfy>=6.1.0 (from flair)\n",
            "  Downloading ftfy-6.3.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: gdown>=4.4.0 in /usr/local/lib/python3.10/dist-packages (from flair) (5.2.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from flair) (0.24.7)\n",
            "Collecting langdetect>=1.0.9 (from flair)\n",
            "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: lxml>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from flair) (5.3.0)\n",
            "Requirement already satisfied: matplotlib>=2.2.3 in /usr/local/lib/python3.10/dist-packages (from flair) (3.8.0)\n",
            "Requirement already satisfied: more-itertools>=8.13.0 in /usr/local/lib/python3.10/dist-packages (from flair) (10.5.0)\n",
            "Collecting mpld3>=0.3 (from flair)\n",
            "  Downloading mpld3-0.5.10-py3-none-any.whl.metadata (5.1 kB)\n",
            "Collecting pptree>=3.1 (from flair)\n",
            "  Downloading pptree-3.1.tar.gz (3.0 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from flair) (2.8.2)\n",
            "Collecting pytorch-revgrad>=0.2.0 (from flair)\n",
            "  Downloading pytorch_revgrad-0.2.0-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from flair) (2024.9.11)\n",
            "Requirement already satisfied: scikit-learn>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from flair) (1.5.2)\n",
            "Collecting segtok>=1.5.11 (from flair)\n",
            "  Downloading segtok-1.5.11-py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting sqlitedict>=2.0.0 (from flair)\n",
            "  Downloading sqlitedict-2.1.0.tar.gz (21 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tabulate>=0.8.10 in /usr/local/lib/python3.10/dist-packages (from flair) (0.9.0)\n",
            "Requirement already satisfied: torch!=1.8,>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from flair) (2.5.0+cu121)\n",
            "Requirement already satisfied: tqdm>=4.63.0 in /usr/local/lib/python3.10/dist-packages (from flair) (4.66.6)\n",
            "Collecting transformer-smaller-training-vocab>=0.2.3 (from flair)\n",
            "  Downloading transformer_smaller_training_vocab-0.4.0-py3-none-any.whl.metadata (8.1 kB)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.18.0 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]<5.0.0,>=4.18.0->flair) (4.44.2)\n",
            "Collecting wikipedia-api>=0.5.7 (from flair)\n",
            "  Downloading wikipedia_api-0.7.1.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting semver<4.0.0,>=3.0.0 (from flair)\n",
            "  Downloading semver-3.0.2-py3-none-any.whl.metadata (5.0 kB)\n",
            "Collecting bioc<3.0.0,>=2.0.0 (from flair)\n",
            "  Downloading bioc-2.1-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting jsonlines>=1.2.0 (from bioc<3.0.0,>=2.0.0->flair)\n",
            "  Downloading jsonlines-4.0.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting intervaltree (from bioc<3.0.0,>=2.0.0->flair)\n",
            "  Downloading intervaltree-3.1.0.tar.gz (32 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting docopt (from bioc<3.0.0,>=2.0.0->flair)\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting botocore<1.36.0,>=1.35.54 (from boto3>=1.20.27->flair)\n",
            "  Downloading botocore-1.35.54-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting jmespath<2.0.0,>=0.7.1 (from boto3>=1.20.27->flair)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting s3transfer<0.11.0,>=0.10.0 (from boto3>=1.20.27->flair)\n",
            "  Downloading s3transfer-0.10.3-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from deprecated>=1.2.13->flair) (1.16.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from ftfy>=6.1.0->flair) (0.2.13)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown>=4.4.0->flair) (4.12.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown>=4.4.0->flair) (3.16.1)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown>=4.4.0->flair) (2.32.3)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.10.0->flair) (2024.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.10.0->flair) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.10.0->flair) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.10.0->flair) (4.12.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from langdetect>=1.0.9->flair) (1.16.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.2.3->flair) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.2.3->flair) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.2.3->flair) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.2.3->flair) (1.4.7)\n",
            "Requirement already satisfied: numpy<2,>=1.21 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.2.3->flair) (1.26.4)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.2.3->flair) (10.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.2.3->flair) (3.2.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from mpld3>=0.3->flair) (3.1.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.2->flair) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.2->flair) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.2->flair) (3.5.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch!=1.8,>=1.5.0->flair) (3.4.2)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch!=1.8,>=1.5.0->flair) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch!=1.8,>=1.5.0->flair) (1.3.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.18.0->transformers[sentencepiece]<5.0.0,>=4.18.0->flair) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.18.0->transformers[sentencepiece]<5.0.0,>=4.18.0->flair) (0.19.1)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]<5.0.0,>=4.18.0->flair) (3.20.3)\n",
            "Requirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]<5.0.0,>=4.18.0->flair) (0.2.0)\n",
            "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /usr/local/lib/python3.10/dist-packages (from botocore<1.36.0,>=1.35.54->boto3>=1.20.27->flair) (2.2.3)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonlines>=1.2.0->bioc<3.0.0,>=2.0.0->flair) (24.2.0)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece,torch]<5.0,>=4.1->transformer-smaller-training-vocab>=0.2.3->flair) (0.34.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown>=4.4.0->flair) (2.6)\n",
            "Collecting sortedcontainers<3.0,>=2.0 (from intervaltree->bioc<3.0.0,>=2.0.0->flair)\n",
            "  Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->mpld3>=0.3->flair) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown>=4.4.0->flair) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown>=4.4.0->flair) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown>=4.4.0->flair) (2024.8.30)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown>=4.4.0->flair) (1.7.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.21.0->transformers[sentencepiece,torch]<5.0,>=4.1->transformer-smaller-training-vocab>=0.2.3->flair) (5.9.5)\n",
            "Downloading flair-0.14.0-py3-none-any.whl (776 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m776.5/776.5 kB\u001b[0m \u001b[31m36.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bioc-2.1-py3-none-any.whl (33 kB)\n",
            "Downloading boto3-1.35.54-py3-none-any.whl (139 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.2/139.2 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading conllu-4.5.3-py2.py3-none-any.whl (16 kB)\n",
            "Downloading ftfy-6.3.1-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mpld3-0.5.10-py3-none-any.whl (202 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m202.6/202.6 kB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytorch_revgrad-0.2.0-py3-none-any.whl (4.6 kB)\n",
            "Downloading segtok-1.5.11-py3-none-any.whl (24 kB)\n",
            "Downloading semver-3.0.2-py3-none-any.whl (17 kB)\n",
            "Downloading transformer_smaller_training_vocab-0.4.0-py3-none-any.whl (14 kB)\n",
            "Downloading botocore-1.35.54-py3-none-any.whl (12.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.7/12.7 MB\u001b[0m \u001b[31m94.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Downloading jsonlines-4.0.0-py3-none-any.whl (8.7 kB)\n",
            "Downloading s3transfer-0.10.3-py3-none-any.whl (82 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.6/82.6 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
            "Building wheels for collected packages: langdetect, pptree, sqlitedict, wikipedia-api, docopt, intervaltree\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993222 sha256=fd8f5f883327cccaa0908bf2335d4ce6fc93c8cc780b0f0f07cdaf8b8b36483d\n",
            "  Stored in directory: /root/.cache/pip/wheels/95/03/7d/59ea870c70ce4e5a370638b5462a7711ab78fba2f655d05106\n",
            "  Building wheel for pptree (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pptree: filename=pptree-3.1-py3-none-any.whl size=4608 sha256=210b4ea6e314fac23ad119b2aaf2359809ddd5ad32c039ed80c05f9ec8d95e7c\n",
            "  Stored in directory: /root/.cache/pip/wheels/9f/b6/0e/6f26eb9e6eb53ff2107a7888d72b5a6a597593956113037828\n",
            "  Building wheel for sqlitedict (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sqlitedict: filename=sqlitedict-2.1.0-py3-none-any.whl size=16864 sha256=6dbb3c8c96b85d72080009fd6e39a97666244a44d57bbcb15424a05c404e3258\n",
            "  Stored in directory: /root/.cache/pip/wheels/79/d6/e7/304e0e6cb2221022c26d8161f7c23cd4f259a9e41e8bbcfabd\n",
            "  Building wheel for wikipedia-api (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wikipedia-api: filename=Wikipedia_API-0.7.1-py3-none-any.whl size=14346 sha256=921c2ac0637af4af02807c5d0f59e305b11d3b6ca716e165731ccbcf6a5861cf\n",
            "  Stored in directory: /root/.cache/pip/wheels/4c/96/18/b9201cc3e8b47b02b510460210cfd832ccf10c0c4dd0522962\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13706 sha256=86c2ba41750e38a037b88100b08728c109c169dfc519be90be2d6e385780dca9\n",
            "  Stored in directory: /root/.cache/pip/wheels/fc/ab/d4/5da2067ac95b36618c629a5f93f809425700506f72c9732fac\n",
            "  Building wheel for intervaltree (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for intervaltree: filename=intervaltree-3.1.0-py2.py3-none-any.whl size=26097 sha256=eaaa98e41365f6f9ee6f18f7865597f5d6436a5eecd177c442385e34a403aa92\n",
            "  Stored in directory: /root/.cache/pip/wheels/fa/80/8c/43488a924a046b733b64de3fac99252674c892a4c3801c0a61\n",
            "Successfully built langdetect pptree sqlitedict wikipedia-api docopt intervaltree\n",
            "Installing collected packages: sqlitedict, sortedcontainers, pptree, docopt, semver, segtok, langdetect, jsonlines, jmespath, intervaltree, ftfy, conllu, wikipedia-api, botocore, bioc, s3transfer, pytorch-revgrad, mpld3, boto3, transformer-smaller-training-vocab, flair\n",
            "Successfully installed bioc-2.1 boto3-1.35.54 botocore-1.35.54 conllu-4.5.3 docopt-0.6.2 flair-0.14.0 ftfy-6.3.1 intervaltree-3.1.0 jmespath-1.0.1 jsonlines-4.0.0 langdetect-1.0.9 mpld3-0.5.10 pptree-3.1 pytorch-revgrad-0.2.0 s3transfer-0.10.3 segtok-1.5.11 semver-3.0.2 sortedcontainers-2.4.0 sqlitedict-2.1.0 transformer-smaller-training-vocab-0.4.0 wikipedia-api-0.7.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from spacy.tokens import DocBin\n",
        "import os\n",
        "\n",
        "def convert_spacy_to_flair(input_file, output_file):\n",
        "    \"\"\"\n",
        "    Convert SpaCy binary format to Flair's CoNLL format.\n",
        "\n",
        "    Args:\n",
        "        input_file (str): Path to SpaCy binary file (.spacy)\n",
        "        output_file (str): Path to output file for Flair format\n",
        "    \"\"\"\n",
        "    # Load spaCy model\n",
        "    nlp = spacy.blank(\"en\")\n",
        "\n",
        "    # Load the DocBin\n",
        "    doc_bin = DocBin().from_disk(input_file)\n",
        "    docs = list(doc_bin.get_docs(nlp.vocab))\n",
        "\n",
        "    with open(output_file, 'w', encoding='utf-8') as f:\n",
        "        for doc in docs:\n",
        "            tokens = [(t.text, t.ent_iob_, t.ent_type_) for t in doc]\n",
        "\n",
        "            # Write tokens in CoNLL format\n",
        "            for token in tokens:\n",
        "                text, iob, ent_type = token\n",
        "\n",
        "                # Convert spaCy IOB to CoNLL format\n",
        "                if iob == 'O':\n",
        "                    tag = 'O'\n",
        "                else:\n",
        "                    tag = f'{iob}-{ent_type}' if ent_type else 'O'\n",
        "\n",
        "                # Write line: token and NER tag\n",
        "                f.write(f'{text} {tag}\\n')\n",
        "\n",
        "            # Empty line between sentences\n",
        "            f.write('\\n')\n",
        "\n",
        "def convert_spacy_json_to_flair(input_file, output_file):\n",
        "    \"\"\"\n",
        "    Convert SpaCy JSON format to Flair's CoNLL format.\n",
        "\n",
        "    Args:\n",
        "        input_file (str): Path to JSON file with SpaCy annotations\n",
        "        output_file (str): Path to output file for Flair format\n",
        "    \"\"\"\n",
        "    import json\n",
        "\n",
        "    nlp = spacy.blank(\"en\")\n",
        "\n",
        "    with open(input_file, 'r', encoding='utf-8') as f:\n",
        "        training_data = json.load(f)\n",
        "\n",
        "    with open(output_file, 'w', encoding='utf-8') as f:\n",
        "        for example in training_data:\n",
        "            text = example['text']\n",
        "            ents = example.get('entities', [])\n",
        "\n",
        "            # Create a spaCy doc\n",
        "            doc = nlp(text)\n",
        "\n",
        "            # Add entities to doc\n",
        "            spans = []\n",
        "            for start, end, label in ents:\n",
        "                span = doc.char_span(start, end, label=label)\n",
        "                if span is not None:\n",
        "                    spans.append(span)\n",
        "            doc.ents = spans\n",
        "\n",
        "            # Convert to CoNLL format\n",
        "            tokens = [(t.text, t.ent_iob_, t.ent_type_) for t in doc]\n",
        "\n",
        "            for token in tokens:\n",
        "                text, iob, ent_type = token\n",
        "                if iob == 'O':\n",
        "                    tag = 'O'\n",
        "                else:\n",
        "                    tag = f'{iob}-{ent_type}' if ent_type else 'O'\n",
        "                f.write(f'{text} {tag}\\n')\n",
        "\n",
        "            f.write('\\n')\n",
        "\n",
        "# Example usage for JSON format\n",
        "flair_train_json = \"flair_train.txt\"\n",
        "flair_test_json = \"flair_test.txt\"\n",
        "\n",
        "convert_spacy_to_flair('/content/spacy_ner_data/train_data.spacy', flair_train_json)\n",
        "convert_spacy_to_flair('/content/spacy_ner_data/test_data.spacy', flair_test_json)"
      ],
      "metadata": {
        "id": "8SgkTXeIiTtF"
      },
      "id": "8SgkTXeIiTtF",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from spacy.training import Corpus\n",
        "\n",
        "!python -m spacy download de_core_news_sm\n",
        "nlp = spacy.load(\"de_core_news_sm\")\n",
        "corpus = Corpus(\"/content/spacy_ner_data/test_data.spacy\")\n",
        "\n",
        "data = corpus(nlp)\n",
        "\n",
        "# Flair supports BIO and BIOES, see https://github.com/flairNLP/flair/issues/875\n",
        "def rename_biluo_to_bioes(old_tag):\n",
        "    new_tag = \"\"\n",
        "    try:\n",
        "        if old_tag.startswith(\"L\"):\n",
        "            new_tag = \"E\" + old_tag[1:]\n",
        "        elif old_tag.startswith(\"U\"):\n",
        "            new_tag = \"S\" + old_tag[1:]\n",
        "        else:\n",
        "            new_tag = old_tag\n",
        "    except:\n",
        "        pass\n",
        "    return new_tag\n",
        "\n",
        "\n",
        "def generate_corpus():\n",
        "    corpus = []\n",
        "    n_ex = 0\n",
        "    for example in data:\n",
        "        n_ex += 1\n",
        "        text = example.text\n",
        "        doc = nlp(text)\n",
        "        tags = example.get_aligned_ner()\n",
        "        # Check if it's an empty list of NER tags.\n",
        "        if None in tags:\n",
        "            pass\n",
        "        else:\n",
        "            new_tags = [rename_biluo_to_bioes(tag) for tag in tags]\n",
        "            for token, tag in zip(doc,new_tags):\n",
        "                row = token.text +' '+ token.pos_ +' ' +tag + '\\n'\n",
        "                corpus.append(row)\n",
        "            corpus.append('\\n')\n",
        "    return corpus\n",
        "\n",
        "def write_file(filepath):\n",
        "    with open(filepath, 'w', encoding='utf-8') as f:\n",
        "        corpus = generate_corpus()\n",
        "        f.writelines(corpus)\n",
        "\n",
        "def main():\n",
        "    write_file('flair_test.txt')\n",
        "\n",
        "main()"
      ],
      "metadata": {
        "id": "TbHBmnUyv65f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be6d42bd-f6a2-4143-b278-f010c011ae8f"
      },
      "id": "TbHBmnUyv65f",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting de-core-news-sm==3.7.0\n",
            "  Using cached https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-3.7.0/de_core_news_sm-3.7.0-py3-none-any.whl (14.6 MB)\n",
            "Requirement already satisfied: spacy<3.8.0,>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from de-core-news-sm==3.7.0) (3.7.5)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.12.5)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (4.66.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.9.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (75.1.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (24.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.4.1)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.26.4)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.23.4)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2024.8.30)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (13.9.3)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.20.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (7.0.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.18.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.16.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.1.2)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('de_core_news_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from flair.data import Corpus\n",
        "from flair.datasets import ColumnCorpus\n",
        "\n",
        "# Define columns for CoNLL (0: word, 1: label)\n",
        "columns = {0: 'text', 1: 'ner'}\n",
        "\n",
        "# Set data folder and file names\n",
        "data_folder = './'\n",
        "train_file = 'flair_train.txt'\n",
        "test_file = 'flair_test.txt'\n",
        "\n",
        "# Load the corpus\n",
        "corpus: Corpus = ColumnCorpus(data_folder, columns,\n",
        "                              train_file=train_file,\n",
        "                              test_file=test_file)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vl2-GpGBjpsi",
        "outputId": "dee2d55b-3f19-4c09-fd0d-19d10773bf38"
      },
      "id": "vl2-GpGBjpsi",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-11-03 01:04:41,893 Reading data from .\n",
            "2024-11-03 01:04:41,895 Train: flair_train.txt\n",
            "2024-11-03 01:04:41,897 Dev: None\n",
            "2024-11-03 01:04:41,899 Test: flair_test.txt\n",
            "2024-11-03 01:04:42,458 No dev split found. Using 10% (i.e. 8 samples) of the train split as dev data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tag_dictionary= corpus.make_label_dictionary(label_type = 'ner')\n",
        "tag_dictionary"
      ],
      "metadata": {
        "id": "d_skLRc8i44m",
        "outputId": "7d891af3-718a-4f38-d76c-bc0069f490b2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "d_skLRc8i44m",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-11-03 01:04:45,218 Computing label dictionary. Progress:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "0it [00:00, ?it/s]\n",
            "72it [00:00, 8012.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-11-03 01:04:45,248 Dictionary created for label 'ner' with 11 values: SKILL (seen 1242 times), JOB (seen 230 times), WORK (seen 225 times), COMPANY (seen 186 times), UNI (seen 76 times), NAME (seen 70 times), DEG (seen 67 times), STUDY (seen 66 times), PHONE (seen 63 times), EMAIL (seen 46 times), LOC (seen 43 times)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<flair.data.Dictionary at 0x7a88c3319480>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create NER tagger\n",
        "from flair.embeddings import WordEmbeddings, StackedEmbeddings\n",
        "from flair.models import SequenceTagger\n",
        "\n",
        "embeddings = StackedEmbeddings([\n",
        "                WordEmbeddings('glove'),\n",
        "                WordEmbeddings('en-crawl')\n",
        "            ])\n",
        "\n",
        "tagger = SequenceTagger(hidden_size=256,\n",
        "                         embeddings=embeddings,\n",
        "                         tag_dictionary=tag_dictionary,\n",
        "                         tag_type='ner',\n",
        "                         use_crf=True)"
      ],
      "metadata": {
        "id": "QEBUKmiAnaFm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b27cfe5-d4d5-4bdc-e6b3-e088326d42d1"
      },
      "id": "QEBUKmiAnaFm",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-11-03 01:05:29,639 SequenceTagger predicts: Dictionary with 45 tags: O, S-SKILL, B-SKILL, E-SKILL, I-SKILL, S-JOB, B-JOB, E-JOB, I-JOB, S-WORK, B-WORK, E-WORK, I-WORK, S-COMPANY, B-COMPANY, E-COMPANY, I-COMPANY, S-UNI, B-UNI, E-UNI, I-UNI, S-NAME, B-NAME, E-NAME, I-NAME, S-DEG, B-DEG, E-DEG, I-DEG, S-STUDY, B-STUDY, E-STUDY, I-STUDY, S-PHONE, B-PHONE, E-PHONE, I-PHONE, S-EMAIL, B-EMAIL, E-EMAIL, I-EMAIL, S-LOC, B-LOC, E-LOC, I-LOC\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train flair ner model\n",
        "from flair.trainers import ModelTrainer\n",
        "from flair.training_utils import EvaluationMetric\n",
        "\n",
        "trainer = ModelTrainer(tagger, corpus)\n",
        "\n",
        "trainer.train(\n",
        "    base_path='flair_output/',\n",
        "    learning_rate=0.01,\n",
        "    mini_batch_size=8,\n",
        "    max_epochs=10,\n",
        "    patience=3,\n",
        "    embeddings_storage_mode='gpu',\n",
        "    use_amp=True,  # Use mixed precision training\n",
        "    train_with_dev=False\n",
        ")"
      ],
      "metadata": {
        "id": "XbuJ4VjCnoPU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "205069ec-1019-41d2-fdb1-58db7bb86a44"
      },
      "id": "XbuJ4VjCnoPU",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-11-03 01:06:06,734 ----------------------------------------------------------------------------------------------------\n",
            "2024-11-03 01:06:06,737 Model: \"SequenceTagger(\n",
            "  (embeddings): StackedEmbeddings(\n",
            "    (list_embedding_0): WordEmbeddings(\n",
            "      'glove'\n",
            "      (embedding): Embedding(400001, 100)\n",
            "    )\n",
            "    (list_embedding_1): WordEmbeddings(\n",
            "      'en-crawl'\n",
            "      (embedding): Embedding(1000001, 300)\n",
            "    )\n",
            "  )\n",
            "  (word_dropout): WordDropout(p=0.05)\n",
            "  (locked_dropout): LockedDropout(p=0.5)\n",
            "  (embedding2nn): Linear(in_features=400, out_features=400, bias=True)\n",
            "  (rnn): LSTM(400, 256, batch_first=True, bidirectional=True)\n",
            "  (linear): Linear(in_features=512, out_features=47, bias=True)\n",
            "  (loss_function): ViterbiLoss()\n",
            "  (crf): CRF()\n",
            ")\"\n",
            "2024-11-03 01:06:06,739 ----------------------------------------------------------------------------------------------------\n",
            "2024-11-03 01:06:06,741 Corpus: 72 train + 8 dev + 20 test sentences\n",
            "2024-11-03 01:06:06,743 ----------------------------------------------------------------------------------------------------\n",
            "2024-11-03 01:06:06,745 Train:  72 sentences\n",
            "2024-11-03 01:06:06,750         (train_with_dev=False, train_with_test=False)\n",
            "2024-11-03 01:06:06,751 ----------------------------------------------------------------------------------------------------\n",
            "2024-11-03 01:06:06,753 Training Params:\n",
            "2024-11-03 01:06:06,754  - learning_rate: \"0.01\" \n",
            "2024-11-03 01:06:06,755  - mini_batch_size: \"8\"\n",
            "2024-11-03 01:06:06,757  - max_epochs: \"10\"\n",
            "2024-11-03 01:06:06,759  - shuffle: \"True\"\n",
            "2024-11-03 01:06:06,760 ----------------------------------------------------------------------------------------------------\n",
            "2024-11-03 01:06:06,763 Plugins:\n",
            "2024-11-03 01:06:06,765  - AnnealOnPlateau | patience: '3', anneal_factor: '0.5', min_learning_rate: '0.0001'\n",
            "2024-11-03 01:06:06,767 ----------------------------------------------------------------------------------------------------\n",
            "2024-11-03 01:06:06,768 Final evaluation on model from best epoch (best-model.pt)\n",
            "2024-11-03 01:06:06,770  - metric: \"('micro avg', 'f1-score')\"\n",
            "2024-11-03 01:06:06,772 ----------------------------------------------------------------------------------------------------\n",
            "2024-11-03 01:06:06,774 Computation:\n",
            "2024-11-03 01:06:06,775  - compute on device: cpu\n",
            "2024-11-03 01:06:06,777  - embedding storage: gpu\n",
            "2024-11-03 01:06:06,779 ----------------------------------------------------------------------------------------------------\n",
            "2024-11-03 01:06:06,781 Model training base path: \"flair_output\"\n",
            "2024-11-03 01:06:06,782 ----------------------------------------------------------------------------------------------------\n",
            "2024-11-03 01:06:06,784 ----------------------------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate model\n",
        "from flair.data import Corpus\n",
        "from flair.datasets import ColumnCorpus\n",
        "from flair.models import SequenceTagger\n",
        "from flair.trainers import ModelTrainer\n",
        "\n",
        "# Load the trained model\n",
        "model = SequenceTagger.load('flair_output/best-model.pt')\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "result = model.evaluate(corpus.test, gold_label_type='ner', mini_batch_size=32)\n",
        "\n",
        "# Print the results\n",
        "# print(\"Evaluation Loss:\", eval_loss)\n",
        "print(result.detailed_results)  # This will print the precision, recall, and F1-score per entity type"
      ],
      "metadata": {
        "id": "6KT8wj3Lns2c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bdaac8a0-3d01-4ccf-c412-bb3eeabb5289"
      },
      "id": "6KT8wj3Lns2c",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-10-31 10:05:42,406 SequenceTagger predicts: Dictionary with 4 tags: O, PER, <START>, <STOP>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:03<00:00,  3.62s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Results:\n",
            "- F-score (micro) 0.6732\n",
            "- F-score (macro) 0.6732\n",
            "- Accuracy 0.5074\n",
            "\n",
            "By class:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         PER     0.8519    0.5565    0.6732       124\n",
            "\n",
            "   micro avg     0.8519    0.5565    0.6732       124\n",
            "   macro avg     0.8519    0.5565    0.6732       124\n",
            "weighted avg     0.8519    0.5565    0.6732       124\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# make prediction\n",
        "import flair\n",
        "model = SequenceTagger.load('flair_output/final-model.pt')\n",
        "resume_text = '''\n",
        "John Doe lives at 1234 Elm Street in Los Angeles, CA 90001. He can be reached at +1 (555) 123-4567 or via email at john.doe@example.com. John is a results-driven software engineer with over 5 years of experience in web development and cloud infrastructure, with strong knowledge of JavaScript, Python, and cloud technologies like AWS and Azure. Currently, he works as a Software Engineer at Google LLC in San Francisco, CA, where he has been employed since August 2019. In this role, he has developed scalable web applications using JavaScript, Node.js, and React, deployed and maintained cloud infrastructure on AWS, reducing downtime by 20%, and led a team of 4 engineers to enhance backend performance by 30%. Previously, he worked as a Junior Developer at Tech Innovators Inc. in Austin, TX, from July 2017 to July 2019, where he created RESTful APIs using Python and Flask, collaborated with front-end developers to build and deploy user-facing applications, and wrote unit and integration tests, improving code coverage by 15%.\n",
        "\n",
        "John holds a Master of Science in Computer Science from the University of California, Berkeley, with a graduation date of May 2017, and a Bachelor of Science in Information Technology from the University of Texas at Austin, graduated in May 2015. His skillset includes proficiency in programming languages like Python, JavaScript, and Java; frameworks such as React, Flask, and Django; cloud platforms including AWS, Google Cloud, and Azure; as well as other tools like Git, Docker, Kubernetes, and SQL. He is certified as an AWS Certified Solutions Architect – Associate, earned in 2020, and as a Google Professional Cloud Architect, earned in 2021'\n",
        "'''\n",
        "sentence = flair.data.Sentence(resume_text.lower())\n",
        "\n",
        "model.predict(sentence)\n",
        "\n",
        "print(sentence.to_tagged_string())"
      ],
      "metadata": {
        "id": "KOYkWF9Anwec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b2f7980-5a1c-4e0e-973d-162581dc982d"
      },
      "id": "KOYkWF9Anwec",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-10-31 10:06:35,880 SequenceTagger predicts: Dictionary with 4 tags: O, PER, <START>, <STOP>\n",
            "Sentence[326]: \" john doe lives at 1234 elm street in los angeles, ca 90001. he can be reached at +1 (555) 123-4567 or via email at john.doe@example.com. john is a results-driven software engineer with over 5 years of experience in web development and cloud infrastructure, with strong knowledge of javascript, python, and cloud technologies like aws and azure. currently, he works as a software engineer at google llc in san francisco, ca, where he has been employed since august 2019. in this role, he has developed scalable web applications using javascript, node.js, and react, deployed and maintained cloud infrastructure on aws, reducing downtime by 20%, and led a team of 4 engineers to enhance backend performance by 30%. previously, he worked as a junior developer at tech innovators inc. in austin, tx, from july 2017 to july 2019, where he created restful apis using python and flask, collaborated with front-end developers to build and deploy user-facing applications, and wrote unit and integration tests, improving code coverage by 15%.  john holds a master of science in computer science from the university of california, berkeley, with a graduation date of may 2017, and a bachelor of science in information technology from the university of texas at austin, graduated in may 2015. his skillset includes proficiency in programming languages like python, javascript, and java; frameworks such as react, flask, and django; cloud platforms including aws, google cloud, and azure; as well as other tools like git, docker, kubernetes, and sql. he is certified as an aws certified solutions architect – associate, earned in 2020, and as a google professional cloud architect, earned in 2021'\" → [\"august\"/PER, \"2019\"/PER, \"july\"/PER, \"2017\"/PER, \"to\"/PER, \"july\"/PER, \"2019\"/PER]\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}