{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chewzzz1014/fyp/blob/master/ner/src/train_ner_models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train NER Models"
      ],
      "metadata": {
        "id": "t0P9v82yDulr"
      },
      "id": "t0P9v82yDulr"
    },
    {
      "cell_type": "code",
      "source": [
        "# mount drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "5YToyjV-40ZV",
        "outputId": "962806b0-cb63-422f-b1cc-22dca1892e6e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "5YToyjV-40ZV",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir spacy_ner_data"
      ],
      "metadata": {
        "id": "VtZ7OFQtpG4-"
      },
      "id": "VtZ7OFQtpG4-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "import spacy\n",
        "from spacy.tokens import DocBin\n",
        "\n",
        "# Load JSON data\n",
        "with open('/content/drive/MyDrive/FYP/Implementation/Resume Dataset/10_resumes_annotated.json', \"r\") as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "# Function to convert JSON data to Spacy's DocBin format\n",
        "def convert_to_spacy_format(data):\n",
        "    nlp = spacy.blank(\"en\")  # Load a blank Spacy model\n",
        "    doc_bin = DocBin()  # Container for our docs\n",
        "\n",
        "    for item in data:\n",
        "        text = item['data']['Text']  # Full document text\n",
        "        entities = []\n",
        "\n",
        "        for annotation in item['annotations'][0]['result']:\n",
        "            start = annotation['value']['start']\n",
        "            end = annotation['value']['end']\n",
        "            label = annotation['value']['labels'][0]  # Entity label\n",
        "            entities.append((start, end, label))\n",
        "\n",
        "        # Create a Spacy doc and add entities to it\n",
        "        doc = nlp.make_doc(text)\n",
        "        spans = [doc.char_span(start, end, label=label) for start, end, label in entities]\n",
        "        # Filter out None spans if Spacy can't align the character indices with tokens\n",
        "        spans = [span for span in spans if span is not None]\n",
        "        doc.ents = spans  # Assign entities to the doc\n",
        "        doc_bin.add(doc)\n",
        "\n",
        "    return doc_bin\n",
        "\n",
        "# Split data into train and test sets\n",
        "train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)\n",
        "\n",
        "# Convert train and test sets to Spacy format\n",
        "train_doc_bin = convert_to_spacy_format(train_data)\n",
        "test_doc_bin = convert_to_spacy_format(test_data)\n",
        "\n",
        "# Save the train and test data to .spacy files\n",
        "train_doc_bin.to_disk(\"spacy_ner_data/train_data.spacy\")\n",
        "test_doc_bin.to_disk(\"spacy_ner_data/test_data.spacy\")"
      ],
      "metadata": {
        "id": "R-8QBDX3gtkp"
      },
      "id": "R-8QBDX3gtkp",
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Spacy NER"
      ],
      "metadata": {
        "id": "FMM7E6hNCEUv"
      },
      "id": "FMM7E6hNCEUv"
    },
    {
      "cell_type": "code",
      "source": [
        "# create base_config.cfg and paste the config generated from spacy widget\n",
        "# update train and test file path\n",
        "!touch base_config.cfg"
      ],
      "metadata": {
        "id": "ruPln43fCDLm"
      },
      "id": "ruPln43fCDLm",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# generate config.cfg from base_config.cfg\n",
        "!python -m spacy init fill-config base_config.cfg config.cfg"
      ],
      "metadata": {
        "id": "0aRjL9jqC-5k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "706de3f0-61ab-4c7e-9593-e567e4ef569e"
      },
      "id": "0aRjL9jqC-5k",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[38;5;2m✔ Auto-filled config with all values\u001b[0m\n",
            "\u001b[38;5;2m✔ Saved config\u001b[0m\n",
            "config.cfg\n",
            "You can now add your data and train your pipeline:\n",
            "python -m spacy train config.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download en_core_web_lg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9wb_aBw9X2NU",
        "outputId": "b6e2805d-e623-4b65-818c-acbb07562caa"
      },
      "id": "9wb_aBw9X2NU",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting en-core-web-lg==3.7.1\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-3.7.1/en_core_web_lg-3.7.1-py3-none-any.whl (587.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m587.7/587.7 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /usr/local/lib/python3.10/dist-packages (from en-core-web-lg==3.7.1) (3.7.5)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.12.5)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (4.66.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.9.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (75.1.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (24.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.4.1)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.26.4)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.23.4)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2024.8.30)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (13.9.3)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.20.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (7.0.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.18.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.16.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.1.2)\n",
            "Installing collected packages: en-core-web-lg\n",
            "Successfully installed en-core-web-lg-3.7.1\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_lg')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train model using hyperparameters set in config.cfg\n",
        "# trained model in output/ dir\n",
        "!python -m spacy train config.cfg --output ./output"
      ],
      "metadata": {
        "id": "Jav_l46BEDjF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80b48b39-11ed-46a7-bc6f-20a705eff7d8"
      },
      "id": "Jav_l46BEDjF",
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[38;5;4mℹ Saving to output directory: output\u001b[0m\n",
            "\u001b[38;5;4mℹ Using CPU\u001b[0m\n",
            "\u001b[1m\n",
            "=========================== Initializing pipeline ===========================\u001b[0m\n",
            "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
            "\u001b[1m\n",
            "============================= Training pipeline =============================\u001b[0m\n",
            "\u001b[38;5;4mℹ Pipeline: ['tok2vec', 'ner']\u001b[0m\n",
            "\u001b[38;5;4mℹ Initial learn rate: 0.001\u001b[0m\n",
            "E    #       LOSS TOK2VEC  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
            "---  ------  ------------  --------  ------  ------  ------  ------\n",
            "  0       0          0.00    296.83    1.01    2.56    0.63    0.01\n",
            "  9     200       1380.49  12424.58   25.91   36.36   20.13    0.26\n",
            " 18     400        165.97   3289.83   41.80   60.00   32.08    0.42\n",
            " 27     600        117.71   1442.75   44.70   56.19   37.11    0.45\n",
            " 36     800        114.14    847.01   41.98   53.40   34.59    0.42\n",
            " 45    1000        148.28    812.46   41.91   50.44   35.85    0.42\n",
            " 54    1200        314.69    796.46   43.41   56.57   35.22    0.43\n",
            " 63    1400        155.75    567.12   45.26   53.91   38.99    0.45\n",
            " 72    1600        217.48    620.53   41.05   67.14   29.56    0.41\n",
            " 81    1800        284.74    480.40   34.93   57.14   25.16    0.35\n",
            " 90    2000        211.32    440.53   43.92   58.33   35.22    0.44\n",
            "100    2200        242.31    447.29   44.68   51.22   39.62    0.45\n",
            "109    2400        125.57    288.51   40.16   57.65   30.82    0.40\n",
            "118    2600        292.95    333.45   34.89   53.95   25.79    0.35\n",
            "127    2800        803.05    421.54   40.00   59.26   30.19    0.40\n",
            "136    3000        473.40    412.28   41.60   57.14   32.70    0.42\n",
            "\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n",
            "output/model-last\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate trained model performance\n",
        "# store output and visualization into result/ dir\n",
        "!python -m spacy evaluate output/model-best spacy_ner_data/test_data.spacy -dp output"
      ],
      "metadata": {
        "id": "V2wzIOsWJgkG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e0d142e-7533-4fb9-e78b-ae7698a84451"
      },
      "id": "V2wzIOsWJgkG",
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[38;5;4mℹ Using CPU\u001b[0m\n",
            "\u001b[1m\n",
            "================================== Results ==================================\u001b[0m\n",
            "\n",
            "TOK     100.00\n",
            "NER P   53.91 \n",
            "NER R   38.99 \n",
            "NER F   45.26 \n",
            "SPEED   3648  \n",
            "\n",
            "\u001b[1m\n",
            "=============================== NER (per type) ===============================\u001b[0m\n",
            "\n",
            "                 P        R        F\n",
            "NAME         66.67    66.67    66.67\n",
            "STUDY PER    66.67    66.67    66.67\n",
            "WORK PER     72.22    81.25    76.47\n",
            "COMPANY      41.67    45.45    43.48\n",
            "SKILL        49.06    27.96    35.62\n",
            "JOB          40.00    25.00    30.77\n",
            "DEG           0.00     0.00     0.00\n",
            "UNI           0.00     0.00     0.00\n",
            "LOC         100.00   100.00   100.00\n",
            "PHONE       100.00   100.00   100.00\n",
            "EMAIL        50.00   100.00    66.67\n",
            "\n",
            "<IPython.core.display.HTML object>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/spacy/__main__.py\", line 4, in <module>\n",
            "    setup_cli()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/spacy/cli/_util.py\", line 87, in setup_cli\n",
            "    command(prog_name=COMMAND)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/click/core.py\", line 1157, in __call__\n",
            "    return self.main(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/typer/core.py\", line 728, in main\n",
            "    return _main(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/typer/core.py\", line 197, in _main\n",
            "    rv = self.invoke(ctx)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/click/core.py\", line 1688, in invoke\n",
            "    return _process_result(sub_ctx.command.invoke(sub_ctx))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/click/core.py\", line 1434, in invoke\n",
            "    return ctx.invoke(self.callback, **ctx.params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/click/core.py\", line 783, in invoke\n",
            "    return __callback(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/typer/main.py\", line 703, in wrapper\n",
            "    return callback(**use_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/spacy/cli/evaluate.py\", line 47, in evaluate_cli\n",
            "    evaluate(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/spacy/cli/evaluate.py\", line 141, in evaluate\n",
            "    render_parses(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/spacy/cli/evaluate.py\", line 208, in render_parses\n",
            "    file_.write(html)\n",
            "TypeError: write() argument must be str, not None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# make prediction\n",
        "import spacy\n",
        "resume_text = 'dot net developer robert smith phone 123 456 78 99 email infoqwikresumecom website wwwqwikresumecom linkedin linkedincomqwikresume address 1737 marshville road alabama objective dot net developer seven years experience design development webbased windows based applications using net technologies hands experience phases software development life cycle sdlc like requirement gathering analysis architectural detail design documentation development testing implementation using agile methodologies like scrum xp test driven environment skills programming languages net technologies c sql plsql web forms win forms web technologies scripting html dhtml css xmlangular jsbootstrap ajax toolkit jquery javascript telerikkendo ui database ms sql server operating systems windows 8 packages ms office amp visio ms frontpage iis version control tools git hub vss tfs methodologies agile oops scrum soa reporting crystal reports net ms sql server reporting services ssrs work experience dot net developer charter communications june 2015 present assisting developing architectural design functional specifications involving analysis designing coding implementation application developing dynamic web page implemented creatively implemented design requirements using client side scripting language technologies assisting agile software development management activities respond unpredictability iterative sprints designing developing web application migrating project mvc architecture using mvc 3 separate internal representations information involved developing telerik kendo ul controls building application enabling focus value generating development tasks involving development presentation logic gui aspnet pages dot net developer abc corp 2011 2015 coded updated maintained computer programs assisted developers prepare high level technical design documents performed code enhancements assist performance analysis provided technical guidance programming standards team trained users team coordinated client amp offshore tearn meet project objectives participated backlog grooming meeting work client remove barriers team worked individual developer also manage offshore team free resume template copyright qwikresumecom usage guidelines'\n",
        "nlp = spacy.load(\"output/model-best\")\n",
        "doc = nlp(resume_text)\n",
        "\n",
        "print(doc.ents)\n",
        "\n",
        "for ent in doc.ents:\n",
        "    print(f\"{ent.text}: {ent.label_}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UXAlZZkEeeMc",
        "outputId": "6338c002-ac23-4bda-93df-70242bdcd810"
      },
      "id": "UXAlZZkEeeMc",
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(robert smith, 123 456 78, infoqwikresumecom, wwwqwikresumecom, agile, sql, plsql, html, jquery, javascript, ui, windows, ms office amp, git, vss, agile, oops, soa, dot net developer, charter communications, june 2015 present, mvc, mvc, gui, abc corp, 2011)\n",
            "robert smith: NAME\n",
            "123 456 78: PHONE\n",
            "infoqwikresumecom: EMAIL\n",
            "wwwqwikresumecom: EMAIL\n",
            "agile: SKILL\n",
            "sql: SKILL\n",
            "plsql: SKILL\n",
            "html: SKILL\n",
            "jquery: SKILL\n",
            "javascript: SKILL\n",
            "ui: SKILL\n",
            "windows: SKILL\n",
            "ms office amp: SKILL\n",
            "git: SKILL\n",
            "vss: SKILL\n",
            "agile: SKILL\n",
            "oops: SKILL\n",
            "soa: SKILL\n",
            "dot net developer: JOB\n",
            "charter communications: COMPANY\n",
            "june 2015 present: WORK PER\n",
            "mvc: SKILL\n",
            "mvc: SKILL\n",
            "gui: SKILL\n",
            "abc corp: COMPANY\n",
            "2011: WORK PER\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from spacy import displacy\n",
        "displacy.render(doc, style=\"ent\", jupyter=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 612
        },
        "id": "LtxtV7GufiOw",
        "outputId": "d2aa48e1-31ed-4fea-906a-0f63a0578c55"
      },
      "id": "LtxtV7GufiOw",
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">dot net developer \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    robert smith\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NAME</span>\n",
              "</mark>\n",
              " phone \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    123 456 78\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PHONE</span>\n",
              "</mark>\n",
              " 99 email \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    infoqwikresumecom\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">EMAIL</span>\n",
              "</mark>\n",
              " website \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    wwwqwikresumecom\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">EMAIL</span>\n",
              "</mark>\n",
              " linkedin linkedincomqwikresume address 1737 marshville road alabama objective dot net developer seven years experience design development webbased windows based applications using net technologies hands experience phases software development life cycle sdlc like requirement gathering analysis architectural detail design documentation development testing implementation using \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    agile\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">SKILL</span>\n",
              "</mark>\n",
              " methodologies like scrum xp test driven environment skills programming languages net technologies c \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    sql\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">SKILL</span>\n",
              "</mark>\n",
              " \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    plsql\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">SKILL</span>\n",
              "</mark>\n",
              " web forms win forms web technologies scripting \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    html\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">SKILL</span>\n",
              "</mark>\n",
              " dhtml css xmlangular jsbootstrap ajax toolkit \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    jquery\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">SKILL</span>\n",
              "</mark>\n",
              " \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    javascript\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">SKILL</span>\n",
              "</mark>\n",
              " telerikkendo \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    ui\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">SKILL</span>\n",
              "</mark>\n",
              " database ms sql server operating systems \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    windows\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">SKILL</span>\n",
              "</mark>\n",
              " 8 packages \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    ms office amp\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">SKILL</span>\n",
              "</mark>\n",
              " visio ms frontpage iis version control tools \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    git\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">SKILL</span>\n",
              "</mark>\n",
              " hub \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    vss\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">SKILL</span>\n",
              "</mark>\n",
              " tfs methodologies \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    agile\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">SKILL</span>\n",
              "</mark>\n",
              " \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    oops\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">SKILL</span>\n",
              "</mark>\n",
              " scrum \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    soa\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">SKILL</span>\n",
              "</mark>\n",
              " reporting crystal reports net ms sql server reporting services ssrs work experience \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    dot net developer\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">JOB</span>\n",
              "</mark>\n",
              " \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    charter communications\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">COMPANY</span>\n",
              "</mark>\n",
              " \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    june 2015 present\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">WORK PER</span>\n",
              "</mark>\n",
              " assisting developing architectural design functional specifications involving analysis designing coding implementation application developing dynamic web page implemented creatively implemented design requirements using client side scripting language technologies assisting agile software development management activities respond unpredictability iterative sprints designing developing web application migrating project \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    mvc\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">SKILL</span>\n",
              "</mark>\n",
              " architecture using \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    mvc\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">SKILL</span>\n",
              "</mark>\n",
              " 3 separate internal representations information involved developing telerik kendo ul controls building application enabling focus value generating development tasks involving development presentation logic \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    gui\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">SKILL</span>\n",
              "</mark>\n",
              " aspnet pages dot net developer \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    abc corp\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">COMPANY</span>\n",
              "</mark>\n",
              " \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    2011\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">WORK PER</span>\n",
              "</mark>\n",
              " 2015 coded updated maintained computer programs assisted developers prepare high level technical design documents performed code enhancements assist performance analysis provided technical guidance programming standards team trained users team coordinated client amp offshore tearn meet project objectives participated backlog grooming meeting work client remove barriers team worked individual developer also manage offshore team free resume template copyright qwikresumecom usage guidelines</div></span>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# download trained model"
      ],
      "metadata": {
        "id": "9sJdwj4GEKTM"
      },
      "id": "9sJdwj4GEKTM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Flair NER"
      ],
      "metadata": {
        "id": "1z_niSalE0uT"
      },
      "id": "1z_niSalE0uT"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install flair"
      ],
      "metadata": {
        "id": "lsEUGnPpnjuU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b650785-ba7d-4aa5-fbd3-6b9666df3ef7"
      },
      "id": "lsEUGnPpnjuU",
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting flair\n",
            "  Downloading flair-0.14.0-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting boto3>=1.20.27 (from flair)\n",
            "  Downloading boto3-1.35.50-py3-none-any.whl.metadata (6.7 kB)\n",
            "Collecting conllu<5.0.0,>=4.0 (from flair)\n",
            "  Downloading conllu-4.5.3-py2.py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: deprecated>=1.2.13 in /usr/local/lib/python3.10/dist-packages (from flair) (1.2.14)\n",
            "Collecting ftfy>=6.1.0 (from flair)\n",
            "  Downloading ftfy-6.3.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: gdown>=4.4.0 in /usr/local/lib/python3.10/dist-packages (from flair) (5.2.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from flair) (0.24.7)\n",
            "Collecting langdetect>=1.0.9 (from flair)\n",
            "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m40.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: lxml>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from flair) (4.9.4)\n",
            "Requirement already satisfied: matplotlib>=2.2.3 in /usr/local/lib/python3.10/dist-packages (from flair) (3.7.1)\n",
            "Requirement already satisfied: more-itertools>=8.13.0 in /usr/local/lib/python3.10/dist-packages (from flair) (10.5.0)\n",
            "Collecting mpld3>=0.3 (from flair)\n",
            "  Downloading mpld3-0.5.10-py3-none-any.whl.metadata (5.1 kB)\n",
            "Collecting pptree>=3.1 (from flair)\n",
            "  Downloading pptree-3.1.tar.gz (3.0 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from flair) (2.8.2)\n",
            "Collecting pytorch-revgrad>=0.2.0 (from flair)\n",
            "  Downloading pytorch_revgrad-0.2.0-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from flair) (2024.9.11)\n",
            "Requirement already satisfied: scikit-learn>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from flair) (1.5.2)\n",
            "Collecting segtok>=1.5.11 (from flair)\n",
            "  Downloading segtok-1.5.11-py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting sqlitedict>=2.0.0 (from flair)\n",
            "  Downloading sqlitedict-2.1.0.tar.gz (21 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tabulate>=0.8.10 in /usr/local/lib/python3.10/dist-packages (from flair) (0.9.0)\n",
            "Requirement already satisfied: torch!=1.8,>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from flair) (2.5.0+cu121)\n",
            "Requirement already satisfied: tqdm>=4.63.0 in /usr/local/lib/python3.10/dist-packages (from flair) (4.66.5)\n",
            "Collecting transformer-smaller-training-vocab>=0.2.3 (from flair)\n",
            "  Downloading transformer_smaller_training_vocab-0.4.0-py3-none-any.whl.metadata (8.1 kB)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.18.0 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]<5.0.0,>=4.18.0->flair) (4.44.2)\n",
            "Collecting wikipedia-api>=0.5.7 (from flair)\n",
            "  Downloading wikipedia_api-0.7.1.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting semver<4.0.0,>=3.0.0 (from flair)\n",
            "  Downloading semver-3.0.2-py3-none-any.whl.metadata (5.0 kB)\n",
            "Collecting bioc<3.0.0,>=2.0.0 (from flair)\n",
            "  Downloading bioc-2.1-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting jsonlines>=1.2.0 (from bioc<3.0.0,>=2.0.0->flair)\n",
            "  Downloading jsonlines-4.0.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting intervaltree (from bioc<3.0.0,>=2.0.0->flair)\n",
            "  Downloading intervaltree-3.1.0.tar.gz (32 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting docopt (from bioc<3.0.0,>=2.0.0->flair)\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting botocore<1.36.0,>=1.35.50 (from boto3>=1.20.27->flair)\n",
            "  Downloading botocore-1.35.50-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting jmespath<2.0.0,>=0.7.1 (from boto3>=1.20.27->flair)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting s3transfer<0.11.0,>=0.10.0 (from boto3>=1.20.27->flair)\n",
            "  Downloading s3transfer-0.10.3-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from deprecated>=1.2.13->flair) (1.16.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from ftfy>=6.1.0->flair) (0.2.13)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown>=4.4.0->flair) (4.12.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown>=4.4.0->flair) (3.16.1)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown>=4.4.0->flair) (2.32.3)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.10.0->flair) (2024.6.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.10.0->flair) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.10.0->flair) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.10.0->flair) (4.12.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from langdetect>=1.0.9->flair) (1.16.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.2.3->flair) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.2.3->flair) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.2.3->flair) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.2.3->flair) (1.4.7)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.2.3->flair) (1.26.4)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.2.3->flair) (10.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.2.3->flair) (3.2.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from mpld3>=0.3->flair) (3.1.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.2->flair) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.2->flair) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.2->flair) (3.5.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch!=1.8,>=1.5.0->flair) (3.4.2)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch!=1.8,>=1.5.0->flair) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch!=1.8,>=1.5.0->flair) (1.3.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.18.0->transformers[sentencepiece]<5.0.0,>=4.18.0->flair) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.18.0->transformers[sentencepiece]<5.0.0,>=4.18.0->flair) (0.19.1)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]<5.0.0,>=4.18.0->flair) (3.20.3)\n",
            "Requirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]<5.0.0,>=4.18.0->flair) (0.2.0)\n",
            "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /usr/local/lib/python3.10/dist-packages (from botocore<1.36.0,>=1.35.50->boto3>=1.20.27->flair) (2.2.3)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonlines>=1.2.0->bioc<3.0.0,>=2.0.0->flair) (24.2.0)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece,torch]<5.0,>=4.1->transformer-smaller-training-vocab>=0.2.3->flair) (0.34.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown>=4.4.0->flair) (2.6)\n",
            "Collecting sortedcontainers<3.0,>=2.0 (from intervaltree->bioc<3.0.0,>=2.0.0->flair)\n",
            "  Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->mpld3>=0.3->flair) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown>=4.4.0->flair) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown>=4.4.0->flair) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown>=4.4.0->flair) (2024.8.30)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown>=4.4.0->flair) (1.7.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.21.0->transformers[sentencepiece,torch]<5.0,>=4.1->transformer-smaller-training-vocab>=0.2.3->flair) (5.9.5)\n",
            "Downloading flair-0.14.0-py3-none-any.whl (776 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m776.5/776.5 kB\u001b[0m \u001b[31m42.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bioc-2.1-py3-none-any.whl (33 kB)\n",
            "Downloading boto3-1.35.50-py3-none-any.whl (139 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.2/139.2 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading conllu-4.5.3-py2.py3-none-any.whl (16 kB)\n",
            "Downloading ftfy-6.3.1-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mpld3-0.5.10-py3-none-any.whl (202 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m202.6/202.6 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytorch_revgrad-0.2.0-py3-none-any.whl (4.6 kB)\n",
            "Downloading segtok-1.5.11-py3-none-any.whl (24 kB)\n",
            "Downloading semver-3.0.2-py3-none-any.whl (17 kB)\n",
            "Downloading transformer_smaller_training_vocab-0.4.0-py3-none-any.whl (14 kB)\n",
            "Downloading botocore-1.35.50-py3-none-any.whl (12.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.6/12.6 MB\u001b[0m \u001b[31m47.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Downloading jsonlines-4.0.0-py3-none-any.whl (8.7 kB)\n",
            "Downloading s3transfer-0.10.3-py3-none-any.whl (82 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.6/82.6 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
            "Building wheels for collected packages: langdetect, pptree, sqlitedict, wikipedia-api, docopt, intervaltree\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993222 sha256=14b153f6835ebb466f02d6c723fbb784cadc5540cf4f0ff74df3f2a7044be477\n",
            "  Stored in directory: /root/.cache/pip/wheels/95/03/7d/59ea870c70ce4e5a370638b5462a7711ab78fba2f655d05106\n",
            "  Building wheel for pptree (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pptree: filename=pptree-3.1-py3-none-any.whl size=4608 sha256=1bcd9024dbf0d8e228d04f02278ac2e8d369b637b21381c913c7ad09209c2b47\n",
            "  Stored in directory: /root/.cache/pip/wheels/9f/b6/0e/6f26eb9e6eb53ff2107a7888d72b5a6a597593956113037828\n",
            "  Building wheel for sqlitedict (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sqlitedict: filename=sqlitedict-2.1.0-py3-none-any.whl size=16864 sha256=b2845d9561d2e2023646509290ff76110e44228f863de0560e8b72458c15fde5\n",
            "  Stored in directory: /root/.cache/pip/wheels/79/d6/e7/304e0e6cb2221022c26d8161f7c23cd4f259a9e41e8bbcfabd\n",
            "  Building wheel for wikipedia-api (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wikipedia-api: filename=Wikipedia_API-0.7.1-py3-none-any.whl size=14346 sha256=12b930385f7abee4f224a20c28c6bdd3b37662a917c3723f519a5c0a0667c4f0\n",
            "  Stored in directory: /root/.cache/pip/wheels/4c/96/18/b9201cc3e8b47b02b510460210cfd832ccf10c0c4dd0522962\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13706 sha256=9d928c9107230414bcbabe656b781f78b992417fd8b0eec77e98e96b1daa072f\n",
            "  Stored in directory: /root/.cache/pip/wheels/fc/ab/d4/5da2067ac95b36618c629a5f93f809425700506f72c9732fac\n",
            "  Building wheel for intervaltree (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for intervaltree: filename=intervaltree-3.1.0-py2.py3-none-any.whl size=26097 sha256=f281c990441a51bfba8095322d434bdd7e551ada59a2160e6038f4dc3ee557e4\n",
            "  Stored in directory: /root/.cache/pip/wheels/fa/80/8c/43488a924a046b733b64de3fac99252674c892a4c3801c0a61\n",
            "Successfully built langdetect pptree sqlitedict wikipedia-api docopt intervaltree\n",
            "Installing collected packages: sqlitedict, sortedcontainers, pptree, docopt, semver, segtok, langdetect, jsonlines, jmespath, intervaltree, ftfy, conllu, wikipedia-api, botocore, bioc, s3transfer, pytorch-revgrad, mpld3, boto3, transformer-smaller-training-vocab, flair\n",
            "Successfully installed bioc-2.1 boto3-1.35.50 botocore-1.35.50 conllu-4.5.3 docopt-0.6.2 flair-0.14.0 ftfy-6.3.1 intervaltree-3.1.0 jmespath-1.0.1 jsonlines-4.0.0 langdetect-1.0.9 mpld3-0.5.10 pptree-3.1 pytorch-revgrad-0.2.0 s3transfer-0.10.3 segtok-1.5.11 semver-3.0.2 sortedcontainers-2.4.0 sqlitedict-2.1.0 transformer-smaller-training-vocab-0.4.0 wikipedia-api-0.7.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from spacy.tokens import DocBin\n",
        "import os\n",
        "\n",
        "def convert_spacy_to_flair(input_file, output_file):\n",
        "    \"\"\"\n",
        "    Convert SpaCy binary format to Flair's CoNLL format.\n",
        "\n",
        "    Args:\n",
        "        input_file (str): Path to SpaCy binary file (.spacy)\n",
        "        output_file (str): Path to output file for Flair format\n",
        "    \"\"\"\n",
        "    # Load spaCy model\n",
        "    nlp = spacy.blank(\"en\")\n",
        "\n",
        "    # Load the DocBin\n",
        "    doc_bin = DocBin().from_disk(input_file)\n",
        "    docs = list(doc_bin.get_docs(nlp.vocab))\n",
        "\n",
        "    with open(output_file, 'w', encoding='utf-8') as f:\n",
        "        for doc in docs:\n",
        "            tokens = [(t.text, t.ent_iob_, t.ent_type_) for t in doc]\n",
        "\n",
        "            # Write tokens in CoNLL format\n",
        "            for token in tokens:\n",
        "                text, iob, ent_type = token\n",
        "\n",
        "                # Convert spaCy IOB to CoNLL format\n",
        "                if iob == 'O':\n",
        "                    tag = 'O'\n",
        "                else:\n",
        "                    tag = f'{iob}-{ent_type}' if ent_type else 'O'\n",
        "\n",
        "                # Write line: token and NER tag\n",
        "                f.write(f'{text} {tag}\\n')\n",
        "\n",
        "            # Empty line between sentences\n",
        "            f.write('\\n')\n",
        "\n",
        "def convert_spacy_json_to_flair(input_file, output_file):\n",
        "    \"\"\"\n",
        "    Convert SpaCy JSON format to Flair's CoNLL format.\n",
        "\n",
        "    Args:\n",
        "        input_file (str): Path to JSON file with SpaCy annotations\n",
        "        output_file (str): Path to output file for Flair format\n",
        "    \"\"\"\n",
        "    import json\n",
        "\n",
        "    nlp = spacy.blank(\"en\")\n",
        "\n",
        "    with open(input_file, 'r', encoding='utf-8') as f:\n",
        "        training_data = json.load(f)\n",
        "\n",
        "    with open(output_file, 'w', encoding='utf-8') as f:\n",
        "        for example in training_data:\n",
        "            text = example['text']\n",
        "            ents = example.get('entities', [])\n",
        "\n",
        "            # Create a spaCy doc\n",
        "            doc = nlp(text)\n",
        "\n",
        "            # Add entities to doc\n",
        "            spans = []\n",
        "            for start, end, label in ents:\n",
        "                span = doc.char_span(start, end, label=label)\n",
        "                if span is not None:\n",
        "                    spans.append(span)\n",
        "            doc.ents = spans\n",
        "\n",
        "            # Convert to CoNLL format\n",
        "            tokens = [(t.text, t.ent_iob_, t.ent_type_) for t in doc]\n",
        "\n",
        "            for token in tokens:\n",
        "                text, iob, ent_type = token\n",
        "                if iob == 'O':\n",
        "                    tag = 'O'\n",
        "                else:\n",
        "                    tag = f'{iob}-{ent_type}' if ent_type else 'O'\n",
        "                f.write(f'{text} {tag}\\n')\n",
        "\n",
        "            f.write('\\n')\n",
        "\n",
        "# Example usage for JSON format\n",
        "flair_train_json = \"flair_train.txt\"\n",
        "flair_test_json = \"flair_test.txt\"\n",
        "\n",
        "convert_spacy_to_flair('/content/spacy_ner_data/train_data.spacy', flair_train_json)\n",
        "convert_spacy_to_flair('/content/spacy_ner_data/test_data.spacy', flair_test_json)"
      ],
      "metadata": {
        "id": "8SgkTXeIiTtF"
      },
      "id": "8SgkTXeIiTtF",
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from flair.data import Corpus\n",
        "from flair.datasets import ColumnCorpus\n",
        "\n",
        "# Define columns for CoNLL (0: word, 1: label)\n",
        "columns = {0: 'text', 1: 'ner'}\n",
        "\n",
        "# Set data folder and file names\n",
        "data_folder = './'\n",
        "train_file = 'flair_train.txt'\n",
        "test_file = 'flair_test.txt'\n",
        "\n",
        "# Load the corpus\n",
        "corpus: Corpus = ColumnCorpus(data_folder, columns,\n",
        "                              train_file=train_file,\n",
        "                              test_file=test_file)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vl2-GpGBjpsi",
        "outputId": "6c0eaba6-3029-4c21-8d74-aa93bc41e09b"
      },
      "id": "vl2-GpGBjpsi",
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-10-29 14:19:43,450 Reading data from .\n",
            "2024-10-29 14:19:43,451 Train: flair_train.txt\n",
            "2024-10-29 14:19:43,454 Dev: None\n",
            "2024-10-29 14:19:43,455 Test: flair_test.txt\n",
            "2024-10-29 14:19:43,629 No dev split found. Using 10% (i.e. 2 samples) of the train split as dev data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create NER tagger\n",
        "from flair.embeddings import WordEmbeddings, StackedEmbeddings\n",
        "from flair.models import SequenceTagger\n",
        "\n",
        "embeddings = StackedEmbeddings([\n",
        "                WordEmbeddings('glove'),\n",
        "                WordEmbeddings('en-crawl')\n",
        "            ])\n",
        "\n",
        "tagger = SequenceTagger(hidden_size=256,\n",
        "                         embeddings=embeddings,\n",
        "                         tag_dictionary=corpus.make_tag_dictionary(tag_type='ner'),\n",
        "                         tag_type='ner',\n",
        "                         use_crf=True)"
      ],
      "metadata": {
        "id": "QEBUKmiAnaFm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3af8c46-6a1f-4cba-a66e-610f809208d0"
      },
      "id": "QEBUKmiAnaFm",
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-10-29 14:20:05,377 https://flair.informatik.hu-berlin.de/resources/embeddings/token/glove.gensim.vectors.npy not found in cache, downloading to /tmp/tmpuoh0v_ah\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 153M/153M [00:06<00:00, 23.8MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-10-29 14:20:12,442 copying /tmp/tmpuoh0v_ah to cache at /root/.flair/embeddings/glove.gensim.vectors.npy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-10-29 14:20:12,956 removing temp file /tmp/tmpuoh0v_ah\n",
            "2024-10-29 14:20:13,343 https://flair.informatik.hu-berlin.de/resources/embeddings/token/glove.gensim not found in cache, downloading to /tmp/tmpefkn2os3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20.5M/20.5M [00:01<00:00, 12.2MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-10-29 14:20:15,423 copying /tmp/tmpefkn2os3 to cache at /root/.flair/embeddings/glove.gensim\n",
            "2024-10-29 14:20:15,471 removing temp file /tmp/tmpefkn2os3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-10-29 14:20:21,469 https://flair.informatik.hu-berlin.de/resources/embeddings/token/en-fasttext-crawl-300d-1M.vectors.npy not found in cache, downloading to /tmp/tmpmwi5difw\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1.12G/1.12G [01:16<00:00, 15.6MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-10-29 14:21:38,771 copying /tmp/tmpmwi5difw to cache at /root/.flair/embeddings/en-fasttext-crawl-300d-1M.vectors.npy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-10-29 14:21:43,243 removing temp file /tmp/tmpmwi5difw\n",
            "2024-10-29 14:21:43,941 https://flair.informatik.hu-berlin.de/resources/embeddings/token/en-fasttext-crawl-300d-1M not found in cache, downloading to /tmp/tmphb6pog37\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 37.5M/37.5M [00:02<00:00, 14.3MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-10-29 14:21:47,129 copying /tmp/tmphb6pog37 to cache at /root/.flair/embeddings/en-fasttext-crawl-300d-1M\n",
            "2024-10-29 14:21:47,180 removing temp file /tmp/tmphb6pog37\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-10-29 14:22:04,219 SequenceTagger predicts: Dictionary with 3 tags: O, <START>, <STOP>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-32-687232df04ba>:12: DeprecationWarning: Call to deprecated method make_tag_dictionary. (Use 'make_label_dictionary' instead.) -- Deprecated since version 0.8.\n",
            "  tag_dictionary=corpus.make_tag_dictionary(tag_type='ner'),\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train flair ner model\n",
        "from flair.trainers import ModelTrainer\n",
        "from flair.training_utils import EvaluationMetric\n",
        "\n",
        "trainer = ModelTrainer(tagger, corpus)\n",
        "\n",
        "trainer.train('flair_output/',\n",
        "               learning_rate=0.1,\n",
        "               mini_batch_size=32,\n",
        "               max_epochs=10)\n",
        "\n",
        "# trainer.train(\n",
        "#      base_path='/flair_output/',\n",
        "#      learning_rate=0.1,\n",
        "#      mini_batch_size=32,\n",
        "#      max_epochs=10,\n",
        "#      patience=3,\n",
        "#      embeddings_storage_mode='gpu',\n",
        "#     #  checkpoint=True,\n",
        "#      use_amp=True,  # Use mixed precision training\n",
        "#      train_with_dev=False,\n",
        "#     #  monitor_train=True,\n",
        "#     #  monitor_test=True,\n",
        "#      evaluation_metric=EvaluationMetric.MICRO_F1_SCORE,\n",
        "# )\n",
        "\n",
        "trainer.train(\n",
        "    base_path='/flair_output/',\n",
        "    learning_rate=0.1,\n",
        "    mini_batch_size=32,\n",
        "    max_epochs=10,\n",
        "    patience=3,\n",
        "    embeddings_storage_mode='gpu',\n",
        "    use_amp=True,  # Use mixed precision training\n",
        "    train_with_dev=False,\n",
        "    main_evaluation_metric=EvaluationMetric.MICRO_F1_SCORE  # Set the evaluation metric here\n",
        ")"
      ],
      "metadata": {
        "id": "XbuJ4VjCnoPU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "844024a2-01ff-4cd8-9d75-cebcc7e932ef"
      },
      "id": "XbuJ4VjCnoPU",
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-10-29 14:46:39,551 ----------------------------------------------------------------------------------------------------\n",
            "2024-10-29 14:46:39,554 Model: \"SequenceTagger(\n",
            "  (embeddings): StackedEmbeddings(\n",
            "    (list_embedding_0): WordEmbeddings(\n",
            "      'glove'\n",
            "      (embedding): Embedding(400001, 100)\n",
            "    )\n",
            "    (list_embedding_1): WordEmbeddings(\n",
            "      'en-crawl'\n",
            "      (embedding): Embedding(1000001, 300)\n",
            "    )\n",
            "  )\n",
            "  (word_dropout): WordDropout(p=0.05)\n",
            "  (locked_dropout): LockedDropout(p=0.5)\n",
            "  (embedding2nn): Linear(in_features=400, out_features=400, bias=True)\n",
            "  (rnn): LSTM(400, 256, batch_first=True, bidirectional=True)\n",
            "  (linear): Linear(in_features=512, out_features=3, bias=True)\n",
            "  (loss_function): ViterbiLoss()\n",
            "  (crf): CRF()\n",
            ")\"\n",
            "2024-10-29 14:46:39,557 ----------------------------------------------------------------------------------------------------\n",
            "2024-10-29 14:46:39,562 Corpus: 20 train + 2 dev + 6 test sentences\n",
            "2024-10-29 14:46:39,565 ----------------------------------------------------------------------------------------------------\n",
            "2024-10-29 14:46:39,566 Train:  20 sentences\n",
            "2024-10-29 14:46:39,568         (train_with_dev=False, train_with_test=False)\n",
            "2024-10-29 14:46:39,569 ----------------------------------------------------------------------------------------------------\n",
            "2024-10-29 14:46:39,571 Training Params:\n",
            "2024-10-29 14:46:39,573  - learning_rate: \"0.1\" \n",
            "2024-10-29 14:46:39,574  - mini_batch_size: \"32\"\n",
            "2024-10-29 14:46:39,575  - max_epochs: \"10\"\n",
            "2024-10-29 14:46:39,576  - shuffle: \"True\"\n",
            "2024-10-29 14:46:39,578 ----------------------------------------------------------------------------------------------------\n",
            "2024-10-29 14:46:39,579 Plugins:\n",
            "2024-10-29 14:46:39,580  - AnnealOnPlateau | patience: '3', anneal_factor: '0.5', min_learning_rate: '0.0001'\n",
            "2024-10-29 14:46:39,581 ----------------------------------------------------------------------------------------------------\n",
            "2024-10-29 14:46:39,583 Final evaluation on model from best epoch (best-model.pt)\n",
            "2024-10-29 14:46:39,584  - metric: \"('micro avg', 'f1-score')\"\n",
            "2024-10-29 14:46:39,585 ----------------------------------------------------------------------------------------------------\n",
            "2024-10-29 14:46:39,586 Computation:\n",
            "2024-10-29 14:46:39,588  - compute on device: cpu\n",
            "2024-10-29 14:46:39,589  - embedding storage: cpu\n",
            "2024-10-29 14:46:39,590 ----------------------------------------------------------------------------------------------------\n",
            "2024-10-29 14:46:39,591 Model training base path: \"flair_output\"\n",
            "2024-10-29 14:46:39,593 ----------------------------------------------------------------------------------------------------\n",
            "2024-10-29 14:46:39,594 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/flair/trainers/trainer.py:499: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler(enabled=use_amp and flair.device.type != \"cpu\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-10-29 14:48:36,579 epoch 1 - iter 1/1 - loss 0.00000000 - time (sec): 116.98 - samples/sec: 81.64 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-10-29 14:48:36,587 ----------------------------------------------------------------------------------------------------\n",
            "2024-10-29 14:48:36,591 EPOCH 1 done: loss 0.0000 - lr: 0.100000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  2.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-10-29 14:48:36,991 DEV : loss -5.580357083090348e-07 - f1-score (micro avg)  0.0\n",
            "2024-10-29 14:48:36,997  - 0 epochs without improvement\n",
            "2024-10-29 14:48:37,001 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-10-29 14:50:34,826 epoch 2 - iter 1/1 - loss -0.00000051 - time (sec): 117.82 - samples/sec: 81.06 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-10-29 14:50:34,837 ----------------------------------------------------------------------------------------------------\n",
            "2024-10-29 14:50:34,844 EPOCH 2 done: loss -0.0000 - lr: 0.100000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  2.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-10-29 14:50:35,253 DEV : loss -5.580357083090348e-07 - f1-score (micro avg)  0.0\n",
            "2024-10-29 14:50:35,260  - 1 epochs without improvement\n",
            "2024-10-29 14:50:35,262 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-10-29 14:52:33,255 epoch 3 - iter 1/1 - loss -0.00000031 - time (sec): 117.99 - samples/sec: 80.95 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-10-29 14:52:33,260 ----------------------------------------------------------------------------------------------------\n",
            "2024-10-29 14:52:33,264 EPOCH 3 done: loss -0.0000 - lr: 0.100000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  1.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-10-29 14:52:33,953 DEV : loss -5.580357083090348e-07 - f1-score (micro avg)  0.0\n",
            "2024-10-29 14:52:33,962  - 2 epochs without improvement\n",
            "2024-10-29 14:52:33,966 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-10-29 14:54:31,900 epoch 4 - iter 1/1 - loss -0.00000041 - time (sec): 117.93 - samples/sec: 80.99 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-10-29 14:54:31,915 ----------------------------------------------------------------------------------------------------\n",
            "2024-10-29 14:54:31,926 EPOCH 4 done: loss -0.0000 - lr: 0.100000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  1.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-10-29 14:54:32,561 DEV : loss -5.580357083090348e-07 - f1-score (micro avg)  0.0\n",
            "2024-10-29 14:54:32,570  - 3 epochs without improvement\n",
            "2024-10-29 14:54:32,575 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-10-29 14:56:31,183 epoch 5 - iter 1/1 - loss 0.00000010 - time (sec): 118.60 - samples/sec: 80.53 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-10-29 14:56:31,192 ----------------------------------------------------------------------------------------------------\n",
            "2024-10-29 14:56:31,198 EPOCH 5 done: loss 0.0000 - lr: 0.100000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  2.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-10-29 14:56:31,620 DEV : loss -5.580357083090348e-07 - f1-score (micro avg)  0.0\n",
            "2024-10-29 14:56:31,627  - 4 epochs without improvement (above 'patience')-> annealing learning_rate to [0.05]\n",
            "2024-10-29 14:56:31,629 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-10-29 14:58:30,225 epoch 6 - iter 1/1 - loss -0.00000010 - time (sec): 118.59 - samples/sec: 80.54 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-10-29 14:58:30,240 ----------------------------------------------------------------------------------------------------\n",
            "2024-10-29 14:58:30,248 EPOCH 6 done: loss -0.0000 - lr: 0.050000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  2.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-10-29 14:58:30,651 DEV : loss -5.580357083090348e-07 - f1-score (micro avg)  0.0\n",
            "2024-10-29 14:58:30,657  - 1 epochs without improvement\n",
            "2024-10-29 14:58:30,661 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-10-29 15:00:29,627 epoch 7 - iter 1/1 - loss 0.00000010 - time (sec): 118.96 - samples/sec: 80.29 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-10-29 15:00:29,636 ----------------------------------------------------------------------------------------------------\n",
            "2024-10-29 15:00:29,648 EPOCH 7 done: loss 0.0000 - lr: 0.050000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  2.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-10-29 15:00:30,058 DEV : loss -5.580357083090348e-07 - f1-score (micro avg)  0.0\n",
            "2024-10-29 15:00:30,066  - 2 epochs without improvement\n",
            "2024-10-29 15:00:30,069 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-10-29 15:02:29,128 epoch 8 - iter 1/1 - loss -0.00000010 - time (sec): 119.06 - samples/sec: 80.22 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-10-29 15:02:29,140 ----------------------------------------------------------------------------------------------------\n",
            "2024-10-29 15:02:29,149 EPOCH 8 done: loss -0.0000 - lr: 0.050000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  1.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-10-29 15:02:29,928 DEV : loss -5.580357083090348e-07 - f1-score (micro avg)  0.0\n",
            "2024-10-29 15:02:29,941  - 3 epochs without improvement\n",
            "2024-10-29 15:02:29,944 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-10-29 15:04:26,327 epoch 9 - iter 1/1 - loss -0.00000051 - time (sec): 116.38 - samples/sec: 82.07 - lr: 0.050000 - momentum: 0.000000\n",
            "2024-10-29 15:04:26,333 ----------------------------------------------------------------------------------------------------\n",
            "2024-10-29 15:04:26,346 EPOCH 9 done: loss -0.0000 - lr: 0.050000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  2.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-10-29 15:04:26,770 DEV : loss -5.580357083090348e-07 - f1-score (micro avg)  0.0\n",
            "2024-10-29 15:04:26,777  - 4 epochs without improvement (above 'patience')-> annealing learning_rate to [0.025]\n",
            "2024-10-29 15:04:26,778 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-10-29 15:06:24,632 epoch 10 - iter 1/1 - loss 0.00000010 - time (sec): 117.85 - samples/sec: 81.04 - lr: 0.025000 - momentum: 0.000000\n",
            "2024-10-29 15:06:24,644 ----------------------------------------------------------------------------------------------------\n",
            "2024-10-29 15:06:24,652 EPOCH 10 done: loss 0.0000 - lr: 0.025000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  2.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-10-29 15:06:25,073 DEV : loss -5.580357083090348e-07 - f1-score (micro avg)  0.0\n",
            "2024-10-29 15:06:25,079  - 1 epochs without improvement\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-10-29 15:06:34,047 ----------------------------------------------------------------------------------------------------\n",
            "2024-10-29 15:06:34,052 Testing using last state of model ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:01<00:00,  1.24s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-10-29 15:06:35,329 \n",
            "Results:\n",
            "- F-score (micro) 0.0\n",
            "- F-score (macro) 0.0\n",
            "- Accuracy 0.0\n",
            "\n",
            "By class:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       SKILL     0.0000    0.0000    0.0000      93.0\n",
            "         JOB     0.0000    0.0000    0.0000      16.0\n",
            "        WORK     0.0000    0.0000    0.0000      16.0\n",
            "     COMPANY     0.0000    0.0000    0.0000      11.0\n",
            "        NAME     0.0000    0.0000    0.0000       6.0\n",
            "       PHONE     0.0000    0.0000    0.0000       4.0\n",
            "         DEG     0.0000    0.0000    0.0000       3.0\n",
            "       STUDY     0.0000    0.0000    0.0000       3.0\n",
            "         UNI     0.0000    0.0000    0.0000       3.0\n",
            "         LOC     0.0000    0.0000    0.0000       3.0\n",
            "       EMAIL     0.0000    0.0000    0.0000       1.0\n",
            "\n",
            "   micro avg     0.0000    0.0000    0.0000     159.0\n",
            "   macro avg     0.0000    0.0000    0.0000     159.0\n",
            "weighted avg     0.0000    0.0000    0.0000     159.0\n",
            "\n",
            "2024-10-29 15:06:35,332 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-10-29 15:06:35,564 ----------------------------------------------------------------------------------------------------\n",
            "2024-10-29 15:06:35,570 Model: \"SequenceTagger(\n",
            "  (embeddings): StackedEmbeddings(\n",
            "    (list_embedding_0): WordEmbeddings(\n",
            "      'glove'\n",
            "      (embedding): Embedding(400001, 100)\n",
            "    )\n",
            "    (list_embedding_1): WordEmbeddings(\n",
            "      'en-crawl'\n",
            "      (embedding): Embedding(1000001, 300)\n",
            "    )\n",
            "  )\n",
            "  (word_dropout): WordDropout(p=0.05)\n",
            "  (locked_dropout): LockedDropout(p=0.5)\n",
            "  (embedding2nn): Linear(in_features=400, out_features=400, bias=True)\n",
            "  (rnn): LSTM(400, 256, batch_first=True, bidirectional=True)\n",
            "  (linear): Linear(in_features=512, out_features=3, bias=True)\n",
            "  (loss_function): ViterbiLoss()\n",
            "  (crf): CRF()\n",
            ")\"\n",
            "2024-10-29 15:06:35,573 ----------------------------------------------------------------------------------------------------\n",
            "2024-10-29 15:06:35,576 Corpus: 20 train + 2 dev + 6 test sentences\n",
            "2024-10-29 15:06:35,579 ----------------------------------------------------------------------------------------------------\n",
            "2024-10-29 15:06:35,580 Train:  20 sentences\n",
            "2024-10-29 15:06:35,582         (train_with_dev=False, train_with_test=False)\n",
            "2024-10-29 15:06:35,584 ----------------------------------------------------------------------------------------------------\n",
            "2024-10-29 15:06:35,585 Training Params:\n",
            "2024-10-29 15:06:35,586  - learning_rate: \"0.1\" \n",
            "2024-10-29 15:06:35,588  - mini_batch_size: \"32\"\n",
            "2024-10-29 15:06:35,589  - max_epochs: \"10\"\n",
            "2024-10-29 15:06:35,590  - shuffle: \"True\"\n",
            "2024-10-29 15:06:35,592 ----------------------------------------------------------------------------------------------------\n",
            "2024-10-29 15:06:35,593 Plugins:\n",
            "2024-10-29 15:06:35,594  - AnnealOnPlateau | patience: '3', anneal_factor: '0.5', min_learning_rate: '0.0001'\n",
            "2024-10-29 15:06:35,596 ----------------------------------------------------------------------------------------------------\n",
            "2024-10-29 15:06:35,597 Final evaluation on model from best epoch (best-model.pt)\n",
            "2024-10-29 15:06:35,598  - metric: \"EvaluationMetric.MICRO_F1_SCORE\"\n",
            "2024-10-29 15:06:35,599 ----------------------------------------------------------------------------------------------------\n",
            "2024-10-29 15:06:35,601 Computation:\n",
            "2024-10-29 15:06:35,602  - compute on device: cpu\n",
            "2024-10-29 15:06:35,603  - embedding storage: gpu\n",
            "2024-10-29 15:06:35,605 ----------------------------------------------------------------------------------------------------\n",
            "2024-10-29 15:06:35,606 Model training base path: \"/flair_output\"\n",
            "2024-10-29 15:06:35,607 ----------------------------------------------------------------------------------------------------\n",
            "2024-10-29 15:06:35,609 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/flair/trainers/trainer.py:499: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler(enabled=use_amp and flair.device.type != \"cpu\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-10-29 15:08:01,262 epoch 1 - iter 1/1 - loss -0.00001145 - time (sec): 85.65 - samples/sec: 111.51 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-10-29 15:08:01,271 ----------------------------------------------------------------------------------------------------\n",
            "2024-10-29 15:08:01,274 EPOCH 1 done: loss -0.0000 - lr: 0.100000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  2.67it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "'EvaluationMetric' object is not subscriptable",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-ed6fad3a6d46>\u001b[0m in \u001b[0;36m<cell line: 27>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m# )\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m trainer.train(\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0mbase_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'/flair_output/'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/flair/trainers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, base_path, anneal_factor, patience, min_learning_rate, initial_extra_patience, anneal_with_restarts, learning_rate, decoder_learning_rate, mini_batch_size, eval_batch_size, mini_batch_chunk_size, max_epochs, optimizer, train_with_dev, train_with_test, reduce_transformer_vocab, main_evaluation_metric, monitor_test, monitor_train_sample, use_final_model_for_eval, gold_label_dictionary_for_eval, exclude_labels, sampler, shuffle, shuffle_first_epoch, embeddings_storage_mode, epoch, save_final_model, save_optimizer_state, save_model_each_k_epochs, create_file_logs, create_loss_file, write_weights, plugins, attach_default_scheduler, **kwargs)\u001b[0m\n\u001b[1;32m    198\u001b[0m         ]:\n\u001b[1;32m    199\u001b[0m             \u001b[0mlocal_variables\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_custom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mlocal_variables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m     def fine_tune(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/flair/trainers/trainer.py\u001b[0m in \u001b[0;36mtrain_custom\u001b[0;34m(self, base_path, learning_rate, decoder_learning_rate, mini_batch_size, eval_batch_size, mini_batch_chunk_size, max_epochs, optimizer, train_with_dev, train_with_test, max_grad_norm, reduce_transformer_vocab, main_evaluation_metric, monitor_test, monitor_train_sample, use_final_model_for_eval, gold_label_dictionary_for_eval, exclude_labels, sampler, shuffle, shuffle_first_epoch, embeddings_storage_mode, epoch, save_final_model, save_optimizer_state, save_model_each_k_epochs, create_file_logs, create_loss_file, write_weights, use_amp, plugins, **kwargs)\u001b[0m\n\u001b[1;32m    681\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mevaluation_split\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluation_split_data\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mevaluation_splits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 683\u001b[0;31m                         eval_result = self.model.evaluate(\n\u001b[0m\u001b[1;32m    684\u001b[0m                             \u001b[0mevaluation_split_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    685\u001b[0m                             \u001b[0mout_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbase_path\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34mf\"{evaluation_split}.tsv\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/flair/nn/model.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, data_points, gold_label_type, out_path, embedding_storage_mode, mini_batch_size, main_evaluation_metric, exclude_labels, gold_label_dictionary, return_loss, **kwargs)\u001b[0m\n\u001b[1;32m    484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    485\u001b[0m             return Result(\n\u001b[0;32m--> 486\u001b[0;31m                 \u001b[0mmain_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclassification_report_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmain_evaluation_metric\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmain_evaluation_metric\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    487\u001b[0m                 \u001b[0mdetailed_results\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdetailed_result\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m                 \u001b[0mclassification_report\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclassification_report_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'EvaluationMetric' object is not subscriptable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate model\n",
        "result, score = trainer.evaluate(corpus.test)\n",
        "print(result)\n",
        "print(score)"
      ],
      "metadata": {
        "id": "6KT8wj3Lns2c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "outputId": "00a04b95-fba1-44b4-8158-6bfec8512e0a"
      },
      "id": "6KT8wj3Lns2c",
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'ModelTrainer' object has no attribute 'evaluate'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-c45746229300>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# evaluate model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'ModelTrainer' object has no attribute 'evaluate'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# make prediction\n",
        "import flair\n",
        "model = SequenceTagger.load('flair_output/final-model.pt')\n",
        "sentence = flair.data.Sentence(resume_text)\n",
        "\n",
        "model.predict(sentence)\n",
        "\n",
        "print(sentence.to_tagged_string())"
      ],
      "metadata": {
        "id": "KOYkWF9Anwec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2cfa6214-ad4a-4418-999a-f74bdc510cd1"
      },
      "id": "KOYkWF9Anwec",
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-10-29 15:09:34,915 SequenceTagger predicts: Dictionary with 3 tags: O, <START>, <STOP>\n",
            "Sentence[278]: \"dot net developer robert smith phone 123 456 78 99 email infoqwikresumecom website wwwqwikresumecom linkedin linkedincomqwikresume address 1737 marshville road alabama objective dot net developer seven years experience design development webbased windows based applications using net technologies hands experience phases software development life cycle sdlc like requirement gathering analysis architectural detail design documentation development testing implementation using agile methodologies like scrum xp test driven environment skills programming languages net technologies c sql plsql web forms win forms web technologies scripting html dhtml css xmlangular jsbootstrap ajax toolkit jquery javascript telerikkendo ui database ms sql server operating systems windows 8 packages ms office amp visio ms frontpage iis version control tools git hub vss tfs methodologies agile oops scrum soa reporting crystal reports net ms sql server reporting services ssrs work experience dot net developer charter communications june 2015 present assisting developing architectural design functional specifications involving analysis designing coding implementation application developing dynamic web page implemented creatively implemented design requirements using client side scripting language technologies assisting agile software development management activities respond unpredictability iterative sprints designing developing web application migrating project mvc architecture using mvc 3 separate internal representations information involved developing telerik kendo ul controls building application enabling focus value generating development tasks involving development presentation logic gui aspnet pages dot net developer abc corp 2011 2015 coded updated maintained computer programs assisted developers prepare high level technical design documents performed code enhancements assist performance analysis provided technical guidance programming standards team trained users team coordinated client amp offshore tearn meet project objectives participated backlog grooming meeting work client remove barriers team worked individual developer also manage offshore team free resume template copyright qwikresumecom usage guidelines\"\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}