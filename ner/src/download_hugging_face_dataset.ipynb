{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chewzzz1014/fyp/blob/master/ner-src/download_hugging_face_dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a1c8ce31",
      "metadata": {
        "id": "a1c8ce31"
      },
      "source": [
        "# Dataset Preparation\n",
        "Steps:\n",
        "1. Download multiple resume dataset from hugging face\n",
        "2. Remove unwanted columns and limit number of rows (for dataset with many rows, only focus on the IT-related resumes)\n",
        "3. Merge all datasets into one csv and download.\n",
        "\n",
        "Dataset Links\n",
        "- https://huggingface.co/datasets/InferencePrince555/Resume-Dataset\n",
        "- https://huggingface.co/datasets/kvsrkc/Resume\n",
        "- https://huggingface.co/datasets/opensporks/resumes\n",
        "- https://huggingface.co/datasets/Dh1raj/resume-dataset\n",
        "- https://huggingface.co/datasets/cnamuangtoun/resume-job-description-fit?row=19\n",
        "- https://huggingface.co/datasets/ahmedheakl/resume-atlas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "896a477a",
      "metadata": {
        "id": "896a477a"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "9NZYbBHxdGu8",
        "outputId": "de1f27e3-bfb8-49b8-81b4-18aaa13def7f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "9NZYbBHxdGu8",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "fc52b6e2",
      "metadata": {
        "id": "fc52b6e2",
        "outputId": "27ab04b3-608e-4324-8516-ea1a380f6873",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# import dataset from hugging face\n",
        "df1 = pd.read_csv(\"hf://datasets/InferencePrince555/Resume-Dataset/updated_data_final_cleaned.csv\")\n",
        "# df2 = pd.read_csv(\"hf://datasets/kvsrkc/Resume/Resume.csv\")\n",
        "# df3 = pd.read_csv(\"hf://datasets/opensporks/resumes/Resume/Resume.csv\")\n",
        "\n",
        "# df4_splits = {'train': 'data/train-00000-of-00001.parquet', 'test': 'data/test-00000-of-00001.parquet', 'validation': 'data/validation-00000-of-00001.parquet'}\n",
        "# df4 = pd.read_parquet(\"hf://datasets/Dh1raj/resume-dataset/\" + df4_splits[\"train\"])\n",
        "\n",
        "# df5_splits = {'train': 'train.csv', 'test': 'test.csv'}\n",
        "# df5 = pd.read_csv(\"hf://datasets/cnamuangtoun/resume-job-description-fit/\" + df5_splits[\"train\"])\n",
        "\n",
        "# df6 = pd.read_csv(\"hf://datasets/ahmedheakl/resume-atlas/train.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7720f610",
      "metadata": {
        "id": "7720f610"
      },
      "source": [
        "## Preprocess df1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "c2218e22",
      "metadata": {
        "id": "c2218e22",
        "outputId": "10d01f75-bebc-4a84-93f5-9e29f2b83e21",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distinct values in 'instruction' column in df1: ['Generate a Resume for a Accountant Job'\n",
            " 'Generate a Resume for a Advocate Job'\n",
            " 'Generate a Resume for a Agriculture Job'\n",
            " 'Generate a Resume for a Apparel Job' 'Generate a Resume for a Arts Job'\n",
            " 'Generate a Resume for a Automation Testing Job'\n",
            " 'Generate a Resume for a Automobile Job'\n",
            " 'Generate a Resume for a Aviation Job' 'Generate a Resume for a BPO Job'\n",
            " 'Generate a Resume for a Banking Job'\n",
            " 'Generate a Resume for a Blockchain Job'\n",
            " 'Generate a Resume for a Business Analyst Job'\n",
            " 'Generate a Resume for a Business Development Job'\n",
            " 'Generate a Resume for a Chef Job'\n",
            " 'Generate a Resume for a Civil Engineer Job'\n",
            " 'Generate a Resume for a Construction Job'\n",
            " 'Generate a Resume for a Consultant Job'\n",
            " 'Generate a Resume for a Data Science Job'\n",
            " 'Generate a Resume for a Database Job'\n",
            " 'Generate a Resume for a Database Administrator Job'\n",
            " 'Generate a Resume for a Designer Job'\n",
            " 'Generate a Resume for a DevOps Engineer Job'\n",
            " 'Generate a Resume for a Digital Media Job'\n",
            " 'Generate a Resume for a DotNet Developer Job'\n",
            " 'Generate a Resume for a ETL Developer Job'\n",
            " 'Generate a Resume for a Electrical Engineering Job'\n",
            " 'Generate a Resume for a Engineering Job'\n",
            " 'Generate a Resume for a Finance Job'\n",
            " 'Generate a Resume for a Fitness Job' 'Generate a Resume for a HR Job'\n",
            " 'Generate a Resume for a Hadoop Job'\n",
            " 'Generate a Resume for a Health and fitness Job'\n",
            " 'Generate a Resume for a Healthcare Job'\n",
            " 'Generate a Resume for a Information Technology Job'\n",
            " 'Generate a Resume for a Java Developer Job'\n",
            " 'Generate a Resume for a Mechanical Engineer Job'\n",
            " 'Generate a Resume for a Network Administrator Job'\n",
            " 'Generate a Resume for a Network Security Engineer Job'\n",
            " 'Generate a Resume for a Operations Manager Job'\n",
            " 'Generate a Resume for a PMO Job'\n",
            " 'Generate a Resume for a Project manager Job'\n",
            " 'Generate a Resume for a Public Relations Job'\n",
            " 'Generate a Resume for a Python Developer Job'\n",
            " 'Generate a Resume for a SAP Developer Job'\n",
            " 'Generate a Resume for a Sales Job'\n",
            " 'Generate a Resume for a Security Analyst Job'\n",
            " 'Generate a Resume for a Software Developer Job'\n",
            " 'Generate a Resume for a Systems Administrator Job'\n",
            " 'Generate a Resume for a Teacher Job'\n",
            " 'Generate a Resume for a Testing Job'\n",
            " 'Generate a Resume for a Web Designing Job'\n",
            " 'Generate a Resume for a Web Developer Job']\n"
          ]
        }
      ],
      "source": [
        "# process df1\n",
        "distinct_instructions = df1['instruction'].unique()\n",
        "print(\"Distinct values in 'instruction' column in df1:\", distinct_instructions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "17f534f2",
      "metadata": {
        "id": "17f534f2",
        "outputId": "fce86fba-71ac-4238-a006-7eb9530c3693",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distinct values in 'instruction' column of filtered_df: ['Generate a Resume for a Data Science Job'\n",
            " 'Generate a Resume for a Database Job'\n",
            " 'Generate a Resume for a Database Administrator Job'\n",
            " 'Generate a Resume for a DevOps Engineer Job'\n",
            " 'Generate a Resume for a DotNet Developer Job'\n",
            " 'Generate a Resume for a ETL Developer Job'\n",
            " 'Generate a Resume for a Information Technology Job'\n",
            " 'Generate a Resume for a Java Developer Job'\n",
            " 'Generate a Resume for a Python Developer Job'\n",
            " 'Generate a Resume for a SAP Developer Job'\n",
            " 'Generate a Resume for a Software Developer Job'\n",
            " 'Generate a Resume for a Web Designing Job'\n",
            " 'Generate a Resume for a Web Developer Job']\n"
          ]
        }
      ],
      "source": [
        "# filter the resume by IT-related resumes only due to high number of resumes\n",
        "filtered_jobs = [\n",
        "    \"data science\",\n",
        "    \"database\",\n",
        "    \"devops\",\n",
        "    \"developer\",\n",
        "    \"information technology\",\n",
        "    \"web\"\n",
        "]\n",
        "filtered_df = df1[df1['instruction'].str.contains('|'.join(filtered_jobs), case=False, regex=True)]\n",
        "print(\"Distinct values in 'instruction' column of filtered_df:\", filtered_df['instruction'].unique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "89a53042",
      "metadata": {
        "id": "89a53042",
        "outputId": "3035c038-cfbd-4a0a-ec02-bb13f4add3c3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 17324 entries, 1428 to 32480\n",
            "Data columns (total 1 columns):\n",
            " #   Column       Non-Null Count  Dtype \n",
            "---  ------       --------------  ----- \n",
            " 0   Resume_test  17324 non-null  object\n",
            "dtypes: object(1)\n",
            "memory usage: 270.7+ KB\n"
          ]
        }
      ],
      "source": [
        "# drop columns\n",
        "df1 = filtered_df.drop(columns=['instruction', 'input'])\n",
        "df1.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "e6a8af33",
      "metadata": {
        "id": "e6a8af33"
      },
      "outputs": [],
      "source": [
        "df1.to_csv('/content/drive/MyDrive/FYP/Implementation/Resume Dataset/resume_collection_1.csv', index=False)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}